"""
from config.i18n import t_gui as _
RTSIç®—æ³• - è¯„çº§è¶‹åŠ¿å¼ºåº¦æŒ‡æ•° (Rating Trend Strength Index)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä¸ªè‚¡è¯„çº§è¶‹åŠ¿å¼ºåº¦è®¡ç®—
2. è¶‹åŠ¿æ–¹å‘æ€§ã€ä¸€è‡´æ€§ã€æŒç»­æ€§ã€å¹…åº¦ç»¼åˆåˆ†æ
3. æ‰¹é‡è®¡ç®—å’Œæ’ååŠŸèƒ½

ç®—æ³•åŸç†ï¼š
- æ–¹å‘æ€§ï¼šçº¿æ€§å›å½’æ–œç‡
- ä¸€è‡´æ€§ï¼šRÂ²å€¼ 
- æ˜¾è‘—æ€§ï¼špå€¼æ£€éªŒ
- å¹…åº¦ï¼šæ ‡å‡†åŒ–å˜åŒ–å¹…åº¦
- RTSIæŒ‡æ•°ï¼šç»¼åˆè¯„åˆ† (0-100)

ä½œè€…: 267278466@qq.com
åˆ›å»ºæ—¶é—´ï¼š2025-06-07
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional, Union
import warnings
from datetime import datetime

# å¯¼å…¥é…ç½®

# å¯¼å…¥å›½é™…åŒ–é…ç½®
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.i18n import t_msci, t_rtsi, t_irsi, t_engine, t_common, set_language
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨å¤‡ç”¨å‡½æ•°
    def t_msci(key): return key
    def t_rtsi(key): return key
    def t_irsi(key): return key
    def t_engine(key): return key
    def t_common(key): return key
    def set_language(lang): pass

def get_rating_score_map():
    """è·å–è¯„çº§åˆ†æ•°æ˜ å°„"""
    return {
        t_rtsi('rating_strong_buy'): 7, 
        t_rtsi('rating_buy'): 6, 
        t_rtsi('rating_moderate_buy'): 5, 
        t_rtsi('rating_slight_buy'): 4,
        t_rtsi('rating_slight_sell'): 3, 
        t_rtsi('rating_moderate_sell'): 2, 
        t_rtsi('rating_sell'): 1, 
        t_rtsi('rating_strong_sell'): 0, 
        '-': None
    }

try:
    from config import RATING_SCORE_MAP
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥é…ç½®ï¼Œä½¿ç”¨åŠ¨æ€æ˜ å°„
    RATING_SCORE_MAP = get_rating_score_map()

# æŠ‘åˆ¶scipyçš„è­¦å‘Š
warnings.filterwarnings('ignore', category=RuntimeWarning)


def calculate_ai_enhanced_rtsi_optimized(stock_ratings, stock_code=None, stock_name=None):
    """AIå¢å¼ºRTSIç®—æ³• - ç®€åŒ–ç‰ˆ"""
    try:
        # æ•°æ®è´¨é‡æ£€æŸ¥
        valid_count = sum(1 for r in stock_ratings if str(r).strip() not in ['-', '', 'nan', 'None'])
        data_quality = valid_count / len(stock_ratings)
        
        if data_quality >= 0.3 and valid_count >= 3:
            try:
                from algorithms.ai_enhanced_signal_analyzer import AIEnhancedSignalAnalyzer
                
                ai_analyzer = AIEnhancedSignalAnalyzer(enable_ai_features=True)
                
                # å‡†å¤‡æ•°æ®
                stock_df = pd.DataFrame({
                    'è‚¡ç¥¨ä»£ç ': [stock_code or 'UNKNOWN'],
                    'è‚¡ç¥¨åç§°': [stock_name or 'UNKNOWN']
                })
                
                date_columns = [col for col in stock_ratings.index if str(col).startswith('202')]
                for col in date_columns:
                    stock_df[col] = [stock_ratings.get(col, '-')]
                
                # AIåˆ†æ
                ai_result = ai_analyzer.comprehensive_analyze(
                    stock_data=stock_df,
                    stock_code=stock_code or 'UNKNOWN',
                    enable_prediction=True
                )
                
                ai_score = ai_result.ai_enhanced_score
                
                if ai_score >= 10:
                    # è·å–åŸºç¡€RTSI
                    base_result = calculate_rating_trend_strength_index_base(stock_ratings)
                    base_rtsi = base_result.get('rtsi', 0)
                    
                    # èåˆåˆ†æ•°
                    if base_rtsi > 0:
                        final_score = ai_score * 0.7 + base_rtsi * 0.3
                    else:
                        final_score = ai_score * 0.8
                    
                    result = base_result.copy()
                    result['rtsi'] = round(final_score, 2)
                    result['algorithm'] = 'ai_enhanced'
                    return result
            except:
                pass
        
        # å›é€€åˆ°åŸºç¡€RTSI
        return calculate_rating_trend_strength_index_base(stock_ratings)
        
    except:
        return {'rtsi': 0, 'trend': 'error', 'confidence': 0}

def calculate_rating_trend_strength_index_base(stock_ratings: pd.Series, language: str = 'zh_CN') -> Dict[str, Union[float, str, int, None]]:
    """åŸå§‹RTSIç®—æ³• - ä½œä¸ºAIå¢å¼ºçš„åŸºç¡€"""

def calculate_rating_trend_strength_index(stock_ratings: pd.Series, language: str = 'zh_CN', stock_code: str = None, stock_name: str = None, enable_ai: bool = True) -> Dict[str, Union[float, str, int, None]]:
    """
    è¯„çº§è¶‹åŠ¿å¼ºåº¦æŒ‡æ•° (Rating Trend Strength Index) - AIå¢å¼ºç‰ˆæœ¬
    ç»¼åˆè€ƒè™‘ï¼šæ–¹å‘æ€§ã€ä¸€è‡´æ€§ã€æŒç»­æ€§ã€å¹…åº¦ï¼Œå¹¶é›†æˆAIå¢å¼ºåŠŸèƒ½
    
    å‚æ•°:
        stock_ratings (pd.Series): è‚¡ç¥¨è¯„çº§åºåˆ—ï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œå€¼ä¸ºè¯„çº§
        language (str): è¯­è¨€è®¾ç½®
        stock_code (str): è‚¡ç¥¨ä»£ç 
        stock_name (str): è‚¡ç¥¨åç§°  
        enable_ai (bool): æ˜¯å¦å¯ç”¨AIå¢å¼ºåŠŸèƒ½
        
    è¿”å›:
        dict: {
            t_rtsi('rtsi'): float,              # RTSIæŒ‡æ•° (0-100)
            t_rtsi('trend'): str,               # è¶‹åŠ¿æ–¹å‘
            'algorithm': str,                   # ä½¿ç”¨çš„ç®—æ³•ç±»å‹
            ...
        }
    """
    # ä¸»ç®—æ³•ï¼šAIå¢å¼ºRTSIï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
    if enable_ai:
        try:
            ai_result = calculate_ai_enhanced_rtsi_optimized(stock_ratings, stock_code, stock_name)
            if ai_result.get('algorithm') == 'ai_enhanced':
                # AIå¢å¼ºæˆåŠŸï¼Œè¿”å›ç»“æœ
                ai_result['primary_algorithm'] = 'ai_enhanced_rtsi'
                ai_result['fallback_used'] = False
                return ai_result
        except Exception as e:
            # AIå¢å¼ºå¤±è´¥ï¼Œè®°å½•ä½†ç»§ç»­ä½¿ç”¨åŸºç¡€ç®—æ³•
            print(f"âš ï¸ AIå¢å¼ºRTSIå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€ç®—æ³•: {str(e)}")
    
    # å®¹é”™æ–¹æ¡ˆï¼šåŸºç¡€RTSIç®—æ³•
    base_result = calculate_rating_trend_strength_index_base(stock_ratings, language)
    base_result['primary_algorithm'] = 'basic_rtsi'
    base_result['fallback_used'] = not enable_ai
    if enable_ai:
        base_result['fallback_reason'] = 'ai_enhancement_failed'
    
    return base_result

def calculate_rating_trend_strength_index_base(stock_ratings: pd.Series, language: str = 'zh_CN') -> Dict[str, Union[float, str, int, None]]:
    """
    åŸå§‹RTSIç®—æ³• - ä½œä¸ºAIå¢å¼ºçš„åŸºç¡€
    è¯„çº§è¶‹åŠ¿å¼ºåº¦æŒ‡æ•° (Rating Trend Strength Index)
    ç»¼åˆè€ƒè™‘ï¼šæ–¹å‘æ€§ã€ä¸€è‡´æ€§ã€æŒç»­æ€§ã€å¹…åº¦
    
    å‚æ•°:
        stock_ratings (pd.Series): è‚¡ç¥¨è¯„çº§åºåˆ—ï¼Œç´¢å¼•ä¸ºæ—¥æœŸï¼Œå€¼ä¸ºè¯„çº§
            t_rtsi('confidence'): float,        # ç½®ä¿¡åº¦ (0-1)
            t_rtsi('slope'): float,             # å›å½’æ–œç‡
            t_rtsi('r_squared'): float,         # RÂ²å€¼
            t_rtsi('recent_score'): int,        # æœ€æ–°è¯„çº§åˆ†æ•°
            t_rtsi('score_change_5d'): float,   # 5æ—¥å˜åŒ–
            t_rtsi('data_points'): int,         # æœ‰æ•ˆæ•°æ®ç‚¹æ•°
            'calculation_time': str     # è®¡ç®—æ—¶é—´
        }
    """
    # è®¾ç½®è¯­è¨€
    set_language(language)
    calculation_start = datetime.now()
    
    # 1. æ•°æ®é¢„å¤„ç†å’Œæ’å€¼æ¯”ä¾‹è®¡ç®—
    if stock_ratings is None or len(stock_ratings) == 0:
        return _get_insufficient_data_result()
    
    # è®¡ç®—æ’å€¼æ¯”ä¾‹
    total_data_points = len(stock_ratings)
    def is_missing(rating):
        try:
            return rating == '-' or pd.isna(rating)
        except:
            return str(rating) in ['-', 'nan', 'None', '<NA>']
    
    missing_count = sum(1 for rating in stock_ratings if is_missing(rating))
    interpolation_ratio = missing_count / total_data_points if total_data_points > 0 else 0
    
    # è·å–åŠ¨æ€è¯„çº§æ˜ å°„è¡¨
    try:
        extended_rating_map = RATING_SCORE_MAP.copy()
    except:
        extended_rating_map = get_rating_score_map()
    
    # æ·»åŠ å¯èƒ½ç¼ºå¤±çš„è¯„çº§æ˜ å°„ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
    additional_mappings = {
        # æ•°å­—è¯„çº§æ˜ å°„
        7: 7, 6: 6, 5: 5, 4: 4, 3: 3, 2: 2, 1: 1, 0: 0,
        # ä¸­æ–‡è¯„çº§æ˜ å°„
        'çœ‹å¤š': 6, 'çœ‹ç©º': 1, 'ä¸­æ€§': 4,
        'å¼ºçƒˆä¹°å…¥': 7, 'ä¹°å…¥': 6, 'è°¨æ…ä¹°å…¥': 5,
        'è°¨æ…å–å‡º': 3, 'å–å‡º': 2, 'å¼ºçƒˆå–å‡º': 1,
        # è‹±æ–‡è¯„çº§æ˜ å°„
        'Strong Buy': 7, 'Buy': 6, 'Moderate Buy': 5, 'Slight Buy': 4,
        'Slight Sell': 3, 'Moderate Sell': 2, 'Sell': 1, 'Strong Sell': 0,
        'Hold': 4
    }
    for rating, score in additional_mappings.items():
        if rating not in extended_rating_map:
            extended_rating_map[rating] = score
    
    # å°†è¯„çº§è½¬æ¢ä¸ºåˆ†æ•°
    scores = stock_ratings.map(extended_rating_map).dropna()
    
    # ä¼˜åŒ–ï¼šé™ä½æœ€å°æ•°æ®ç‚¹è¦æ±‚ä»5åˆ°3
    if len(scores) < 3:
        return _get_insufficient_data_result(len(scores))
    
    try:
        # 2. çº¿æ€§å›å½’åˆ†æ - è¶‹åŠ¿æ–¹å‘æ€§
        x = np.arange(len(scores))
        slope, intercept, r_value, p_value, std_err = stats.linregress(x, scores)
        
        # 3. è¶‹åŠ¿ä¸€è‡´æ€§ (RÂ²å€¼)
        consistency = r_value ** 2
        
        # 4. è¶‹åŠ¿æ˜¾è‘—æ€§ (på€¼æ£€éªŒ) - ä¼˜åŒ–ï¼šæ”¾å®½på€¼é˜ˆå€¼åˆ°0.1
        significance = max(0, 1 - p_value) if p_value < 0.1 else 0
        
        # 5. å˜åŒ–å¹…åº¦ (æ ‡å‡†åŒ–åˆ°8çº§è¯„çº§èŒƒå›´: 0-7)
        rating_scale_max = 7  # 8çº§è¯„çº§ç³»ç»Ÿï¼šå¤§å¤š=7åˆ°å¤§ç©º=0
        amplitude = abs(slope) * len(scores) / rating_scale_max
        amplitude = min(amplitude, 1.0)  # é™åˆ¶åœ¨[0,1]èŒƒå›´
        
        # 6. ç»¼åˆRTSIæŒ‡æ•°è®¡ç®— (0-100)
        # ä¼˜åŒ–æƒé‡åˆ†é…ï¼šä¸€è‡´æ€§45% + æ˜¾è‘—æ€§25% + å¹…åº¦30%
        rtsi = (consistency * 0.45 + significance * 0.25 + amplitude * 0.30) * 100
        
        # 6.5. åŸºç¡€åˆ†æ•°ä¿éšœæœºåˆ¶ - ä¼˜åŒ–ï¼šé¿å…è¿‡å¤šé›¶åˆ†
        if rtsi < 3 and (consistency > 0.1 or amplitude > 0.1):
            rtsi = 3  # æœ€ä½ç»™3åˆ†
        
        # 7. è¶‹åŠ¿æ–¹å‘åˆ¤æ–­
        trend_direction = _determine_trend_direction(slope, significance)
        
        # 8. è®¡ç®—é™„åŠ æŒ‡æ ‡
        recent_score = int(scores.iloc[-1]) if len(scores) > 0 else None
        score_change_5d = _calculate_score_change(scores, 5)
        
        # 9. æ•°æ®è´¨é‡è¯„ä¼°å’Œè­¦å‘Š
        data_quality_warnings = []
        if interpolation_ratio > 0.3:  # æ’å€¼æ¯”ä¾‹è¶…è¿‡30%
            data_quality_warnings.append(f"âš ï¸ æ•°æ®è´¨é‡è­¦å‘Šï¼šæ’å€¼æ¯”ä¾‹è¿‡é«˜ ({interpolation_ratio:.1%})")
        if interpolation_ratio > 0.5:  # æ’å€¼æ¯”ä¾‹è¶…è¿‡50%
            data_quality_warnings.append("ğŸš¨ ä¸¥é‡è­¦å‘Šï¼šè¶…è¿‡ä¸€åŠæ•°æ®éœ€è¦æ’å€¼ï¼ŒRTSIç»“æœå¯é æ€§è¾ƒä½")
        
        # 10. è®¡ç®—æ—¶é—´
        calculation_time = f"{(datetime.now() - calculation_start).total_seconds():.3f}s"
        
        return {
            t_rtsi('rtsi'): round(rtsi, 2),
            t_rtsi('trend'): trend_direction,
            t_rtsi('confidence'): round(significance, 3),
            t_rtsi('slope'): round(slope, 4),
            t_rtsi('r_squared'): round(consistency, 3),
            t_rtsi('recent_score'): recent_score,
            t_rtsi('score_change_5d'): score_change_5d,
            t_rtsi('data_points'): len(scores),
            t_rtsi('calculation_time'): calculation_time,
            'interpolation_ratio': round(interpolation_ratio, 3),
            'data_quality_warnings': data_quality_warnings,
            'total_data_points': total_data_points,
            'missing_count': missing_count
        }
        
    except Exception as e:
        return {
            t_rtsi('rtsi'): 0,
            t_rtsi('trend'): t_rtsi('calculation_error'),
            t_rtsi('confidence'): 0,
            'error': str(e),
            t_rtsi('data_points'): len(scores),
            t_rtsi('calculation_time'): f"{(datetime.now() - calculation_start).total_seconds():.3f}s"
        }


def batch_calculate_rtsi(stock_data: pd.DataFrame, language: str = 'zh_CN') -> Dict[str, Dict]:
    """
    æ‰¹é‡è®¡ç®—æ‰€æœ‰è‚¡ç¥¨çš„RTSIæŒ‡æ•°
    
    å‚æ•°:
        stock_data (pd.DataFrame): è‚¡ç¥¨æ•°æ®ï¼Œåˆ—åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°å’Œå„æ—¥æœŸè¯„çº§
        
    è¿”å›:
        dict: {stock_code: rtsi_result, ...}
    """
    # è®¾ç½®è¯­è¨€
    set_language(language)
    
    if stock_data is None or len(stock_data) == 0:
        return {}
    
    batch_start = datetime.now()
    results = {}
    
    # è¯†åˆ«æ—¥æœŸåˆ—
    date_columns = [col for col in stock_data.columns if str(col).startswith('202')]
    date_columns.sort()  # ç¡®ä¿æ—¥æœŸæ’åº
    
    if len(date_columns) == 0:
        print("")
        return {}
    
    print(f"æ•°æ® å¼€å§‹æ‰¹é‡è®¡ç®—RTSIæŒ‡æ•°...")
    print(f"   æ•°æ®è§„æ¨¡: {len(stock_data)} åªè‚¡ç¥¨ Ã— {len(date_columns)} ä¸ªäº¤æ˜“æ—¥")
    
    # æ‰¹é‡å¤„ç†
    for idx, row in stock_data.iterrows():
        stock_code = str(row.get('è‚¡ç¥¨ä»£ç ', f'STOCK_{idx}'))
        stock_name = row.get('è‚¡ç¥¨åç§°', 'æœªçŸ¥è‚¡ç¥¨')
        
        # æå–è¯¥è‚¡ç¥¨çš„è¯„çº§åºåˆ—
        stock_ratings = row[date_columns]
        
        # è®¡ç®—RTSI
        rtsi_result = calculate_rating_trend_strength_index(stock_ratings)
        
        # æ·»åŠ è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        rtsi_result.update({
            t_rtsi('stock_code'): stock_code,
            t_rtsi('stock_name'): stock_name,
            t_rtsi('industry'): row.get('è¡Œä¸š', 'æœªåˆ†ç±»')
        })
        
        results[stock_code] = rtsi_result
        
        # è¿›åº¦æç¤º
        if (idx + 1) % 1000 == 0:
            print(f"   å·²å¤„ç†: {idx + 1:,} / {len(stock_data):,} åªè‚¡ç¥¨")
    
    batch_time = (datetime.now() - batch_start).total_seconds()
    print(f"æˆåŠŸ æ‰¹é‡è®¡ç®—å®Œæˆ: {len(results)} åªè‚¡ç¥¨ï¼Œè€—æ—¶ {batch_time:.2f} ç§’")
    print(f"   å¹³å‡é€Ÿåº¦: {len(results) / batch_time:.1f} åª/ç§’")
    
    return results


def get_rtsi_ranking(rtsi_results: Dict[str, Dict], top_n: int = 50, 
                    trend_filter: Optional[str] = None) -> List[Tuple[str, str, float, str]]:
    """
    è·å–RTSIæŒ‡æ•°æ’å
    
    å‚æ•°:
        rtsi_results (dict): æ‰¹é‡è®¡ç®—çš„RTSIç»“æœ
        top_n (int): è¿”å›å‰Nåï¼Œé»˜è®¤50
        trend_filter (str): è¶‹åŠ¿è¿‡æ»¤å™¨ï¼Œå¯é€‰å€¼: 'up', 'down', t_rtsi('strong_up'), t_rtsi('strong_down')
        
    è¿”å›:
        list: [(stock_code, stock_name, rtsi, trend), ...] æŒ‰RTSIé™åºæ’åˆ—
    """
    if not rtsi_results:
        return []
    
    # è¿‡æ»¤æœ‰æ•ˆç»“æœ
    valid_results = []
    for stock_code, result in rtsi_results.items():
        if result.get(t_rtsi('rtsi'), 0) > 0:  # æ’é™¤è®¡ç®—å¤±è´¥çš„ç»“æœ
            # è¶‹åŠ¿è¿‡æ»¤
            if trend_filter:
                trend = result.get(t_rtsi('trend'), '')
                if trend_filter == 'up' and 'up' not in trend:
                    continue
                elif trend_filter == 'down' and 'down' not in trend:
                    continue
                elif trend_filter == t_rtsi('strong_up') and trend != t_rtsi('strong_up'):
                    continue
                elif trend_filter == t_rtsi('strong_down') and trend != t_rtsi('strong_down'):
                    continue
            
            valid_results.append((
                stock_code,
                result.get(t_rtsi('stock_name'), 'æœªçŸ¥'),
                result.get(t_rtsi('rtsi'), 0),
                result.get(t_rtsi('trend'), 'unknown'),
                result.get(t_rtsi('confidence'), 0),
                result.get(t_rtsi('recent_score'), 0)
            ))
    
    # æŒ‰RTSIæŒ‡æ•°é™åºæ’åº
    valid_results.sort(key=lambda x: x[2], reverse=True)
    
    # è¿”å›å‰Nå
    return [(code, name, rtsi, trend) for code, name, rtsi, trend, conf, score in valid_results[:top_n]]


def get_rtsi_statistics(rtsi_results: Dict[str, Dict]) -> Dict[str, Union[int, float]]:
    """
    è·å–RTSIè®¡ç®—çš„ç»Ÿè®¡ä¿¡æ¯
    
    å‚æ•°:
        rtsi_results (dict): æ‰¹é‡è®¡ç®—çš„RTSIç»“æœ
        
    è¿”å›:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    if not rtsi_results:
        return {}
    
    valid_rtsi = [result[t_rtsi('rtsi')] for result in rtsi_results.values() 
                  if result.get(t_rtsi('rtsi'), 0) > 0]
    
    if not valid_rtsi:
        return {'total_stocks': len(rtsi_results), 'valid_calculations': 0}
    
    # è¶‹åŠ¿åˆ†å¸ƒç»Ÿè®¡
    trend_counts = {}
    for result in rtsi_results.values():
        trend = result.get(t_rtsi('trend'), 'unknown')
        trend_counts[trend] = trend_counts.get(trend, 0) + 1
    
    return {
        'total_stocks': len(rtsi_results),
        'valid_calculations': len(valid_rtsi),
        'success_rate': len(valid_rtsi) / len(rtsi_results) * 100,
        'rtsi_mean': np.mean(valid_rtsi),
        'rtsi_median': np.median(valid_rtsi),
        'rtsi_std': np.std(valid_rtsi),
        'rtsi_max': max(valid_rtsi),
        'rtsi_min': min(valid_rtsi),
        'trend_distribution': trend_counts
    }


# ç§æœ‰è¾…åŠ©å‡½æ•°

def _get_insufficient_data_result(data_points: int = 0) -> Dict:
    """è¿”å›æ•°æ®ä¸è¶³çš„ç»“æœ"""
    return {
        t_rtsi('rtsi'): 0,
        t_rtsi('trend'): t_rtsi('insufficient_data'),
        t_rtsi('confidence'): 0,
        t_rtsi('slope'): 0,
        t_rtsi('r_squared'): 0,
        t_rtsi('recent_score'): None,
        t_rtsi('score_change_5d'): None,
        t_rtsi('data_points'): data_points,
        t_rtsi('calculation_time'): '0.001s'
    }


def _determine_trend_direction(slope: float, significance: float) -> str:
    """
    æ ¹æ®æ–œç‡å’Œæ˜¾è‘—æ€§ç¡®å®šè¶‹åŠ¿æ–¹å‘ - ä¼˜åŒ–ç‰ˆæœ¬
    é‡‡ç”¨ç»Ÿä¸€çš„7çº§åˆ†ç±»æ ‡å‡†ï¼ŒåŸºäºç»Ÿè®¡å­¦åŸç†
    
    å‚æ•°:
        slope (float): å›å½’æ–œç‡
        significance (float): æ˜¾è‘—æ€§æ°´å¹³
        
    è¿”å›:
        str: è¶‹åŠ¿æ–¹å‘æè¿°ï¼ˆç»Ÿä¸€æ ‡å‡†ï¼‰
    """
    # å…ˆè®¡ç®—åŸºç¡€RTSIåˆ†æ•°ç”¨äºåˆ†ç±»
    if significance < 0.3:  # æ˜¾è‘—æ€§å¤ªä½ï¼Œå½’ä¸ºæ¨ªç›˜
        return t_rtsi('neutral')
    
    # åŸºäºæ–œç‡å¼ºåº¦å’Œæ˜¾è‘—æ€§çš„ç»„åˆåˆ¤æ–­
    if slope > 0.15 and significance > 0.7:
        return t_rtsi('strong_bull')      # å¼ºåŠ¿å¤šå¤´è¶‹åŠ¿
    elif slope > 0.08 and significance > 0.5:
        return t_rtsi('moderate_bull')    # æ¸©å’Œå¤šå¤´è¶‹åŠ¿
    elif slope > 0.03:
        return t_rtsi('weak_bull')        # å¼±åŠ¿å¤šå¤´æ ¼å±€
    elif slope < -0.15 and significance > 0.7:
        return t_rtsi('strong_bear')      # å¼ºåŠ¿ç©ºå¤´è¶‹åŠ¿
    elif slope < -0.08 and significance > 0.5:
        return t_rtsi('moderate_bear')    # æ¸©å’Œç©ºå¤´è¶‹åŠ¿
    elif slope < -0.03:
        return t_rtsi('weak_bear')        # å¼±åŠ¿ç©ºå¤´æ ¼å±€
    else:
        return t_rtsi('neutral')          # æ¨ªç›˜æ•´ç†æ ¼å±€


def classify_rtsi_by_value(rtsi_value: float) -> str:
    """
    æ ¹æ®RTSIæ•°å€¼è¿›è¡Œç»Ÿä¸€åˆ†ç±» - æ–°å¢å‡½æ•°
    é‡‡ç”¨åŸºäºç»Ÿè®¡å­¦åˆ†æçš„7çº§åˆ†ç±»æ ‡å‡†
    
    å‚æ•°:
        rtsi_value (float): RTSIæŒ‡æ•°å€¼ (0-100)
        
    è¿”å›:
        str: ç»Ÿä¸€çš„è¶‹åŠ¿åˆ†ç±»
    """
    if rtsi_value >= 75:
        return t_rtsi('strong_bull')      # å¼ºåŠ¿å¤šå¤´ï¼šç»Ÿè®¡å­¦ä¸Šä½æ•°(90%+)
    elif rtsi_value >= 60:
        return t_rtsi('moderate_bull')    # æ¸©å’Œå¤šå¤´ï¼šä¸Šå››åˆ†ä½æ•°(75%+)
    elif rtsi_value >= 50:
        return t_rtsi('weak_bull')        # å¼±åŠ¿å¤šå¤´ï¼šä¸­ä½æ•°ä»¥ä¸Š
    elif rtsi_value >= 40:
        return t_rtsi('neutral')          # æ¨ªç›˜æ•´ç†ï¼šä¸­æ€§åŒºé—´
    elif rtsi_value >= 30:
        return t_rtsi('weak_bear')        # å¼±åŠ¿ç©ºå¤´ï¼šä¸‹å››åˆ†ä½æ•°(25%+)
    elif rtsi_value >= 20:
        return t_rtsi('moderate_bear')    # æ¸©å’Œç©ºå¤´ï¼šè¾ƒä½åˆ†ä½æ•°
    else:
        return t_rtsi('strong_bear')      # å¼ºåŠ¿ç©ºå¤´ï¼šæœ€ä½åˆ†ä½æ•°


def get_professional_terminology(trend_category: str) -> dict:
    """
    è·å–ä¸“ä¸šæœ¯è¯­æè¿° - æ–°å¢å‡½æ•°
    
    å‚æ•°:
        trend_category (str): è¶‹åŠ¿åˆ†ç±»
        
    è¿”å›:
        dict: åŒ…å«ç®€çŸ­å’Œè¯¦ç»†æè¿°çš„ä¸“ä¸šæœ¯è¯­
    """
    terminology = {
        t_rtsi('strong_bull'): {
            'short': 'å¼ºåŠ¿å¤šå¤´',
            'detailed': 'å¼ºåŠ¿å¤šå¤´è¶‹åŠ¿ï¼ŒæŠ€æœ¯é¢æåº¦ä¹è§‚ï¼Œå»ºè®®ç§¯æé…ç½®',
            'english': 'Strong Bullish Trend',
            'confidence_required': 0.7
        },
        t_rtsi('moderate_bull'): {
            'short': 'æ¸©å’Œå¤šå¤´', 
            'detailed': 'æ¸©å’Œå¤šå¤´è¶‹åŠ¿ï¼Œä¸Šå‡åŠ¨èƒ½å……è¶³ï¼Œé€‚åˆä¸­çº¿æŒæœ‰',
            'english': 'Moderate Bullish Trend',
            'confidence_required': 0.5
        },
        t_rtsi('weak_bull'): {
            'short': 'å¼±åŠ¿å¤šå¤´',
            'detailed': 'å¼±åŠ¿å¤šå¤´æ ¼å±€ï¼Œä¸Šå‡ç©ºé—´æœ‰é™ï¼Œè°¨æ…ä¹è§‚',
            'english': 'Weak Bullish Bias',
            'confidence_required': 0.4
        },
        t_rtsi('neutral'): {
            'short': 'æ¨ªç›˜æ•´ç†',
            'detailed': 'æ¨ªç›˜æ•´ç†æ ¼å±€ï¼Œæ–¹å‘é€‰æ‹©å¾…å®šï¼Œè§‚æœ›ä¸ºä¸»',
            'english': 'Sideways Consolidation',
            'confidence_required': 0.3
        },
        t_rtsi('weak_bear'): {
            'short': 'å¼±åŠ¿ç©ºå¤´',
            'detailed': 'å¼±åŠ¿ç©ºå¤´æ ¼å±€ï¼Œä¸‹è·Œç©ºé—´æœ‰é™ï¼Œé€‚åº¦é˜²å¾¡',
            'english': 'Weak Bearish Bias', 
            'confidence_required': 0.4
        },
        t_rtsi('moderate_bear'): {
            'short': 'æ¸©å’Œç©ºå¤´',
            'detailed': 'æ¸©å’Œç©ºå¤´è¶‹åŠ¿ï¼Œä¸‹è·ŒåŠ¨èƒ½å……è¶³ï¼Œå»ºè®®å‡ä»“',
            'english': 'Moderate Bearish Trend',
            'confidence_required': 0.5
        },
        t_rtsi('strong_bear'): {
            'short': 'å¼ºåŠ¿ç©ºå¤´',
            'detailed': 'å¼ºåŠ¿ç©ºå¤´è¶‹åŠ¿ï¼ŒæŠ€æœ¯é¢æåº¦æ‚²è§‚ï¼Œä¸¥æ ¼é£æ§',
            'english': 'Strong Bearish Trend',
            'confidence_required': 0.7
        }
    }
    
    return terminology.get(trend_category, {
        'short': 'æœªçŸ¥è¶‹åŠ¿',
        'detailed': 'è¶‹åŠ¿æ–¹å‘ä¸æ˜ç¡®ï¼Œå»ºè®®è°¨æ…æ“ä½œ',
        'english': 'Unknown Trend',
        'confidence_required': 0.5
    })


def calculate_risk_level_unified(rtsi_value: float, confidence: float) -> str:
    """
    ç»Ÿä¸€çš„é£é™©ç­‰çº§è¯„ä¼° - æ–°å¢å‡½æ•°
    åŸºäºRTSIå€¼å’Œç½®ä¿¡åº¦çš„ç»¼åˆè¯„ä¼°
    
    å‚æ•°:
        rtsi_value (float): RTSIæŒ‡æ•°å€¼
        confidence (float): ç½®ä¿¡åº¦
        
    è¿”å›:
        str: é£é™©ç­‰çº§æè¿°
    """
    # åŸºäºRTSIå€¼å’Œç½®ä¿¡åº¦çš„çŸ©é˜µè¯„ä¼°
    if rtsi_value >= 75 and confidence >= 0.7:
        return 'ğŸŸ¢ æä½é£é™©ï¼ˆå¼ºåŠ¿ç¡®è®¤ï¼‰'
    elif rtsi_value >= 75 and confidence >= 0.4:
        return 'ğŸŸ¡ ä¸­ç­‰é£é™©ï¼ˆå¼ºåŠ¿å¾…ç¡®è®¤ï¼‰'
    elif rtsi_value >= 60 and confidence >= 0.5:
        return 'ğŸŸ¢ ä½é£é™©ï¼ˆæ¸©å’Œä¸Šå‡ï¼‰'
    elif rtsi_value >= 50 and confidence >= 0.4:
        return 'ğŸŸ¡ ä¸­ç­‰é£é™©ï¼ˆå¼±åŠ¿å¤šå¤´ï¼‰'
    elif rtsi_value >= 40:
        return 'ğŸŸ¡ ä¸­ç­‰é£é™©ï¼ˆä¸­æ€§åŒºé—´ï¼‰'
    elif rtsi_value >= 30:
        return 'ğŸŸ  è¾ƒé«˜é£é™©ï¼ˆå¼±åŠ¿ç©ºå¤´ï¼‰'
    elif rtsi_value >= 20 and confidence >= 0.5:
        return 'ğŸ”´ é«˜é£é™©ï¼ˆæ¸©å’Œä¸‹è·Œï¼‰'
    elif rtsi_value < 20 and confidence >= 0.7:
        return 'ğŸ”´ æé«˜é£é™©ï¼ˆå¼ºåŠ¿ä¸‹è·Œç¡®è®¤ï¼‰'
    else:
        return 'ğŸ”´ é«˜é£é™©'


def _calculate_score_change(scores: pd.Series, days: int) -> Optional[float]:
    """
    è®¡ç®—æŒ‡å®šå¤©æ•°çš„è¯„çº§åˆ†æ•°å˜åŒ–
    
    å‚æ•°:
        scores (pd.Series): è¯„çº§åˆ†æ•°åºåˆ—
        days (int): è®¡ç®—å¤©æ•°
        
    è¿”å›:
        float: åˆ†æ•°å˜åŒ–ï¼Œå¦‚æœæ•°æ®ä¸è¶³è¿”å›None
    """
    if len(scores) < days + 1:
        return None
    
    return float(scores.iloc[-1] - scores.iloc[-(days + 1)])


# æ¨¡å—æµ‹è¯•å‡½æ•°
def test_rtsi_calculator():
    """æµ‹è¯•RTSIè®¡ç®—å™¨åŠŸèƒ½"""
    print("RTSI...")
    
    # æ„é€ æµ‹è¯•æ•°æ®
    test_ratings = pd.Series([
        'ä¸­ç©º', 'å°ç©º', 'å¾®ç©º', 'å¾®å¤š', 'å°å¤š', 'ä¸­å¤š', 'å¤§å¤š'
    ])
    
    # æµ‹è¯•å•ä¸ªè®¡ç®—
    result = calculate_rating_trend_strength_index(test_ratings)
    print(f"   æµ‹è¯•ç»“æœ: RTSI={result[t_rtsi('rtsi')]}, è¶‹åŠ¿={result[t_rtsi('trend')]}")
    
    # æ„é€ æ‰¹é‡æµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'è‚¡ç¥¨ä»£ç ': ['000001', '000002', '000003'],
        'è‚¡ç¥¨åç§°': ['æµ‹è¯•è‚¡ç¥¨A', 'æµ‹è¯•è‚¡ç¥¨B', 'æµ‹è¯•è‚¡ç¥¨C'],
        'è¡Œä¸š': ['é“¶è¡Œ', 'åœ°äº§', 'ç§‘æŠ€'],
        '20250601': ['ä¸­ç©º', 'å¾®å¤š', 'å¤§å¤š'],
        '20250602': ['å°ç©º', 'å°å¤š', 'ä¸­å¤š'],
        '20250603': ['å¾®ç©º', 'ä¸­å¤š', 'å°å¤š'],
        '20250604': ['å¾®å¤š', 'å¤§å¤š', 'å¾®å¤š'],
        '20250605': ['å°å¤š', 'ä¸­å¤š', 'å¾®ç©º']
    })
    
    # æµ‹è¯•æ‰¹é‡è®¡ç®—
    batch_results = batch_calculate_rtsi(test_data)
    print(f"   æ‰¹é‡æµ‹è¯•: å¤„ç† {len(batch_results)} åªè‚¡ç¥¨")
    
    # æµ‹è¯•æ’å
    ranking = get_rtsi_ranking(batch_results, top_n=3)
    print(f"   æ’åæµ‹è¯•: å‰3åè·å–æˆåŠŸ")
    
    # æµ‹è¯•ç»Ÿè®¡
    stats = get_rtsi_statistics(batch_results)
    print(f"   ç»Ÿè®¡æµ‹è¯•: æˆåŠŸç‡ {stats.get('success_rate', 0):.1f}%")
    
    print("RTSI")
    return True


if __name__ == "__main__":
    test_rtsi_calculator()


class RTSICalculator:
    """
    RTSIç®—æ³•è®¡ç®—å™¨ç±»
    
    æä¾›é¢å‘å¯¹è±¡çš„RTSIè®¡ç®—æ¥å£ï¼Œä¾¿äºå®ä¾‹åŒ–å’Œé…ç½®ç®¡ç†
    """
    
    def __init__(self, rating_map: Dict = None, min_data_points: int = 5, enable_cache: bool = True):
        """
        åˆå§‹åŒ–RTSIè®¡ç®—å™¨
        
        å‚æ•°:
            rating_map (dict): è¯„çº§æ˜ å°„è¡¨ï¼Œé»˜è®¤ä½¿ç”¨RATING_SCORE_MAP
            min_data_points (int): æœ€å°‘æ•°æ®ç‚¹è¦æ±‚ï¼Œé»˜è®¤5ä¸ª
            enable_cache (bool): æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜ï¼Œé»˜è®¤å¯ç”¨
        """
        self.rating_map = rating_map or RATING_SCORE_MAP
        self.min_data_points = min_data_points
        self.calculation_count = 0
        self.enable_cache = enable_cache
        self._cache = {} if enable_cache else None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_calculations': 0,
            'cache_hits': 0,
            'total_time': 0.0,
            'avg_time_per_stock': 0.0
        }
    
    def calculate(self, stock_ratings: pd.Series, stock_code: str = None, language: str = 'zh_CN') -> Dict[str, Union[float, str, int, None]]:
        """
        è®¡ç®—å•åªè‚¡ç¥¨çš„RTSIæŒ‡æ•°
        
        å‚æ•°:
            stock_ratings (pd.Series): è‚¡ç¥¨è¯„çº§åºåˆ—
            stock_code (str): è‚¡ç¥¨ä»£ç ï¼Œç”¨äºç¼“å­˜é”®
            language (str): è¯­è¨€è®¾ç½®
            
        è¿”å›:
            dict: RTSIè®¡ç®—ç»“æœ
        """
        self.calculation_count += 1
        start_time = datetime.now()
        
        # ç¼“å­˜æ£€æŸ¥
        if self.enable_cache and stock_code:
            cache_key = self._generate_cache_key(stock_ratings, stock_code)
            if cache_key in self._cache:
                self.stats['cache_hits'] += 1
                return self._cache[cache_key]
        
        # æ‰§è¡Œè®¡ç®—
        result = calculate_rating_trend_strength_index(stock_ratings, language=language)
        
        # æ›´æ–°ç»Ÿè®¡
        calc_time = (datetime.now() - start_time).total_seconds()
        self.stats['total_calculations'] += 1
        self.stats['total_time'] += calc_time
        self.stats['avg_time_per_stock'] = self.stats['total_time'] / self.stats['total_calculations']
        
        # å­˜å‚¨ç¼“å­˜
        if self.enable_cache and stock_code:
            self._cache[cache_key] = result
        
        return result
    
    def batch_calculate_optimized(self, stock_data: pd.DataFrame, parallel: bool = False, language: str = 'zh_CN') -> Dict[str, Dict]:
        """
        ä¼˜åŒ–çš„æ‰¹é‡è®¡ç®—RTSIæŒ‡æ•°
        
        å‚æ•°:
            stock_data (pd.DataFrame): è‚¡ç¥¨æ•°æ®
            parallel (bool): æ˜¯å¦ä½¿ç”¨å¹¶è¡Œè®¡ç®—ï¼ˆå¤§æ•°æ®é›†æ¨èï¼‰
            language (str): è¯­è¨€è®¾ç½®
            
        è¿”å›:
            dict: æ‰¹é‡è®¡ç®—ç»“æœ
        """
        if parallel and len(stock_data) > 1000:
            return self._parallel_batch_calculate(stock_data, language=language)
        else:
            return batch_calculate_rtsi(stock_data, language=language)
    
    def _parallel_batch_calculate(self, stock_data: pd.DataFrame, language: str = 'zh_CN') -> Dict[str, Dict]:
        """
        å¹¶è¡Œæ‰¹é‡è®¡ç®—ï¼ˆé¢„ç•™æ¥å£ï¼‰
        """
        # å½“å‰ä½¿ç”¨æ ‡å‡†æ‰¹é‡è®¡ç®—ï¼Œåç»­å¯é›†æˆmultiprocessing
        print("...")
        return batch_calculate_rtsi(stock_data, language=language)
    
    def _generate_cache_key(self, stock_ratings: pd.Series, stock_code: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        ratings_hash = hash(tuple(stock_ratings.dropna().values))
        return f"{stock_code}_{ratings_hash}"
    
    def get_performance_stats(self) -> Dict[str, Union[int, float, str]]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        cache_hit_rate = (self.stats['cache_hits'] / max(1, self.stats['total_calculations'])) * 100
        
        return {
            'total_calculations': self.stats['total_calculations'],
            'cache_hits': self.stats['cache_hits'],
            'cache_hit_rate': f"{cache_hit_rate:.1f}%",
            'total_time': f"{self.stats['total_time']:.3f}s",
            'avg_time_per_stock': f"{self.stats['avg_time_per_stock']*1000:.2f}ms",
            'cache_enabled': self.enable_cache,
            'cache_size': len(self._cache) if self._cache else 0
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self._cache:
            self._cache.clear()
            print("RTSI")
    
    def batch_calculate(self, stock_data: pd.DataFrame, language: str = 'zh_CN') -> Dict[str, Dict]:
        """
        æ‰¹é‡è®¡ç®—RTSIæŒ‡æ•°
        
        å‚æ•°:
            stock_data (pd.DataFrame): è‚¡ç¥¨æ•°æ®
            language (str): è¯­è¨€è®¾ç½®
            
        è¿”å›:
            dict: æ‰¹é‡è®¡ç®—ç»“æœ
        """
        return self.batch_calculate_optimized(stock_data, parallel=False, language=language)
    
    def get_ranking(self, rtsi_results: Dict[str, Dict], top_n: int = 50, 
                   trend_filter: Optional[str] = None) -> List[Tuple[str, str, float, str]]:
        """
        è·å–RTSIæ’å
        
        å‚æ•°:
            rtsi_results (dict): RTSIè®¡ç®—ç»“æœ
            top_n (int): è¿”å›å‰Nå
            trend_filter (str): è¶‹åŠ¿è¿‡æ»¤å™¨
            
        è¿”å›:
            list: æ’åç»“æœ
        """
        return get_rtsi_ranking(rtsi_results, top_n, trend_filter)
    
    def get_statistics(self, rtsi_results: Dict[str, Dict]) -> Dict[str, Union[int, float]]:
        """
        è·å–RTSIç»Ÿè®¡ä¿¡æ¯
        
        å‚æ•°:
            rtsi_results (dict): RTSIè®¡ç®—ç»“æœ
            
        è¿”å›:
            dict: ç»Ÿè®¡ä¿¡æ¯
        """
        return get_rtsi_statistics(rtsi_results)
    
    def reset_counter(self):
        """é‡ç½®è®¡ç®—è®¡æ•°å™¨"""
        self.calculation_count = 0
        self.stats = {
            'total_calculations': 0,
            'cache_hits': 0,
            'total_time': 0.0,
            'avg_time_per_stock': 0.0
        }
    
    def __str__(self):
        cache_info = f", cache={len(self._cache) if self._cache else 0}" if self.enable_cache else ""
        return f"RTSICalculator(calculations={self.calculation_count}, min_points={self.min_data_points}{cache_info})"

# ========== AIå¢å¼ºRTSIç®—æ³•é›†æˆ ==========

# AIå¢å¼ºRTSIç®—æ³• - æœ€ä½³é…ç½®é›†æˆ
from algorithms.ai_enhanced_signal_analyzer import AIEnhancedSignalAnalyzer

# å…¨å±€AIåˆ†æå™¨å®ä¾‹
_ai_analyzer = None

def get_ai_analyzer():
    global _ai_analyzer
    if _ai_analyzer is None:
        _ai_analyzer = AIEnhancedSignalAnalyzer(enable_ai_features=True)
    return _ai_analyzer

def calculate_ai_enhanced_rtsi_best(stock_ratings: pd.Series, 
                                   stock_code: str = None,
                                   stock_name: str = None) -> Dict[str, Union[float, str, int, None]]:
    """
    AIå¢å¼ºRTSIç®—æ³• - æœ€ä½³é…ç½®ç‰ˆæœ¬
    
    æœ€ä½³å‚æ•°:
    - AIæƒé‡: 0.7
    - æ•°æ®è´¨é‡é˜ˆå€¼: 0.2
    - æœ€å°AIåˆ†æ•°: 15
    """
    try:
        # è®¡ç®—æ•°æ®è´¨é‡
        total_points = len(stock_ratings)
        valid_points = sum(1 for rating in stock_ratings 
                          if str(rating).strip() not in ['-', '', 'nan', 'None'])
        data_quality = valid_points / total_points if total_points > 0 else 0
        
        # AIå¢å¼ºæ¡ä»¶
        use_ai = (data_quality >= 0.2 and valid_points >= 3)
        
        if use_ai:
            try:
                ai_analyzer = get_ai_analyzer()
                
                # å‡†å¤‡æ•°æ®
                stock_df = pd.DataFrame({
                    'è‚¡ç¥¨ä»£ç ': [stock_code or 'UNKNOWN'],
                    'è‚¡ç¥¨åç§°': [stock_name or 'UNKNOWN']
                })
                
                # æ·»åŠ è¯„çº§æ•°æ®
                for col in stock_ratings.index:
                    if str(col).startswith('202'):
                        stock_df[col] = [stock_ratings.get(col, '-')]
                
                # AIåˆ†æ
                ai_result = ai_analyzer.comprehensive_analyze(
                    stock_data=stock_df,
                    stock_code=stock_code or 'UNKNOWN',
                    enable_prediction=True
                )
                
                ai_score = ai_result.ai_enhanced_score
                
                if ai_score >= 15:
                    # è·å–åŸºç¡€RTSI
                    base_result = calculate_rating_trend_strength_index(stock_ratings)
                    base_rtsi = base_result.get('rtsi', 0)
                    
                    # èåˆåˆ†æ•°
                    if base_rtsi > 0:
                        final_score = ai_score * 0.7 + base_rtsi * 0.30000000000000004
                    else:
                        final_score = ai_score * 0.8
                    
                    result = base_result.copy()
                    result['rtsi'] = round(final_score, 2)
                    result['algorithm'] = 'ai_enhanced_best'
                    result['ai_score'] = ai_score
                    result['base_rtsi'] = base_rtsi
                    return result
            except:
                pass
        
        # å›é€€åˆ°åŸºç¡€RTSI
        return calculate_rating_trend_strength_index(stock_ratings)
        
    except Exception as e:
        return {
            'rtsi': 0,
            'trend': 'error',
            'confidence': 0,
            'error': str(e)
        }
