"""
from config.gui_i18n import t_gui as _
å®æ—¶åˆ†æå¼•æ“æ¨¡å—

æä¾›é«˜æ€§èƒ½çš„è‚¡ç¥¨åˆ†æè®¡ç®—å¼•æ“ï¼Œæ•´åˆRTSIã€IRSIã€MSCIä¸‰å¤§æ ¸å¿ƒç®—æ³•ã€‚
æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—ã€ç»“æœç¼“å­˜ã€æ€§èƒ½ç›‘æ§ç­‰åŠŸèƒ½ã€‚

ä½œè€…: 267278466@qq.com
ç‰ˆæœ¬: 1.0.0
"""

import threading
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import pandas as pd
import numpy as np

from data.stock_dataset import StockDataSet
from algorithms.rtsi_calculator import calculate_rating_trend_strength_index
from algorithms.enhanced_rtsi_calculator import EnhancedRTSICalculator
from algorithms.irsi_calculator import calculate_industry_relative_strength
from algorithms.msci_calculator import calculate_market_sentiment_composite_index

# å¯¼å…¥å¢å¼ºç‰ˆTMAåˆ†æå™¨
try:
    from algorithms.enhanced_tma_analyzer import EnhancedTMAAnalyzer, enhanced_industry_analysis
    ENHANCED_TMA_AVAILABLE = True
except ImportError as e:
    logger.warning(f"å¢å¼ºTMAåˆ†æå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼: {e}")
    ENHANCED_TMA_AVAILABLE = False
from config import get_config

# é…ç½®æ—¥å¿—

# å¯¼å…¥å›½é™…åŒ–é…ç½®
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from config.gui_i18n import t_gui as t_msci, t_gui as t_rtsi, t_gui as t_irsi, t_gui as t_engine, t_gui as t_common, set_language
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œä½¿ç”¨å¤‡ç”¨å‡½æ•°
    def t_msci(key): return key
    def t_rtsi(key): return key
    def t_irsi(key): return key
    def t_engine(key): return key
    def t_common(key): return key
    def set_language(lang): pass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AnalysisResults:
    """åˆ†æç»“æœæ•°æ®ç±»"""
    
    def __init__(self):
        self.stocks: Dict[str, Dict] = {}
        self.industries: Dict[str, Dict] = {}
        self.market: Dict = {}
        self.metadata: Dict = {
            'calculation_time': None,
            'total_stocks': 0,
            'total_industries': 0,
            'cache_hit_rate': 0,
            'performance_metrics': {}
        }
        self.last_updated = datetime.now()
    
    def get_top_stocks(self, metric: str = 'rtsi', top_n: int = 50, large_cap_only: bool = True) -> List[Tuple[str, str, float]]:
        """è·å–æŒ‡å®šæŒ‡æ ‡çš„å‰Nåªè‚¡ç¥¨
        
        Args:
            metric: æŒ‡æ ‡åç§°
            top_n: è¿”å›æ•°é‡
            large_cap_only: æ˜¯å¦åªè¿”å›å¤§ç›˜è‚¡
        """
        try:
            stock_scores = []
            for code, data in self.stocks.items():
                if metric in data and data[metric] is not None:
                    # å¤§ç›˜è‚¡ç­›é€‰ï¼šåªæ¨èå¤§ç›˜è‚¡
                    if large_cap_only and not self._is_large_cap_stock(code):
                        continue
                    
                    # ä¿®å¤ï¼šæ­£ç¡®æå–RTSIåˆ†æ•°
                    if isinstance(data[metric], dict):
                        if metric == 'rtsi':
                            # ä½¿ç”¨å›½é™…åŒ–é”®åè·å–RTSIå€¼
                            # t_rtsi å·²åœ¨æ–‡ä»¶å¼€å¤´å®šä¹‰
                            score = data[metric].get(t_rtsi('rtsi'), data[metric].get('RTSI', data[metric].get('rtsi', 0)))
                        else:
                            score = data[metric].get('value', 0)  # å…¶ä»–æŒ‡æ ‡å¯èƒ½å­˜å‚¨åœ¨'value'å­—æ®µ
                    else:
                        score = data[metric]
                    
                    # å¤„ç†numpyç±»å‹
                    import numpy as np
                    if isinstance(score, (np.number, np.integer, np.floating)):
                        score = float(score)
                    elif not isinstance(score, (int, float)):
                        score = 0.0
                    
                    stock_scores.append((code, data.get('name', ''), score))
            
            stock_scores.sort(key=lambda x: x[2], reverse=True)
            return stock_scores[:top_n]
        except Exception as e:
            logger.error(f"è·å–top stockså¤±è´¥: {e}")
            return []
    
    def _is_large_cap_stock(self, stock_code: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¤§ç›˜è‚¡
        
        åŸºäºè‚¡ç¥¨ä»£ç å‰ç¼€å’Œå·²çŸ¥çš„å¤§ç›˜è‚¡è§„å¾‹åˆ¤æ–­ï¼š
        - Aè‚¡ï¼šä»¥00ã€60å¼€å¤´çš„é€šå¸¸æ˜¯å¤§ç›˜è‚¡
        - æ¸¯è‚¡ï¼š00700(è…¾è®¯)ã€00939(å»ºè®¾é“¶è¡Œ)ç­‰çŸ¥åå¤§ç›˜è‚¡
        - ç¾è‚¡ï¼šAAPLã€MSFTã€GOOGLç­‰çŸ¥åå¤§å…¬å¸
        """
        code = str(stock_code).strip()
        
        # Aè‚¡å¤§ç›˜è‚¡åˆ¤æ–­
        if len(code) == 6 and code.isdigit():
            # ä¸»æ¿è‚¡ç¥¨é€šå¸¸æ˜¯å¤§ç›˜è‚¡
            if code.startswith('00') or code.startswith('60'):
                return True
            # éƒ¨åˆ†æ·±å¸‚ä¸»æ¿å¤§ç›˜è‚¡ï¼ˆ001ã€002å¼€å¤´çš„éƒ¨åˆ†è‚¡ç¥¨ï¼‰
            if code.startswith('001') or code.startswith('002'):
                # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´ç²¾ç¡®çš„åˆ¤æ–­é€»è¾‘
                return True
        
        # æ¸¯è‚¡å¤§ç›˜è‚¡åˆ¤æ–­ï¼ˆ5ä½æ•°å­—ï¼‰
        elif len(code) == 5 and code.isdigit():
            # çŸ¥åæ¸¯è‚¡å¤§ç›˜è‚¡ä»£ç 
            large_cap_hk_codes = {
                '00700', '00939', '00388', '00005', '00001', '00002', '00003', '00004',
                '00011', '00012', '00016', '00017', '00019', '00023', '00027', '00066',
                '00083', '00101', '00135', '00144', '00151', '00175', '00267', '00288',
                '00386', '00688', '00762', '00823', '00857', '00883', '00941', '00992',
                '01038', '01044', '01088', '01093', '01109', '01113', '01171', '01177',
                '01299', '01398', '01818', '01928', '01997', '02007', '02018', '02020',
                '02202', '02318', '02319', '02382', '02388', '02628', '03328', '03988'
            }
            return code in large_cap_hk_codes
        
        # ç¾è‚¡å¤§ç›˜è‚¡åˆ¤æ–­ï¼ˆå­—æ¯ä»£ç ï¼‰
        elif code.isalpha():
            # çŸ¥åç¾è‚¡å¤§ç›˜è‚¡ä»£ç 
            large_cap_us_codes = {
                'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'TSLA', 'META', 'NVDA',
                'BRK.A', 'BRK.B', 'UNH', 'JNJ', 'JPM', 'V', 'PG', 'HD', 'MA', 'PFE',
                'ABBV', 'BAC', 'KO', 'AVGO', 'PEP', 'TMO', 'COST', 'DIS', 'ABT',
                'MRK', 'ACN', 'VZ', 'CRM', 'DHR', 'ADBE', 'NKE', 'TXN', 'LIN',
                'WMT', 'NEE', 'AMD', 'BMY', 'PM', 'RTX', 'QCOM', 'HON', 'T',
                'UPS', 'ORCL', 'COP', 'MS', 'SCHW', 'LOW', 'CAT', 'GS', 'IBM',
                'AXP', 'BLK', 'DE', 'ELV', 'LMT', 'SYK', 'TJX', 'MDT', 'ADP',
                'GE', 'C', 'MDLZ', 'ISRG', 'REGN', 'CB', 'MMC', 'SO', 'PLD',
                'NOW', 'ZTS', 'ICE', 'DUK', 'SHW', 'CMG', 'WM', 'GD', 'TGT',
                'BDX', 'ITW', 'EOG', 'FIS', 'NSC', 'SRE', 'MU', 'BSX', 'FCX'
            }
            return code.upper() in large_cap_us_codes
        
        # é»˜è®¤ä¸æ˜¯å¤§ç›˜è‚¡
        return False
    
    def get_top_industries(self, metric: str = 'irsi', top_n: int = 20) -> List[Tuple[str, float]]:
        """è·å–æŒ‡å®šæŒ‡æ ‡çš„å‰Nä¸ªè¡Œä¸š"""
        try:
            industry_scores = []
            for industry, data in self.industries.items():
                if metric in data and data[metric] is not None:
                    # ä¿®å¤ï¼šæ­£ç¡®æå–IRSIåˆ†æ•°
                    if isinstance(data[metric], dict):
                        if metric == 'irsi':
                            score = data[metric].get('irsi', 0)  # IRSIå­˜å‚¨åœ¨'irsi'å­—æ®µ
                        else:
                            score = data[metric].get('value', 0)  # å…¶ä»–æŒ‡æ ‡å¯èƒ½å­˜å‚¨åœ¨'value'å­—æ®µ
                    else:
                        score = data[metric]
                    
                    # å¤„ç†numpyç±»å‹
                    import numpy as np
                    if isinstance(score, (np.number, np.integer, np.floating)):
                        score = float(score)
                    elif not isinstance(score, (int, float)):
                        score = 0.0
                    
                    industry_scores.append((industry, score))
            
            industry_scores.sort(key=lambda x: x[1], reverse=True)
            return industry_scores[:top_n]
        except Exception as e:
            logger.error(f"è·å–top industrieså¤±è´¥: {e}")
            return []
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'stocks': self.stocks,
            'industries': self.industries,
            'market': self.market,
            'metadata': self.metadata,
            'last_updated': self.last_updated.isoformat()
        }


class RealtimeAnalysisEngine:
    """
    å®æ—¶åˆ†æå¼•æ“
    
    åŠŸèƒ½ç‰¹æ€§:
    - æ•´åˆRTSIã€IRSIã€MSCIä¸‰å¤§ç®—æ³•
    - æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®— (å¯é…ç½®å¼€å…³)
    - æ™ºèƒ½ç¼“å­˜æœºåˆ¶
    - å®æ—¶æ€§èƒ½ç›‘æ§
    - å¢é‡è®¡ç®—æ”¯æŒ
    """
    
    def __init__(self, data_source: StockDataSet, enable_multithreading: bool = True, enable_enhanced_tma: bool = True):
        """
        åˆå§‹åŒ–å®æ—¶åˆ†æå¼•æ“
        
        Args:
            data_source: è‚¡ç¥¨æ•°æ®æº
            enable_multithreading: æ˜¯å¦å¯ç”¨å¤šçº¿ç¨‹è®¡ç®—
            enable_enhanced_tma: æ˜¯å¦å¯ç”¨å¢å¼ºTMAåˆ†æ
        """
        self.data_source = data_source
        self.enable_multithreading = enable_multithreading
        self.enable_enhanced_tma = enable_enhanced_tma and ENHANCED_TMA_AVAILABLE
        self.results_cache: Optional[AnalysisResults] = None
        self.last_calculation_time: Optional[datetime] = None
        self.calculation_lock = threading.Lock()
        
        # åˆå§‹åŒ–å¢å¼ºTMAåˆ†æå™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.enable_enhanced_tma:
            try:
                self.enhanced_tma_analyzer = EnhancedTMAAnalyzer(
                    enable_ai_enhancement=False,  # æ ¹æ®æµ‹è¯•ç»“æœå…³é—­AIå¢å¼º
                    min_credibility=0.2,  # æœ€ä½³å¯ä¿¡åº¦é˜ˆå€¼
                    max_interpolation_ratio=0.5,  # æœ€ä½³æ’å€¼æ¯”ä¾‹
                    min_stocks_per_industry=2  # æœ€å°è‚¡ç¥¨æ•°
                )
                logger.info("å¢å¼ºTMAåˆ†æå™¨å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"å¢å¼ºTMAåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼: {e}")
                self.enable_enhanced_tma = False
        
        # åˆå§‹åŒ–æ™ºèƒ½RTSIè®¡ç®—å™¨
        # å…ˆåˆå§‹åŒ–æ‰€æœ‰å±æ€§ä¸ºNone
        self.smart_rtsi_calculator = None
        self.enhanced_rtsi_calculator = None
        
        try:
            from .smart_rtsi_algorithm import get_smart_rtsi_calculator
            # åœ¨å¤šçº¿ç¨‹æ¨¡å¼ä¸‹ç¦ç”¨ç¼“å­˜ä»¥é¿å…AKShareå»¶è¿Ÿ
            enable_cache = not enable_multithreading
            self.smart_rtsi_calculator = get_smart_rtsi_calculator(enable_cache=enable_cache, verbose=False)
            logger.info(f"æ™ºèƒ½RTSIè®¡ç®—å™¨å·²å¯ç”¨ (ç¼“å­˜: {enable_cache})")
        except Exception as e:
            logger.warning(f"æ™ºèƒ½RTSIè®¡ç®—å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            
        # æ€»æ˜¯åˆå§‹åŒ–å¢å¼ºRTSIè®¡ç®—å™¨ï¼Œç”¨äºæ‰¹é‡è®¡ç®—
        try:
            self.enhanced_rtsi_calculator = EnhancedRTSICalculator()
            logger.info("å¢å¼ºRTSIè®¡ç®—å™¨å·²å¯ç”¨")
        except Exception as e2:
            logger.warning(f"å¢å¼ºRTSIè®¡ç®—å™¨åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ¨¡å¼: {e2}")
        
        # é…ç½®å‚æ•° - ä¼˜åŒ–æ€§èƒ½è®¾ç½®
        try:
            self.config = get_config('engine', {
                'cache_ttl': 600,  # å¢åŠ ç¼“å­˜æ—¶é—´åˆ°10åˆ†é’Ÿ
                'max_workers': 4,  # é€‚å½“å¢åŠ çº¿ç¨‹æ•°ä»¥æé«˜å¹¶è¡Œåº¦
                'chunk_size': 100, # å¢åŠ æ‰¹å¤„ç†å¤§å°
                'timeout': 180     # é€‚å½“çš„è¶…æ—¶æ—¶é—´
            })
            # å¦‚æœget_configè¿”å›Noneï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            if self.config is None:
                self.config = {
                    'cache_ttl': 600,
                    'max_workers': 4,
                    'chunk_size': 100,
                    'timeout': 180
                }
        except Exception:
            # å¦‚æœé…ç½®è·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
            self.config = {
                'cache_ttl': 600,
                'max_workers': 4,
                'chunk_size': 100,
                'timeout': 180
            }
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_stats = {
            'total_calculations': 0,
            'avg_calculation_time': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'errors': 0
        }
        
        logger.info(f"å®æ—¶åˆ†æå¼•æ“åˆå§‹åŒ–å®Œæˆ (å¤šçº¿ç¨‹: {enable_multithreading})")
    
    def _detect_market_type(self, stock_data: Dict[str, Any]) -> str:
        """æ£€æµ‹è‚¡ç¥¨æ‰€å±å¸‚åœºç±»å‹"""
        try:
            # ä¼˜å…ˆä»æ•°æ®æºçš„æ–‡ä»¶è·¯å¾„åˆ¤æ–­
            if hasattr(self.data_source, 'file_path') and self.data_source.file_path:
                file_name = os.path.basename(self.data_source.file_path).lower()
                if file_name.startswith('cn'):
                    return 'cn'
                elif file_name.startswith('hk'):
                    return 'hk'
                elif file_name.startswith('us'):
                    return 'us'
            
            # ä»è‚¡ç¥¨ä»£ç æ ¼å¼åˆ¤æ–­
            stock_code = str(stock_data.get('è‚¡ç¥¨ä»£ç ', ''))
            if stock_code:
                # ä¸­å›½è‚¡ç¥¨ï¼š6ä½æ•°å­—
                if len(stock_code) == 6 and stock_code.isdigit():
                    return 'cn'
                # é¦™æ¸¯è‚¡ç¥¨ï¼š5ä½æ•°å­—ï¼ˆé€šå¸¸å‰é¢è¡¥0åˆ°6ä½ï¼‰
                elif len(stock_code) == 6 and stock_code.startswith('00') and stock_code[2:].isdigit():
                    return 'hk'
                # ç¾å›½è‚¡ç¥¨ï¼šå­—æ¯+æ•°å­—ç»„åˆ
                elif not stock_code.isdigit():
                    return 'us'
            
            # é»˜è®¤è¿”å›ä¸­å›½å¸‚åœº
            return 'cn'
            
        except Exception as e:
            logger.debug(f"å¸‚åœºç±»å‹æ£€æµ‹å¤±è´¥: {e}")
            return 'cn'
    
    def calculate_all_metrics(self, force_refresh: bool = False, enable_emergency_timeout: bool = True) -> AnalysisResults:
        """
        è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        
        Args:
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
            
        Returns:
            å®Œæ•´çš„åˆ†æç»“æœ
        """
        start_time = time.time()
        
        with self.calculation_lock:
            # æ£€æŸ¥ç¼“å­˜
            if not force_refresh and self._is_cache_valid():
                self.performance_stats['cache_hits'] += 1
                logger.info("ä½¿ç”¨ç¼“å­˜ç»“æœ")
                return self.results_cache
            
            self.performance_stats['cache_misses'] += 1
            logger.info("å¼€å§‹å®Œæ•´è®¡ç®—...")
            
            try:
                # è·å–æ•°æ®
                raw_data = self.data_source.get_raw_data()
                if raw_data is None or raw_data.empty:
                    raise ValueError("æ•°æ®æºä¸ºç©º")
                
                # åˆ›å»ºç»“æœå¯¹è±¡
                results = AnalysisResults()
                
                # ç´§æ€¥è¶…æ—¶æ£€æŸ¥
                if enable_emergency_timeout:
                    emergency_timeout = 180  # 3åˆ†é’Ÿç´§æ€¥è¶…æ—¶
                    logger.info(f"å¯ç”¨ç´§æ€¥è¶…æ—¶æœºåˆ¶: {emergency_timeout}ç§’")
                
                # å¤šçº¿ç¨‹æˆ–å•çº¿ç¨‹è®¡ç®—
                calculation_start = time.time()
                if self.enable_multithreading:
                    results = self._calculate_multithreaded(raw_data, results)
                else:
                    results = self._calculate_single_threaded(raw_data, results)
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡ç´§æ€¥è¶…æ—¶
                if enable_emergency_timeout and (time.time() - calculation_start) > emergency_timeout:
                    logger.warning(f"è®¡ç®—è¶…è¿‡ç´§æ€¥è¶…æ—¶æ—¶é—´ {emergency_timeout}ç§’ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜")
                    # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œä½†è®°å½•è­¦å‘Š
                
                # æ›´æ–°ç¼“å­˜å’Œç»Ÿè®¡
                self.results_cache = results
                self.last_calculation_time = datetime.now()
                self.performance_stats['total_calculations'] += 1
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                calculation_time = time.time() - start_time
                self._update_performance_stats(calculation_time)
                
                results.metadata['calculation_time'] = calculation_time
                results.metadata['total_stocks'] = len(results.stocks)
                results.metadata['total_industries'] = len(results.industries)
                results.metadata['cache_hit_rate'] = self._get_cache_hit_rate()
                results.metadata['performance_metrics'] = self.performance_stats.copy()
                
                logger.info(f"è®¡ç®—å®Œæˆ: {len(results.stocks)}åªè‚¡ç¥¨, {len(results.industries)}ä¸ªè¡Œä¸š, è€—æ—¶{calculation_time:.2f}ç§’")
                
                return results
                
            except Exception as e:
                self.performance_stats['errors'] += 1
                logger.error(f"è®¡ç®—å¤±è´¥: {e}")
                raise
    
    def _calculate_multithreaded(self, raw_data: pd.DataFrame, results: AnalysisResults) -> AnalysisResults:
        """å¤šçº¿ç¨‹è®¡ç®—æ¨¡å¼"""
        logger.info("ä½¿ç”¨å¤šçº¿ç¨‹è®¡ç®—æ¨¡å¼")
        
        # 1. å¤šçº¿ç¨‹è®¡ç®—ä¸ªè‚¡RTSI
        results.stocks = self._calculate_stocks_rtsi_parallel(raw_data)
        
        # 2. è®¡ç®—è¡Œä¸šIRSI (åŸºäºå·²è®¡ç®—çš„ä¸ªè‚¡ç»“æœ)
        results.industries = self._calculate_industries_irsi(raw_data, results.stocks)
        
        # 3. è®¡ç®—å¸‚åœºMSCI
        results.market = self._calculate_market_msci(raw_data)
        
        return results
    
    def _calculate_single_threaded(self, raw_data: pd.DataFrame, results: AnalysisResults) -> AnalysisResults:
        """å•çº¿ç¨‹è®¡ç®—æ¨¡å¼"""
        logger.info("ä½¿ç”¨å•çº¿ç¨‹è®¡ç®—æ¨¡å¼")
        
        # 1. è®¡ç®—ä¸ªè‚¡RTSI
        results.stocks = self._calculate_stocks_rtsi_sequential(raw_data)
        
        # 2. è®¡ç®—è¡Œä¸šIRSI
        results.industries = self._calculate_industries_irsi(raw_data, results.stocks)
        
        # 3. è®¡ç®—å¸‚åœºMSCI
        results.market = self._calculate_market_msci(raw_data)
        
        return results
    
    def _calculate_stocks_rtsi_parallel(self, raw_data: pd.DataFrame) -> Dict[str, Dict]:
        """å¤šçº¿ç¨‹å¹¶è¡Œè®¡ç®—ä¸ªè‚¡RTSIï¼ˆæ”¯æŒARTSç®—æ³•ï¼‰"""
        stocks_results = {}
        date_columns = [col for col in raw_data.columns if str(col).startswith('202')]
        
        # å¯¼å…¥ARTSç®—æ³•ä½œä¸ºåå¤‡
        try:
            from algorithms.arts_calculator import ARTSCalculator
            arts_calculator = ARTSCalculator()
            arts_available = True
        except ImportError:
            logger.warning("âš ï¸ ARTSç®—æ³•ä¸å¯ç”¨")
            arts_available = False
            arts_calculator = None
        
        logger.info("ğŸ“Š å¹¶è¡Œæ¨¡å¼ä½¿ç”¨RTSIç®—æ³•è¿›è¡Œä¸ªè‚¡åˆ†æï¼ˆä¸»ç®—æ³•ï¼‰")
        
        def calculate_single_stock(stock_data):
            try:
                stock_code = str(stock_data['è‚¡ç¥¨ä»£ç '])
                stock_name = stock_data.get('è‚¡ç¥¨åç§°', '')
                industry = stock_data.get('è¡Œä¸š', 'æœªåˆ†ç±»')
                
                # ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½RTSIç®—æ³•ï¼ˆä¸»ç®—æ³•ï¼‰
                rtsi_success = False
                
                # è®¡ç®—RTSI - ä½¿ç”¨æ™ºèƒ½RTSIè®¡ç®—å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if hasattr(self, 'smart_rtsi_calculator') and self.smart_rtsi_calculator is not None:
                    try:
                        # ç¡®å®šå¸‚åœºç±»å‹
                        market = self._detect_market_type(stock_data)
                        
                        # ä½¿ç”¨æ™ºèƒ½RTSIè®¡ç®—å™¨
                        rtsi_result = self.smart_rtsi_calculator.calculate_smart_rtsi(
                            stock_data, 
                            market=market, 
                            stock_code=stock_code
                        )
                        rtsi_success = True
                        logger.debug(f"æ™ºèƒ½RTSIè®¡ç®—æˆåŠŸ {stock_code}: {rtsi_result.get('algorithm', 'unknown')}")
                    except Exception as e:
                        # é™é»˜å¤„ç†æ™ºèƒ½RTSIè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°å¢å¼ºRTSI
                        logger.debug(f"æ™ºèƒ½RTSIè®¡ç®—å¤±è´¥ {stock_code}: {e}")
                        rtsi_success = False
                
                # å¦‚æœæ™ºèƒ½RTSIå¤±è´¥ï¼Œå°è¯•å¢å¼ºRTSI
                if not rtsi_success and hasattr(self, 'enhanced_rtsi_calculator') and self.enhanced_rtsi_calculator is not None:
                    try:
                        # ä½¿ç”¨å¢å¼ºRTSIè®¡ç®—å™¨
                        rtsi_enhanced_result = self.enhanced_rtsi_calculator.batch_calculate_enhanced_rtsi(
                            pd.DataFrame([stock_data])
                        )
                        if stock_code in rtsi_enhanced_result:
                            rtsi_result = rtsi_enhanced_result[stock_code]
                            rtsi_success = True
                        else:
                            raise Exception("å¢å¼ºRTSIæ‰¹é‡è®¡ç®—æœªè¿”å›ç»“æœ")
                    except Exception as e:
                        # é™é»˜å¤„ç†å¢å¼ºRTSIè®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†RTSI
                        logger.debug(f"å¢å¼ºRTSIè®¡ç®—å¤±è´¥ {stock_code}: {e}")
                        rtsi_success = False
                
                # å¦‚æœæ™ºèƒ½RTSIå’Œå¢å¼ºRTSIéƒ½å¤±è´¥ï¼Œå°è¯•æ ‡å‡†RTSI
                if not rtsi_success:
                    try:
                        # ä½¿ç”¨AIå¢å¼ºRTSIä½œä¸ºä¸»ç®—æ³•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
                        ratings = stock_data[date_columns]
                        rtsi_result = calculate_rating_trend_strength_index(
                            ratings, 
                            stock_code=stock_code,
                            stock_name=stock_name,
                            enable_ai=True  # ç¡®ä¿ä½¿ç”¨AIå¢å¼ºä¸»ç®—æ³•
                        )
                        rtsi_success = True
                    except Exception as e:
                        logger.warning(f"æ ‡å‡†RTSIè®¡ç®—å¤±è´¥ {stock_code}: {e}")
                        rtsi_success = False
                
                # å¦‚æœRTSIå¤±è´¥ä¸”ARTSå¯ç”¨ï¼Œä½¿ç”¨ARTSä½œä¸ºåå¤‡
                if not rtsi_success and arts_available:
                    try:
                        logger.info(f"ğŸ”„ {stock_code} å¹¶è¡Œæ¨¡å¼ä½¿ç”¨ARTSåå¤‡ç®—æ³•")
                        ratings = stock_data[date_columns]
                        arts_result = arts_calculator.calculate_arts(ratings, stock_code)
                        
                        # å°†ARTSç»“æœè½¬æ¢ä¸ºå…¼å®¹RTSIçš„æ ¼å¼
                        rtsi_result = {
                            'rtsi': arts_result.get('arts_score', 0),
                            'trend': arts_result.get('trend_direction', 'unknown'),
                            'confidence': arts_result.get('confidence_level', 'unknown'),
                            'pattern': arts_result.get('trend_pattern', 'unknown'),
                            'rating_level': arts_result.get('rating_level', 'unknown'),
                            'recommendation': arts_result.get('recommendation', ''),
                            'algorithm': 'ARTS_v1.0_backup',
                            'recent_score': arts_result.get('recent_rating'),
                            'data_points': arts_result.get('data_points', 0)
                        }
                        rtsi_success = True
                    except Exception as e:
                        logger.error(f"ARTSåå¤‡ç®—æ³•ä¹Ÿå¤±è´¥ {stock_code}: {e}")
                
                # å¦‚æœæ‰€æœ‰ç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ
                if not rtsi_success:
                    rtsi_result = {
                        'rtsi': 0,
                        'trend': 'unknown',
                        'confidence': 0,
                        'algorithm': 'fallback',
                        'recent_score': None,
                        'data_points': 0
                    }
                
                return stock_code, {
                    'name': stock_name,
                    'industry': industry,
                    'rtsi': rtsi_result,
                    'last_score': rtsi_result.get('recent_score'),
                    'trend': rtsi_result.get('trend', 'unknown')
                }
            except Exception as e:
                logger.warning(f"è®¡ç®—è‚¡ç¥¨RTSIå¤±è´¥ {stock_data.get('è‚¡ç¥¨ä»£ç ', 'unknown')}: {e}")
                return None, None
        
        # å¤šçº¿ç¨‹æ‰§è¡Œ - å¢å¼ºé”™è¯¯å¤„ç†å’Œè¿›åº¦ç›‘æ§
        total_stocks = len(raw_data)
        max_workers = min(self.config['max_workers'], total_stocks, 6)  # é€‚å½“å¢åŠ çº¿ç¨‹æ•°ä¸Šé™
        logger.info(f"å¯åŠ¨å¤šçº¿ç¨‹è®¡ç®—: {total_stocks}åªè‚¡ç¥¨, {max_workers}ä¸ªçº¿ç¨‹")
        
        try:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # æäº¤ä»»åŠ¡
                futures = []
                for _, stock_data in raw_data.iterrows():
                    future = executor.submit(calculate_single_stock, stock_data)
                    futures.append(future)
                
                logger.info(f"å·²æäº¤ {len(futures)} ä¸ªè®¡ç®—ä»»åŠ¡")
                
                # æ”¶é›†ç»“æœ - ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶æ—¶é—´å’Œé€‚åº¦çš„è¿›åº¦æŠ¥å‘Š
                completed = 0
                failed = 0
                timeout_per_batch = min(45, self.config['timeout'] // 8)  # æ¯æ‰¹æ¬¡æœ€å¤š45ç§’ï¼Œå‡å°‘è¶…æ—¶é¢‘ç‡
                
                for i, future in enumerate(futures):
                    try:
                        # ä½¿ç”¨é€‚ä¸­çš„è¶…æ—¶æ—¶é—´ï¼Œå¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§
                        stock_code, result = future.result(timeout=timeout_per_batch)
                        if stock_code and result:
                            stocks_results[stock_code] = result
                            completed += 1
                        else:
                            failed += 1
                        
                        # é€‚åº¦çš„è¿›åº¦æŠ¥å‘Šï¼Œå‡å°‘æ—¥å¿—è¾“å‡ºå¼€é”€
                        if (i + 1) % 100 == 0 or (i + 1) == len(futures):
                            progress = ((i + 1) / len(futures)) * 100
                            logger.info(f"è®¡ç®—è¿›åº¦: {progress:.1f}% ({i + 1}/{len(futures)}) - æˆåŠŸ:{completed}, å¤±è´¥:{failed}")
                            
                    except Exception as e:
                        failed += 1
                        if failed % 50 == 0:  # åªåœ¨å¤±è´¥æ•°é‡è¾¾åˆ°ä¸€å®šç¨‹åº¦æ—¶è®°å½•
                            logger.warning(f"ä»»åŠ¡å¤±è´¥æ•°é‡: {failed}, æœ€æ–°å¤±è´¥: {e}")
                        # ç»§ç»­å¤„ç†å…¶ä»–ä»»åŠ¡ï¼Œä¸è¦å› ä¸ºå•ä¸ªä»»åŠ¡å¤±è´¥è€Œåœæ­¢
                
                logger.info(f"å¤šçº¿ç¨‹è®¡ç®—å®Œæˆ: æ€»è®¡{len(futures)}åªè‚¡ç¥¨, æˆåŠŸ{completed}åª, å¤±è´¥{failed}åª")
                
        except Exception as e:
            logger.error(f"å¤šçº¿ç¨‹æ‰§è¡Œå¼‚å¸¸: {e}")
            # å¦‚æœå¤šçº¿ç¨‹å®Œå…¨å¤±è´¥ï¼Œå›é€€åˆ°å•çº¿ç¨‹æ¨¡å¼
            logger.info("å›é€€åˆ°å•çº¿ç¨‹æ¨¡å¼...")
            return self._calculate_stocks_rtsi_sequential(raw_data)
        
        return stocks_results
    
    def _calculate_stocks_rtsi_sequential(self, raw_data: pd.DataFrame) -> Dict[str, Dict]:
        """å•çº¿ç¨‹é¡ºåºè®¡ç®—ä¸ªè‚¡RTSI"""
        stocks_results = {}
        date_columns = [col for col in raw_data.columns if str(col).startswith('202')]
        
        # å¯¼å…¥ARTSç®—æ³•ä½œä¸ºåå¤‡
        try:
            from algorithms.arts_calculator import ARTSCalculator
            arts_calculator = ARTSCalculator()
            arts_available = True
        except ImportError:
            logger.warning("âš ï¸ ARTSç®—æ³•ä¸å¯ç”¨")
            arts_available = False
            arts_calculator = None
        
        # å¦‚æœæœ‰å¢å¼ºRTSIè®¡ç®—å™¨ï¼Œæ‰¹é‡è®¡ç®—ä»¥æé«˜æ•ˆç‡
        if self.enhanced_rtsi_calculator is not None:
            logger.info("ğŸ“Š å¼€å§‹æ‰¹é‡è®¡ç®—å¢å¼ºRTSI...")
            enhanced_results = self.enhanced_rtsi_calculator.batch_calculate_enhanced_rtsi(raw_data)
            logger.info(f"ğŸ“Š æ‰¹é‡è®¡ç®—å®Œæˆï¼ŒæˆåŠŸè®¡ç®— {len(enhanced_results)} åªè‚¡ç¥¨")
            logger.info("ğŸ“Š ä½¿ç”¨RTSIç®—æ³•è¿›è¡Œä¸ªè‚¡åˆ†æï¼ˆä¸»ç®—æ³•ï¼‰")
        else:
            enhanced_results = {}
            logger.info("ğŸ“Š ä½¿ç”¨RTSIç®—æ³•è¿›è¡Œä¸ªè‚¡åˆ†æï¼ˆæ ‡å‡†æ¨¡å¼ï¼‰")
        
        total_stocks = len(raw_data)
        logger.info(f"å¼€å§‹é€ä¸ªè‚¡ç¥¨è®¡ç®—: {total_stocks}åªè‚¡ç¥¨")
        
        for idx, stock_data in raw_data.iterrows():
            try:
                stock_code = str(stock_data['è‚¡ç¥¨ä»£ç '])
                stock_name = stock_data.get('è‚¡ç¥¨åç§°', '')
                industry = stock_data.get('è¡Œä¸š', 'æœªåˆ†ç±»')
                
                # è¿›åº¦æŠ¥å‘Š
                if (idx + 1) % 100 == 0 or (idx + 1) == total_stocks:
                    progress = ((idx + 1) / total_stocks) * 100
                    logger.info(f"é€ä¸ªè‚¡ç¥¨è®¡ç®—è¿›åº¦: {progress:.1f}% ({idx + 1}/{total_stocks})")
                
                # ä¼˜å…ˆä½¿ç”¨RTSIç®—æ³•ï¼ˆä¸»ç®—æ³•ï¼‰
                rtsi_success = False
                
                # è®¡ç®—RTSI - ä¼˜å…ˆä½¿ç”¨å¢å¼ºç»“æœ
                if stock_code in enhanced_results:
                    rtsi_result = enhanced_results[stock_code]
                    rtsi_success = True
                else:
                    try:
                        # ä½¿ç”¨AIå¢å¼ºRTSIä½œä¸ºä¸»ç®—æ³•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
                        ratings = stock_data[date_columns]
                        rtsi_result = calculate_rating_trend_strength_index(
                            ratings, 
                            stock_code=stock_code,
                            stock_name=stock_name,
                            enable_ai=True  # ç¡®ä¿ä½¿ç”¨AIå¢å¼ºä¸»ç®—æ³•
                        )
                        rtsi_success = True
                    except Exception as e:
                        logger.debug(f"RTSIç®—æ³•è®¡ç®—å¤±è´¥ {stock_code}: {e}")
                        rtsi_success = False
                
                # å¦‚æœRTSIå¤±è´¥ä¸”ARTSå¯ç”¨ï¼Œä½¿ç”¨ARTSä½œä¸ºåå¤‡
                if not rtsi_success and arts_available:
                    try:
                        logger.info(f"ğŸ”„ {stock_code} ä½¿ç”¨ARTSåå¤‡ç®—æ³•")
                        ratings = stock_data[date_columns]
                        arts_result = arts_calculator.calculate_arts(ratings, stock_code)
                        
                        # å°†ARTSç»“æœè½¬æ¢ä¸ºå…¼å®¹RTSIçš„æ ¼å¼
                        rtsi_result = {
                            'rtsi': arts_result.get('arts_score', 0),
                            'trend': arts_result.get('trend_direction', 'unknown'),
                            'confidence': arts_result.get('confidence_level', 'unknown'),
                            'pattern': arts_result.get('trend_pattern', 'unknown'),
                            'rating_level': arts_result.get('rating_level', 'unknown'),
                            'recommendation': arts_result.get('recommendation', ''),
                            'algorithm': 'ARTS_v1.0_backup',
                            'recent_score': arts_result.get('recent_rating'),
                            'data_points': arts_result.get('data_points', 0)
                        }
                        rtsi_success = True
                    except Exception as e:
                        logger.error(f"ARTSåå¤‡ç®—æ³•ä¹Ÿå¤±è´¥ {stock_code}: {e}")
                
                # å¦‚æœæ‰€æœ‰ç®—æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ
                if not rtsi_success:
                    rtsi_result = {
                        'rtsi': 0,
                        'trend': 'unknown',
                        'confidence': 0,
                        'algorithm': 'fallback',
                        'recent_score': None,
                        'data_points': 0
                    }
                
                stocks_results[stock_code] = {
                    'name': stock_name,
                    'industry': industry,
                    'rtsi': rtsi_result,
                    'last_score': rtsi_result.get('recent_score'),
                    'trend': rtsi_result.get('trend', 'unknown')
                }
                
                if (idx + 1) % 100 == 0:
                    logger.info(f"å·²å®Œæˆ {idx + 1}/{len(raw_data)} åªè‚¡ç¥¨è®¡ç®—")
                    
            except Exception as e:
                logger.warning(f"è®¡ç®—è‚¡ç¥¨RTSIå¤±è´¥ {stock_data.get('è‚¡ç¥¨ä»£ç ', 'unknown')}: {e}")
        
        return stocks_results
    
    def _calculate_industries_irsi(self, raw_data: pd.DataFrame, stocks_results: Dict) -> Dict[str, Dict]:
        """è®¡ç®—è¡Œä¸šIRSIï¼ˆæ”¯æŒå¢å¼ºTMAï¼‰"""
        industries_results = {}
        
        # æŒ‰è¡Œä¸šåˆ†ç»„
        industries = raw_data['è¡Œä¸š'].dropna().unique()
        
        # é€‰æ‹©åˆ†ææ–¹æ³•
        if self.enable_enhanced_tma:
            logger.info("ä½¿ç”¨å¢å¼ºTMAåˆ†æè¡Œä¸šå¼ºåŠ¿")
            try:
                # ä½¿ç”¨å¢å¼ºTMAåˆ†æå™¨è¿›è¡Œæ‰¹é‡åˆ†æ
                enhanced_results = self.enhanced_tma_analyzer.batch_analyze_industries_enhanced(raw_data)
                
                for industry in industries:
                    if industry in enhanced_results:
                        enhanced_result = enhanced_results[industry]
                        
                        # ç»Ÿè®¡è¡Œä¸šå†…è‚¡ç¥¨ä¿¡æ¯
                        industry_data = raw_data[raw_data['è¡Œä¸š'] == industry]
                        industry_stocks = []
                        for _, stock in industry_data.iterrows():
                            stock_code = str(stock['è‚¡ç¥¨ä»£ç '])
                            if stock_code in stocks_results:
                                industry_stocks.append({
                                    'code': stock_code,
                                    'name': stocks_results[stock_code]['name'],
                                    'rtsi': stocks_results[stock_code]['rtsi'].get('rtsi', 0)
                                })
                        
                        # æ„å»ºå¢å¼ºç»“æœ
                        industries_results[industry] = {
                            'irsi': enhanced_result,  # åŒ…å«æ‰€æœ‰å¢å¼ºä¿¡æ¯
                            'stock_count': len(industry_stocks),
                            'stocks': industry_stocks,
                            'status': enhanced_result.get('enhanced_status', enhanced_result.get('status', 'unknown')),
                            'enhanced_tma': True,
                            'ai_enhanced': enhanced_result.get('ai_enhanced', False),
                            'credibility_info': enhanced_result.get('credibility_info', {}),
                            'risk_assessment': enhanced_result.get('risk_assessment', {})
                        }
                
                # è®°å½•å¢å¼ºåˆ†æç»Ÿè®¡
                if hasattr(self.enhanced_tma_analyzer, 'get_analysis_statistics'):
                    enhancement_stats = self.enhanced_tma_analyzer.get_analysis_statistics()
                    logger.info(f"å¢å¼ºTMAåˆ†æç»Ÿè®¡: {enhancement_stats}")
                
            except Exception as e:
                logger.error(f"å¢å¼ºTMAåˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸºç¡€æ¨¡å¼: {e}")
                self.enable_enhanced_tma = False  # ä¸´æ—¶å…³é—­å¢å¼ºæ¨¡å¼
        
        # åŸºç¡€IRSIåˆ†æï¼ˆä½œä¸ºå›é€€æˆ–æœªå¯ç”¨å¢å¼ºTMAæ—¶ä½¿ç”¨ï¼‰
        if not self.enable_enhanced_tma:
            logger.info("ä½¿ç”¨åŸºç¡€TMAåˆ†æè¡Œä¸šå¼ºåŠ¿")
            for industry in industries:
                try:
                    # è·å–è¡Œä¸šæ•°æ®
                    industry_data = raw_data[raw_data['è¡Œä¸š'] == industry]
                    
                    # è®¡ç®—è¡Œä¸šå¼ºåŠ¿åˆ†æ (ä½¿ç”¨æ ¸å¿ƒå¼ºåŠ¿åˆ†æå™¨)
                    irsi_result = calculate_industry_relative_strength(industry_data, raw_data, industry)
                    
                    # ç»Ÿè®¡è¡Œä¸šå†…è‚¡ç¥¨ä¿¡æ¯
                    industry_stocks = []
                    for _, stock in industry_data.iterrows():
                        stock_code = str(stock['è‚¡ç¥¨ä»£ç '])
                        if stock_code in stocks_results:
                            industry_stocks.append({
                                'code': stock_code,
                                'name': stocks_results[stock_code]['name'],
                                'rtsi': stocks_results[stock_code]['rtsi'].get('rtsi', 0)
                            })
                    
                    industries_results[industry] = {
                        'irsi': irsi_result,
                        'stock_count': len(industry_stocks),
                        'stocks': industry_stocks,  # ä¿å­˜æ‰€æœ‰è‚¡ç¥¨
                        'status': irsi_result.get('status', 'unknown'),
                        'enhanced_tma': False,
                        'ai_enhanced': False
                    }
                    
                except Exception as e:
                    logger.warning(f"è®¡ç®—è¡Œä¸šIRSIå¤±è´¥ {industry}: {e}")
        
        return industries_results
    
    def _calculate_market_msci(self, raw_data: pd.DataFrame) -> Dict:
        """è®¡ç®—å¸‚åœºMSCI"""
        try:
            msci_result = calculate_market_sentiment_composite_index(raw_data)
            return msci_result
        except Exception as e:
            logger.error(f"è®¡ç®—å¸‚åœºMSCIå¤±è´¥: {e}")
            return {'status': 'error', 'message': str(e)}
    
    def _is_cache_valid(self) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if not self.results_cache or not self.last_calculation_time:
            return False
        
        cache_age = (datetime.now() - self.last_calculation_time).total_seconds()
        return cache_age < self.config.get('cache_ttl', 300)
    
    def _update_performance_stats(self, calculation_time: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        total = self.performance_stats['total_calculations']
        current_avg = self.performance_stats['avg_calculation_time']
        
        # è®¡ç®—æ–°çš„å¹³å‡æ—¶é—´
        new_avg = (current_avg * (total - 1) + calculation_time) / total
        self.performance_stats['avg_calculation_time'] = new_avg
    
    def _get_cache_hit_rate(self) -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        total_requests = self.performance_stats['cache_hits'] + self.performance_stats['cache_misses']
        if total_requests == 0:
            return 0
        return self.performance_stats['cache_hits'] / total_requests
    
    def update_analysis(self, new_data: pd.DataFrame) -> Dict:
        """
        å¢é‡æ›´æ–°åˆ†æç»“æœ
        
        Args:
            new_data: æ–°çš„æ•°æ®
            
        Returns:
            æ›´æ–°çŠ¶æ€ä¿¡æ¯
        """
        try:
            logger.info("å¼€å§‹å¢é‡æ›´æ–°åˆ†æ...")
            
            # æ›´æ–°æ•°æ®æº
            self.data_source.update_data(new_data)
            
            # å¼ºåˆ¶é‡æ–°è®¡ç®—
            results = self.calculate_all_metrics(force_refresh=True)
            
            return {
                'status': 'success',
                'updated_stocks': len(results.stocks),
                'updated_industries': len(results.industries),
                'update_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"å¢é‡æ›´æ–°å¤±è´¥: {e}")
            return {
                'status': 'error',
                'message': str(e),
                'update_time': datetime.now().isoformat()
            }
    
    def get_real_time_rankings(self) -> Dict:
        """è·å–å®æ—¶æ’å"""
        if not self.results_cache:
            logger.warning("æ²¡æœ‰å¯ç”¨çš„åˆ†æç»“æœ")
            return {}
        
        return {
            'top_stocks_by_rtsi': self.results_cache.get_top_stocks('rtsi', 20),
            'top_industries_by_irsi': self.results_cache.get_top_industries('irsi', 10),
            'market_sentiment': self.results_cache.market.get('current_msci', 0),
            'market_state': self.results_cache.market.get('market_state', 'unknown'),
            'last_updated': self.results_cache.last_updated.isoformat()
        }
    
    def detect_trend_changes(self) -> List[Dict]:
        """æ£€æµ‹è¶‹åŠ¿å˜åŒ–ä¿¡å·"""
        if not self.results_cache:
            return []
        
        signals = []
        
        try:
            # æ£€æµ‹ä¸ªè‚¡å¼ºåŠ¿åè½¬ä¿¡å·
            for stock_code, data in self.results_cache.stocks.items():
                rtsi_data = data.get('rtsi', {})
                rtsi_value = rtsi_data.get('rtsi', 0)
                trend = rtsi_data.get('trend', '')
                confidence = rtsi_data.get('confidence', 0)
                
                # å¼ºåŠ¿åè½¬ä¿¡å·
                if rtsi_value > 70 and trend in ['strong_up', 'weak_up'] and confidence > 0.7:
                    signals.append({
                        'type': 'stock_bullish',
                        'target': stock_code,
                        'name': data.get('name', ''),
                        'signal': f"å¼ºåŠ¿ä¸Šæ¶¨ä¿¡å· (RTSI: {rtsi_value:.2f})",
                        'confidence': confidence,
                        'timestamp': datetime.now().isoformat()
                    })
                
                # é£é™©é¢„è­¦ä¿¡å·
                elif rtsi_value < 20 and trend in ['strong_down', 'weak_down'] and confidence > 0.7:
                    signals.append({
                        'type': 'stock_bearish',
                        'target': stock_code,
                        'name': data.get('name', ''),
                        'signal': f"ä¸‹è·Œé£é™©é¢„è­¦ (RTSI: {rtsi_value:.2f})",
                        'confidence': confidence,
                        'timestamp': datetime.now().isoformat()
                    })
            
            # æ£€æµ‹è¡Œä¸šè½®åŠ¨ä¿¡å·
            for industry, data in self.results_cache.industries.items():
                irsi_data = data.get('irsi', {})
                irsi_value = irsi_data.get('irsi', 0)
                status = irsi_data.get('status', '')
                
                if irsi_value > 30 and status == 'strong_outperform':
                    signals.append({
                        'type': 'industry_rotation',
                        'target': industry,
                        'signal': f"è¡Œä¸šè½®åŠ¨ä¿¡å· (IRSI: {irsi_value:.2f})",
                        'stock_count': data.get('stock_count', 0),
                        'timestamp': datetime.now().isoformat()
                    })
            
            # æ£€æµ‹å¸‚åœºæƒ…ç»ªæç«¯ä¿¡å·
            market_state = self.results_cache.market.get('market_state', '')
            msci_value = self.results_cache.market.get('current_msci', 0)
            
            if market_state in ['euphoric', 'panic']:
                signals.append({
                    'type': 'market_extreme',
                    'target': 'market',
                    'signal': f"å¸‚åœºæƒ…ç»ªæç«¯: {market_state} (MSCI: {msci_value:.2f})",
                    'risk_level': self.results_cache.market.get('risk_level', 'unknown'),
                    'timestamp': datetime.now().isoformat()
                })
            
            logger.info(f"æ£€æµ‹åˆ° {len(signals)} ä¸ªè¶‹åŠ¿ä¿¡å·")
            return signals[:50]  # é™åˆ¶è¿”å›æ•°é‡
            
        except Exception as e:
            logger.error(f"è¶‹åŠ¿æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def cache_results(self) -> None:
        """æ‰‹åŠ¨ç¼“å­˜å½“å‰ç»“æœ"""
        if self.results_cache:
            # å¯ä»¥åœ¨è¿™é‡Œå®ç°æŒä¹…åŒ–ç¼“å­˜é€»è¾‘
            logger.info("ç»“æœå·²ç¼“å­˜")
    
    def get_performance_report(self) -> Dict:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        return {
            'engine_config': {
                'multithreading_enabled': self.enable_multithreading,
                'max_workers': self.config.get('max_workers', 4),
                'cache_ttl': self.config.get('cache_ttl', 300)
            },
            'performance_stats': self.performance_stats.copy(),
            'cache_status': {
                'is_cached': self.results_cache is not None,
                'cache_age': (datetime.now() - self.last_calculation_time).total_seconds() 
                            if self.last_calculation_time else None,
                'hit_rate': self._get_cache_hit_rate()
            },
            'last_calculation': self.last_calculation_time.isoformat() 
                              if self.last_calculation_time else None
        }


# ä¾¿æ·å‡½æ•°
def create_engine(data_source: StockDataSet, 
                  enable_multithreading: bool = True, 
                  enable_enhanced_tma: bool = True) -> RealtimeAnalysisEngine:
    """åˆ›å»ºå®æ—¶åˆ†æå¼•æ“å®ä¾‹"""
    return RealtimeAnalysisEngine(data_source, enable_multithreading, enable_enhanced_tma)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("-")
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„æµ‹è¯•é€»è¾‘
    try:
        from data.stock_dataset import StockDataset
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æº
        dataset = StockDataset("Aè‚¡æ•°æ®20250606.xlsx")
        
        # æµ‹è¯•å¤šçº¿ç¨‹å¼•æ“
        print("\n=== æµ‹è¯•å¤šçº¿ç¨‹å¼•æ“ ===")
        engine_mt = create_engine(dataset, enable_multithreading=True)
        start_time = time.time()
        results_mt = engine_mt.calculate_all_metrics()
        mt_time = time.time() - start_time
        print(f"å¤šçº¿ç¨‹è®¡ç®—è€—æ—¶: {mt_time:.2f}ç§’")
        print(f"è®¡ç®—è‚¡ç¥¨æ•°: {len(results_mt.stocks)}")
        print(f"è®¡ç®—è¡Œä¸šæ•°: {len(results_mt.industries)}")
        
        # æµ‹è¯•å•çº¿ç¨‹å¼•æ“
        print("\n=== æµ‹è¯•å•çº¿ç¨‹å¼•æ“ ===")
        engine_st = create_engine(dataset, enable_multithreading=False)
        start_time = time.time()
        results_st = engine_st.calculate_all_metrics()
        st_time = time.time() - start_time
        print(f"å•çº¿ç¨‹è®¡ç®—è€—æ—¶: {st_time:.2f}ç§’")
        print(f"è®¡ç®—è‚¡ç¥¨æ•°: {len(results_st.stocks)}")
        print(f"è®¡ç®—è¡Œä¸šæ•°: {len(results_st.industries)}")
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\n=== æ€§èƒ½å¯¹æ¯” ===")
        print(f"å¤šçº¿ç¨‹ vs å•çº¿ç¨‹åŠ é€Ÿæ¯”: {st_time/mt_time:.2f}x")
        
        # æµ‹è¯•ç¼“å­˜
        print("\n=== æµ‹è¯•ç¼“å­˜ ===")
        start_time = time.time()
        results_cached = engine_mt.calculate_all_metrics()  # åº”è¯¥ä½¿ç”¨ç¼“å­˜
        cached_time = time.time() - start_time
        print(f"ç¼“å­˜æŸ¥è¯¢è€—æ—¶: {cached_time:.4f}ç§’")
        
        # æµ‹è¯•æ’ååŠŸèƒ½
        rankings = engine_mt.get_real_time_rankings()
        print(f"\n=== å®æ—¶æ’å ===")
        print(f"Top 5 RTSIè‚¡ç¥¨:")
        for i, (code, name, score) in enumerate(rankings['top_stocks_by_rtsi'][:5], 1):
            print(f"  {i}. {code} {name}: {score:.2f}")
        
        # æµ‹è¯•ä¿¡å·æ£€æµ‹
        signals = engine_mt.detect_trend_changes()
        print(f"\n=== è¶‹åŠ¿ä¿¡å· ===")
        print(f"æ£€æµ‹åˆ° {len(signals)} ä¸ªä¿¡å·")
        for signal in signals[:3]:
            print(f"  {signal['type']}: {signal['signal']}")
        
        print("\næˆåŠŸ å®æ—¶åˆ†æå¼•æ“æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"é”™è¯¯ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()