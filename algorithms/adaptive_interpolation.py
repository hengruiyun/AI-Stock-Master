# -*- coding: utf-8 -*-
"""
è‡ªé€‚åº”æ’å€¼ç®—æ³•
æ ¹æ®ç¼ºå¤±æ—¶é•¿ã€å¸‚åœºç¯å¢ƒã€æ•°æ®è´¨é‡ç­‰å› ç´ æ™ºèƒ½é€‰æ‹©æ’å€¼ç­–ç•¥
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Union, Optional
import logging
from datetime import datetime, timedelta
from enum import Enum

class InterpolationStrategy(Enum):
    """æ’å€¼ç­–ç•¥æšä¸¾"""
    FORWARD_FILL = "forward_fill"           # å‰å‘å¡«å……
    NEUTRAL_FILL = "neutral_fill"           # ä¸­æ€§æ’å€¼
    WEIGHTED_HYBRID = "weighted_hybrid"     # åŠ æƒæ··åˆ
    ML_PREDICTION = "ml_prediction"         # æœºå™¨å­¦ä¹ é¢„æµ‹
    INDUSTRY_CORRELATION = "industry_correlation"  # è¡Œä¸šç›¸å…³æ€§æ’å€¼

class AdaptiveInterpolationEngine:
    """
    è‡ªé€‚åº”æ’å€¼å¼•æ“
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ™ºèƒ½è¯„ä¼°ç¼ºå¤±æ•°æ®çš„ç‰¹å¾
    2. åŠ¨æ€é€‰æ‹©æœ€ä¼˜æ’å€¼ç­–ç•¥
    3. æä¾›æ’å€¼è´¨é‡è¯„ä¼°
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARNINGï¼Œå‡å°‘INFOè¾“å‡º
        self.logger.setLevel(logging.WARNING)
        
        # 8çº§è¯„çº§ç³»ç»Ÿé…ç½®
        self.rating_map = {
            'å¤§å¤š': 7, 'ä¸­å¤š': 6, 'å°å¤š': 5, 'å¾®å¤š': 4,
            'å¾®ç©º': 3, 'å°ç©º': 2, 'ä¸­ç©º': 1, 'å¤§ç©º': 0,
            'ä¸­æ€§': 3.5, '-': None
        }
        
        # ä¸­æ€§å€¼ï¼ˆ8çº§ç³»ç»Ÿçš„ä¸­é—´å€¼ï¼‰
        self.neutral_value = 3.5
        
        # æ’å€¼ç­–ç•¥æƒé‡é…ç½®
        self.strategy_weights = {
            'data_quality': 0.3,      # æ•°æ®è´¨é‡æƒé‡
            'temporal_distance': 0.25, # æ—¶é—´è·ç¦»æƒé‡  
            'market_volatility': 0.2,  # å¸‚åœºæ³¢åŠ¨æ€§æƒé‡
            'trend_strength': 0.15,    # è¶‹åŠ¿å¼ºåº¦æƒé‡
            'industry_correlation': 0.1 # è¡Œä¸šç›¸å…³æ€§æƒé‡
        }
    
    def interpolate_rating_series(self, 
                                 ratings_series: pd.Series,
                                 stock_info: Dict = None,
                                 market_context: Dict = None) -> Dict[str, Union[pd.Series, float, str]]:
        """
        è‡ªé€‚åº”æ’å€¼ä¸»å‡½æ•°
        
        Args:
            ratings_series: åŸå§‹è¯„çº§åºåˆ—
            stock_info: è‚¡ç¥¨ä¿¡æ¯ï¼ˆä»£ç ã€è¡Œä¸šç­‰ï¼‰
            market_context: å¸‚åœºç¯å¢ƒä¿¡æ¯
            
        Returns:
            æ’å€¼ç»“æœå­—å…¸ï¼š{
                'interpolated_series': æ’å€¼ååºåˆ—,
                'interpolation_quality': æ’å€¼è´¨é‡è¯„åˆ†,
                'strategy_used': ä½¿ç”¨çš„ç­–ç•¥,
                'confidence_score': ç½®ä¿¡åº¦è¯„åˆ†
            }
        """
        start_time = datetime.now()
        
        try:
            # 1. æ•°æ®é¢„å¤„ç†å’Œè´¨é‡è¯„ä¼°
            missing_analysis = self._analyze_missing_pattern(ratings_series)
            
            # 2. é€‰æ‹©æœ€ä¼˜æ’å€¼ç­–ç•¥
            optimal_strategy = self._select_optimal_strategy(
                missing_analysis, stock_info, market_context
            )
            
            # 3. æ‰§è¡Œæ’å€¼
            interpolated_series = self._execute_interpolation(
                ratings_series, optimal_strategy, missing_analysis
            )
            
            # 4. è´¨é‡è¯„ä¼°
            quality_assessment = self._assess_interpolation_quality(
                ratings_series, interpolated_series, missing_analysis
            )
            
            # 5. ç”Ÿæˆç»“æœ
            processing_time = (datetime.now() - start_time).total_seconds()
            
            return {
                'interpolated_series': interpolated_series,
                'interpolation_quality': quality_assessment['quality_score'],
                'strategy_used': optimal_strategy.value,
                'confidence_score': quality_assessment['confidence'],
                'missing_ratio': missing_analysis['missing_ratio'],
                'max_gap_days': missing_analysis['max_gap_days'],
                'processing_time': f"{processing_time:.3f}s",
                'recommendations': quality_assessment['recommendations']
            }
            
        except Exception as e:
            self.logger.error(f"æ’å€¼å¤„ç†å¤±è´¥: {str(e)}")
            return {
                'interpolated_series': ratings_series,
                'interpolation_quality': 0.0,
                'strategy_used': 'error',
                'confidence_score': 0.0,
                'error_message': str(e)
            }
    
    def _analyze_missing_pattern(self, ratings_series: pd.Series) -> Dict:
        """åˆ†æç¼ºå¤±æ•°æ®æ¨¡å¼"""
        missing_mask = ratings_series.isin(['-', None, np.nan])
        total_points = len(ratings_series)
        missing_count = missing_mask.sum()
        
        # è®¡ç®—è¿ç»­ç¼ºå¤±çš„æœ€å¤§é•¿åº¦
        max_gap = 0
        current_gap = 0
        gap_positions = []
        
        for i, is_missing in enumerate(missing_mask):
            if is_missing:
                current_gap += 1
            else:
                if current_gap > 0:
                    gap_positions.append((i - current_gap, i - 1, current_gap))
                    max_gap = max(max_gap, current_gap)
                    current_gap = 0
        
        # å¤„ç†åºåˆ—æœ«å°¾çš„ç¼ºå¤±
        if current_gap > 0:
            gap_positions.append((total_points - current_gap, total_points - 1, current_gap))
            max_gap = max(max_gap, current_gap)
        
        # åˆ†æç¼ºå¤±æ¨¡å¼ç±»å‹
        if missing_count == 0:
            pattern_type = "complete"
        elif missing_count == total_points:
            pattern_type = "empty"
        elif missing_count / total_points > 0.7:
            pattern_type = "sparse"
        elif max_gap > 7:
            pattern_type = "long_gaps"
        elif len(gap_positions) > total_points / 3:
            pattern_type = "scattered"
        else:
            pattern_type = "normal"
        
        return {
            'missing_ratio': missing_count / total_points,
            'missing_count': missing_count,
            'total_points': total_points,
            'max_gap_days': max_gap,
            'gap_positions': gap_positions,
            'pattern_type': pattern_type,
            'data_density': 1 - (missing_count / total_points)
        }
    
    def _select_optimal_strategy(self, 
                               missing_analysis: Dict,
                               stock_info: Dict = None,
                               market_context: Dict = None) -> InterpolationStrategy:
        """é€‰æ‹©æœ€ä¼˜æ’å€¼ç­–ç•¥"""
        
        # åŸºäºç¼ºå¤±æ•°æ®ç‰¹å¾çš„ç­–ç•¥é€‰æ‹©
        missing_ratio = missing_analysis['missing_ratio']
        max_gap = missing_analysis['max_gap_days']
        pattern_type = missing_analysis['pattern_type']
        
        # ç­–ç•¥è¯„åˆ†
        strategy_scores = {}
        
        # 1. å‰å‘å¡«å……è¯„åˆ†
        if missing_ratio < 0.3 and max_gap <= 5:
            strategy_scores[InterpolationStrategy.FORWARD_FILL] = 0.9
        elif missing_ratio < 0.5 and max_gap <= 3:
            strategy_scores[InterpolationStrategy.FORWARD_FILL] = 0.7
        else:
            strategy_scores[InterpolationStrategy.FORWARD_FILL] = 0.3
        
        # 2. ä¸­æ€§æ’å€¼è¯„åˆ†
        if missing_ratio > 0.5 or max_gap > 7:
            strategy_scores[InterpolationStrategy.NEUTRAL_FILL] = 0.9
        elif pattern_type in ['sparse', 'long_gaps']:
            strategy_scores[InterpolationStrategy.NEUTRAL_FILL] = 0.8
        else:
            strategy_scores[InterpolationStrategy.NEUTRAL_FILL] = 0.6
        
        # 3. åŠ æƒæ··åˆè¯„åˆ†
        if 0.2 < missing_ratio < 0.6 and 3 < max_gap <= 7:
            strategy_scores[InterpolationStrategy.WEIGHTED_HYBRID] = 0.9
        elif pattern_type == 'normal':
            strategy_scores[InterpolationStrategy.WEIGHTED_HYBRID] = 0.7
        else:
            strategy_scores[InterpolationStrategy.WEIGHTED_HYBRID] = 0.5
        
        # 4. è€ƒè™‘å¸‚åœºç¯å¢ƒè°ƒæ•´
        if market_context:
            volatility = market_context.get('volatility', 0.5)
            if volatility > 0.7:  # é«˜æ³¢åŠ¨å¸‚åœº
                strategy_scores[InterpolationStrategy.NEUTRAL_FILL] *= 1.2
                strategy_scores[InterpolationStrategy.FORWARD_FILL] *= 0.8
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç­–ç•¥
        optimal_strategy = max(strategy_scores.items(), key=lambda x: x[1])[0]
        
        self.logger.info(f"é€‰æ‹©æ’å€¼ç­–ç•¥: {optimal_strategy.value}, è¯„åˆ†: {strategy_scores}")
        
        return optimal_strategy
    
    def _execute_interpolation(self, 
                             ratings_series: pd.Series,
                             strategy: InterpolationStrategy,
                             missing_analysis: Dict) -> pd.Series:
        """æ‰§è¡Œå…·ä½“çš„æ’å€¼æ“ä½œ"""
        
        if strategy == InterpolationStrategy.FORWARD_FILL:
            return self._forward_fill_interpolation(ratings_series)
        
        elif strategy == InterpolationStrategy.NEUTRAL_FILL:
            return self._neutral_fill_interpolation(ratings_series)
        
        elif strategy == InterpolationStrategy.WEIGHTED_HYBRID:
            return self._weighted_hybrid_interpolation(ratings_series, missing_analysis)
        
        else:
            # é»˜è®¤ä½¿ç”¨å‰å‘å¡«å……
            self.logger.warning(f"æœªå®ç°çš„ç­–ç•¥ {strategy}, ä½¿ç”¨å‰å‘å¡«å……")
            return self._forward_fill_interpolation(ratings_series)
    
    def _forward_fill_interpolation(self, ratings_series: pd.Series) -> pd.Series:
        """å‰å‘å¡«å……æ’å€¼"""
        interpolated = ratings_series.copy()
        last_valid = None
        
        for i, rating in enumerate(interpolated):
            if rating not in ['-', None, np.nan]:
                # è½¬æ¢ä¸ºæ•°å€¼
                if rating in self.rating_map:
                    last_valid = self.rating_map[rating]
                    interpolated.iloc[i] = last_valid
                else:
                    try:
                        last_valid = float(rating)
                        interpolated.iloc[i] = last_valid
                    except:
                        if last_valid is not None:
                            interpolated.iloc[i] = last_valid
            else:
                if last_valid is not None:
                    interpolated.iloc[i] = last_valid
                else:
                    interpolated.iloc[i] = self.neutral_value
        
        return interpolated
    
    def _neutral_fill_interpolation(self, ratings_series: pd.Series) -> pd.Series:
        """ä¸­æ€§æ’å€¼"""
        interpolated = ratings_series.copy()
        
        for i, rating in enumerate(interpolated):
            if rating in ['-', None, np.nan]:
                interpolated.iloc[i] = self.neutral_value
            else:
                if rating in self.rating_map:
                    interpolated.iloc[i] = self.rating_map[rating]
                else:
                    try:
                        interpolated.iloc[i] = float(rating)
                    except:
                        interpolated.iloc[i] = self.neutral_value
        
        return interpolated
    
    def _weighted_hybrid_interpolation(self, 
                                     ratings_series: pd.Series,
                                     missing_analysis: Dict) -> pd.Series:
        """åŠ æƒæ··åˆæ’å€¼"""
        interpolated = ratings_series.copy()
        last_valid = None
        
        for i, rating in enumerate(interpolated):
            if rating not in ['-', None, np.nan]:
                if rating in self.rating_map:
                    last_valid = self.rating_map[rating]
                    interpolated.iloc[i] = last_valid
                else:
                    try:
                        last_valid = float(rating)
                        interpolated.iloc[i] = last_valid
                    except:
                        if last_valid is not None:
                            interpolated.iloc[i] = last_valid
            else:
                if last_valid is not None:
                    # è®¡ç®—æ—¶é—´è¡°å‡æƒé‡
                    days_since_valid = self._calculate_days_since_valid(i, ratings_series)
                    time_weight = max(0, 1 - days_since_valid / 7)  # 7å¤©å†…çº¿æ€§è¡°å‡
                    
                    # åŠ æƒæ’å€¼ï¼šå†å²ä¿¡å· + ä¸­æ€§å€¼
                    interpolated_value = (time_weight * last_valid + 
                                        (1 - time_weight) * self.neutral_value)
                    interpolated.iloc[i] = interpolated_value
                else:
                    interpolated.iloc[i] = self.neutral_value
        
        return interpolated
    
    def _calculate_days_since_valid(self, current_index: int, ratings_series: pd.Series) -> int:
        """è®¡ç®—è·ç¦»æœ€è¿‘æœ‰æ•ˆæ•°æ®çš„å¤©æ•°"""
        days = 0
        for i in range(current_index - 1, -1, -1):
            if ratings_series.iloc[i] not in ['-', None, np.nan]:
                break
            days += 1
        return days
    
    def _assess_interpolation_quality(self, 
                                    original_series: pd.Series,
                                    interpolated_series: pd.Series,
                                    missing_analysis: Dict) -> Dict:
        """è¯„ä¼°æ’å€¼è´¨é‡"""
        
        # åŸºç¡€è´¨é‡æŒ‡æ ‡
        missing_ratio = missing_analysis['missing_ratio']
        max_gap = missing_analysis['max_gap_days']
        pattern_type = missing_analysis['pattern_type']
        
        # è´¨é‡è¯„åˆ†è®¡ç®—
        quality_score = 1.0
        confidence = 1.0
        recommendations = []
        
        # 1. åŸºäºç¼ºå¤±æ¯”ä¾‹çš„è´¨é‡è°ƒæ•´
        if missing_ratio > 0.5:
            quality_score *= 0.6
            confidence *= 0.7
            recommendations.append("âš ï¸ ç¼ºå¤±æ•°æ®è¿‡å¤šï¼Œå»ºè®®è°¨æ…ä½¿ç”¨åˆ†æç»“æœ")
        elif missing_ratio > 0.3:
            quality_score *= 0.8
            confidence *= 0.85
            recommendations.append("ğŸ“Š æ•°æ®è´¨é‡ä¸­ç­‰ï¼Œå»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡")
        
        # 2. åŸºäºæœ€å¤§ç¼ºå¤±é—´éš”çš„è°ƒæ•´
        if max_gap > 10:
            quality_score *= 0.5
            confidence *= 0.6
            recommendations.append("ğŸš¨ å­˜åœ¨é•¿æœŸæ•°æ®ç¼ºå¤±ï¼Œç»“æœå¯é æ€§é™ä½")
        elif max_gap > 5:
            quality_score *= 0.8
            confidence *= 0.8
            recommendations.append("âš ï¸ å­˜åœ¨è¾ƒé•¿æ•°æ®ç¼ºå¤±é—´éš”")
        
        # 3. åŸºäºç¼ºå¤±æ¨¡å¼çš„è°ƒæ•´
        if pattern_type == 'sparse':
            quality_score *= 0.6
            recommendations.append("ğŸ“‰ æ•°æ®ç¨€ç–ï¼Œå»ºè®®å¯»æ‰¾æ›¿ä»£æ•°æ®æº")
        elif pattern_type == 'scattered':
            quality_score *= 0.9
            recommendations.append("âœ… æ•°æ®å®Œæ•´æ€§è‰¯å¥½")
        
        # 4. è®¡ç®—æ•°æ®ä¸€è‡´æ€§
        valid_data = original_series[original_series.notna()]
        if len(valid_data) > 1:
            data_variance = np.var([self.rating_map.get(x, x) for x in valid_data if x != '-'])
            if data_variance < 1:  # ä½æ–¹å·®è¡¨ç¤ºä¸€è‡´æ€§å¥½
                quality_score *= 1.1
                confidence *= 1.05
        
        return {
            'quality_score': min(quality_score, 1.0),
            'confidence': min(confidence, 1.0),
            'recommendations': recommendations,
            'missing_ratio': missing_ratio,
            'max_gap_days': max_gap,
            'pattern_type': pattern_type
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ’å€¼å¼•æ“
    engine = AdaptiveInterpolationEngine()
    
    # ç¤ºä¾‹æ•°æ®
    test_ratings = pd.Series(['å¤§å¤š', 'ä¸­å¤š', '-', '-', 'å°å¤š', '-', 'å¾®ç©º', 'å°ç©º'])
    
    # æ‰§è¡Œæ’å€¼
    result = engine.interpolate_rating_series(test_ratings)
    
    print("æ’å€¼ç»“æœ:")
    print(f"åŸå§‹åºåˆ—: {test_ratings.tolist()}")
    print(f"æ’å€¼åºåˆ—: {result['interpolated_series'].tolist()}")
    print(f"ä½¿ç”¨ç­–ç•¥: {result['strategy_used']}")
    print(f"è´¨é‡è¯„åˆ†: {result['interpolation_quality']:.2f}")
    print(f"ç½®ä¿¡åº¦: {result['confidence_score']:.2f}")
    for rec in result['recommendations']:
        print(f"å»ºè®®: {rec}")
