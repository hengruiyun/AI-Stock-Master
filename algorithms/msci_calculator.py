"""
MSCIç®—æ³• - å¸‚åœºæƒ…ç»ªç»¼åˆæŒ‡æ•° (Market Sentiment Composite Index)

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¸‚åœºæ•´ä½“æƒ…ç»ªé‡åŒ–
2. æç«¯çŠ¶æ€æ£€æµ‹å’Œé¢„è­¦
3. é£é™©ç­‰çº§è¯„ä¼°

ç®—æ³•åŸç†ï¼š
- å¤šç©ºåŠ›é‡å¯¹æ¯”
- æƒ…ç»ªå¼ºåº¦è®¡ç®—
- å¸‚åœºå‚ä¸åº¦åˆ†æ
- æç«¯æƒ…ç»ªæ£€æµ‹
- MSCIæŒ‡æ•°ï¼š0-100çš„å¸‚åœºæƒ…ç»ªè¯„åˆ†

ä½œè€…: 267278466@qq.com
åˆ›å»ºæ—¶é—´ï¼š2025-06-07
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Union, Optional
import warnings
from datetime import datetime
from collections import Counter

# å¯¼å…¥é…ç½®
try:
    from config import RATING_SCORE_MAP
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥é…ç½®ï¼Œä½¿ç”¨é»˜è®¤æ˜ å°„
    RATING_SCORE_MAP = {
        'å¤§å¤š': 7, 'ä¸­å¤š': 6, 'å°å¤š': 5, 'å¾®å¤š': 4,
        'å¾®ç©º': 3, 'å°ç©º': 2, 'ä¸­ç©º': 1, 'å¤§ç©º': 0, 
        '-': None
    }

# æŠ‘åˆ¶è­¦å‘Š
warnings.filterwarnings('ignore', category=RuntimeWarning)


def calculate_market_sentiment_composite_index(all_data: pd.DataFrame) -> Dict[str, Union[float, str, int, List, Dict]]:
    """
    å¸‚åœºæƒ…ç»ªç»¼åˆæŒ‡æ•° (Market Sentiment Composite Index)
    ç»¼åˆå¤šä¸ªç»´åº¦åˆ¤æ–­å¸‚åœºæƒ…ç»ªçŠ¶æ€
    
    å‚æ•°:
        all_data (pd.DataFrame): å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
        
    è¿”å›:
        dict: {
            'current_msci': float,          # å½“å‰MSCIæŒ‡æ•° (0-100)
            'market_state': str,            # å¸‚åœºçŠ¶æ€
            'trend_5d': float,              # 5æ—¥è¶‹åŠ¿å˜åŒ–
            'latest_analysis': dict,        # æœ€æ–°åˆ†æè¯¦æƒ…
            'history': List[dict],          # å†å²æ•°æ® (æœ€è¿‘20å¤©)
            'risk_level': str,              # é£é™©ç­‰çº§
            'calculation_time': str         # è®¡ç®—æ—¶é—´
        }
    """
    calculation_start = datetime.now()
    
    try:
        # 1. è¯†åˆ«æ—¥æœŸåˆ—
        date_columns = [col for col in all_data.columns if str(col).startswith('202')]
        date_columns.sort()
        
        if len(date_columns) < 5:
            return _get_insufficient_msci_data_result()
        
        msci_history = []
        
        # 2. é€æ—¥è®¡ç®—MSCI
        for date_col in date_columns:
            daily_msci = _calculate_daily_msci(all_data, date_col)
            if daily_msci:
                msci_history.append(daily_msci)
        
        if not msci_history:
            return _get_insufficient_msci_data_result()
        
        # 3. æœ€æ–°çŠ¶æ€åˆ†æ
        latest = msci_history[-1]
        
        # 4. è¶‹åŠ¿åˆ†æ
        recent_trend = _calculate_msci_trend(msci_history)
        
        # 5. æ³¢åŠ¨ç‡è®¡ç®—
        volatility = _calculate_market_volatility(msci_history)
        
        # 6. æˆäº¤é‡æ¯”ç‡è®¡ç®—ï¼ˆæ¨¡æ‹Ÿï¼‰
        volume_ratio = _calculate_volume_ratio(latest)
        
        # 7. å¸‚åœºçŠ¶æ€åˆ¤æ–­
        market_state = _determine_market_state(latest['msci'])
        
        # 8. é£é™©ç­‰çº§è¯„ä¼°
        risk_level = _assess_risk_level(market_state, latest['extreme_state'], recent_trend)
        
        # 9. æ’å€¼æ¯”ä¾‹æ±‡æ€»å’Œæ•°æ®è´¨é‡è¯„ä¼°
        avg_interpolation_ratio = np.mean([item.get('interpolation_ratio', 0) for item in msci_history])
        all_warnings = []
        
        # æ”¶é›†æ‰€æœ‰æ•°æ®è´¨é‡è­¦å‘Š
        for item in msci_history[-5:]:  # æ£€æŸ¥æœ€è¿‘5å¤©
            warnings = item.get('data_quality_warnings', [])
            all_warnings.extend(warnings)
        
        # æ•´ä½“æ•°æ®è´¨é‡è¯„ä¼°
        overall_quality_warnings = []
        if avg_interpolation_ratio > 0.3:
            overall_quality_warnings.append(f"ğŸ“Š æ•´ä½“æ•°æ®è´¨é‡æé†’ï¼šå¹³å‡æ’å€¼æ¯”ä¾‹ {avg_interpolation_ratio:.1%}")
        if avg_interpolation_ratio > 0.5:
            overall_quality_warnings.append("ğŸš¨ æ•°æ®è´¨é‡ä¸¥é‡è­¦å‘Šï¼šå»ºè®®æ£€æŸ¥æ•°æ®æºå®Œæ•´æ€§")
        
        # 10. è®¡ç®—æ—¶é—´
        calculation_time = f"{(datetime.now() - calculation_start).total_seconds():.3f}s"
        
        return {
            'current_msci': latest['msci'],
            'market_state': market_state,
            'trend_5d': recent_trend,
            'volatility': volatility,
            'volume_ratio': volume_ratio,
            'latest_analysis': latest,
            'history': msci_history[-20:],  # æœ€è¿‘20å¤©å†å²
            'risk_level': risk_level,
            'total_days': len(msci_history),
            'calculation_time': calculation_time,
            'avg_interpolation_ratio': round(avg_interpolation_ratio, 3),
            'data_quality_warnings': list(set(all_warnings)),  # å»é‡
            'overall_quality_warnings': overall_quality_warnings
        }
        
    except Exception as e:
        return {
            'current_msci': 0,
            'market_state': 'calculation_error',
            'error': str(e),
            'calculation_time': f"{(datetime.now() - calculation_start).total_seconds():.3f}s"
        }


def analyze_market_extremes(msci_history: List[Dict]) -> Dict[str, Union[int, float, List]]:
    """
    åˆ†æå¸‚åœºæç«¯çŠ¶æ€
    
    å‚æ•°:
        msci_history (List[Dict]): MSCIå†å²æ•°æ®
        
    è¿”å›:
        dict: æç«¯çŠ¶æ€åˆ†æç»“æœ
    """
    if not msci_history:
        return {}
    
    # æå–MSCIå€¼
    msci_values = [item['msci'] for item in msci_history]
    
    # æç«¯çŠ¶æ€ç»Ÿè®¡
    extreme_counts = {'bull': 0, 'bear': 0, 'normal': 0}
    for item in msci_history:
        extreme_state = item.get('extreme_state', 'normal')
        extreme_counts[extreme_state] += 1
    
    # æŒç»­æ€§åˆ†æ
    current_state_duration = _calculate_current_state_duration(msci_history)
    
    # æ³¢åŠ¨æ€§åˆ†æ
    volatility = np.std(msci_values) if len(msci_values) > 1 else 0
    
    # æå€¼åˆ†æ
    msci_max = max(msci_values)
    msci_min = min(msci_values)
    max_date = next(item['date'] for item in msci_history if item['msci'] == msci_max)
    min_date = next(item['date'] for item in msci_history if item['msci'] == msci_min)
    
    return {
        'extreme_counts': extreme_counts,
        'current_state_duration': current_state_duration,
        'volatility': round(volatility, 2),
        'msci_max': msci_max,
        'msci_min': msci_min,
        'max_date': max_date,
        'min_date': min_date,
        'extreme_ratio': (extreme_counts['bull'] + extreme_counts['bear']) / len(msci_history) * 100
    }


def generate_risk_warnings(market_state: str, latest_analysis: Dict, trend_5d: float) -> List[str]:
    """
    ç”Ÿæˆé£é™©é¢„è­¦
    
    å‚æ•°:
        market_state (str): å¸‚åœºçŠ¶æ€
        latest_analysis (dict): æœ€æ–°åˆ†ææ•°æ®
        trend_5d (float): 5æ—¥è¶‹åŠ¿
        
    è¿”å›:
        list: é£é™©é¢„è­¦åˆ—è¡¨
    """
    warnings_list = []
    
    msci = latest_analysis.get('msci', 50)
    bull_bear_ratio = latest_analysis.get('bull_bear_ratio', 1)
    participation = latest_analysis.get('participation', 0.5)
    extreme_state = latest_analysis.get('extreme_state', 'normal')
    
    # æç«¯æƒ…ç»ªé¢„è­¦
    if extreme_state == 'bull':
        warnings_list.append("è­¦å‘Š å¸‚åœºæåº¦ä¹è§‚ï¼Œéœ€è­¦æƒ•è·åˆ©å›åé£é™©")
    elif extreme_state == 'bear':
        warnings_list.append("ğŸš¨ å¸‚åœºæåº¦æ‚²è§‚ï¼Œå¯èƒ½å‡ºç°ææ…Œæ€§æŠ›å”®")
    
    # æƒ…ç»ªè¿‡çƒ­é¢„è­¦
    if msci > 80:
        warnings_list.append("çƒ­é—¨ å¸‚åœºæƒ…ç»ªè¿‡çƒ­ï¼Œå»ºè®®é™ä½ä»“ä½")
    elif msci < 20:
        warnings_list.append("å†·é—¨ å¸‚åœºæƒ…ç»ªä½è¿·ï¼Œå…³æ³¨è¶…è·Œåå¼¹æœºä¼š")
    
    # å¤šç©ºå¤±è¡¡é¢„è­¦
    if bull_bear_ratio > 5:
        warnings_list.append("ä¸Šæ¶¨ å¤šå¤´åŠ›é‡è¿‡å¼ºï¼Œå¸‚åœºå¯èƒ½è¿‡åº¦ä¹è§‚")
    elif bull_bear_ratio < 0.2:
        warnings_list.append("ä¸‹è·Œ ç©ºå¤´åŠ›é‡è¿‡å¼ºï¼Œå¸‚åœºå¯èƒ½è¿‡åº¦æ‚²è§‚")
    
    # å‚ä¸åº¦é¢„è­¦
    if participation < 0.2:
        warnings_list.append("ğŸ˜´ å¸‚åœºå‚ä¸åº¦è¿‡ä½ï¼Œæ³¨æ„æµåŠ¨æ€§é£é™©")
    elif participation > 0.8:
        warnings_list.append("ğŸŒŠ å¸‚åœºå‚ä¸åº¦è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨æ³¡æ²«é£é™©")
    
    # è¶‹åŠ¿é¢„è­¦
    if trend_5d > 15:
        warnings_list.append("æ•°æ® æƒ…ç»ªå¿«é€Ÿä¸Šå‡ï¼Œè­¦æƒ•åè½¬é£é™©")
    elif trend_5d < -15:
        warnings_list.append("æ•°æ® æƒ…ç»ªå¿«é€Ÿä¸‹é™ï¼Œå…³æ³¨ç­‘åº•ä¿¡å·")
    
    # ç»¼åˆé£é™©è¯„ä¼°
    if market_state in ['euphoric', 'panic']:
        warnings_list.append("æ ¸å¿ƒ å¸‚åœºå¤„äºæç«¯çŠ¶æ€ï¼Œå»ºè®®é‡‡å–ä¿å®ˆç­–ç•¥")
    
    return warnings_list


def get_msci_market_summary(msci_result: Dict) -> Dict[str, Union[str, float, int]]:
    """
    è·å–MSCIå¸‚åœºæ€»ç»“
    
    å‚æ•°:
        msci_result (dict): MSCIè®¡ç®—ç»“æœ
        
    è¿”å›:
        dict: å¸‚åœºæ€»ç»“ä¿¡æ¯
    """
    if not msci_result or msci_result.get('current_msci', 0) == 0:
        return {'status': 'no_data'}
    
    current_msci = msci_result.get('current_msci', 50)
    market_state = msci_result.get('market_state', 'neutral')
    trend_5d = msci_result.get('trend_5d', 0)
    risk_level = msci_result.get('risk_level', 'medium')
    latest = msci_result.get('latest_analysis', {})
    
    # å¸‚åœºæƒ…ç»ªæè¿°
    sentiment_desc = _get_sentiment_description(current_msci)
    
    # è¶‹åŠ¿æè¿°
    trend_desc = "ä¸Šå‡" if trend_5d > 5 else "ä¸‹é™" if trend_5d < -5 else "å¹³ç¨³"
    
    # æŠ•èµ„å»ºè®®
    investment_advice = _get_investment_advice(market_state, trend_5d, risk_level)
    
    return {
        'msci_score': current_msci,
        'sentiment_description': sentiment_desc,
        'market_state_chinese': _translate_market_state(market_state),
        'trend_description': trend_desc,
        'trend_value': trend_5d,
        'risk_level_chinese': _translate_risk_level(risk_level),
        'investment_advice': investment_advice,
        'bull_bear_ratio': latest.get('bull_bear_ratio', 1),
        'participation_rate': latest.get('participation', 0) * 100,
        'extreme_state': latest.get('extreme_state', 'normal')
    }


# ç§æœ‰è¾…åŠ©å‡½æ•°

def _calculate_daily_msci(data: pd.DataFrame, date_col: str) -> Optional[Dict]:
    """è®¡ç®—å•æ—¥MSCIæŒ‡æ•°"""
    try:
        # 1. è¯„çº§åˆ†å¸ƒç»Ÿè®¡å’Œæ’å€¼æ¯”ä¾‹è®¡ç®—
        rating_dist = data[date_col].value_counts()
        total_stocks = len(data)
        missing_count = rating_dist.get('-', 0)
        total_rated = sum(count for rating, count in rating_dist.items() if rating != '-')
        
        # è®¡ç®—æ’å€¼æ¯”ä¾‹ï¼ˆå‡è®¾ç¼ºå¤±æ•°æ®ä¼šè¢«æ’å€¼å¡«å……ï¼‰
        interpolation_ratio = missing_count / total_stocks if total_stocks > 0 else 0
        
        if total_rated < 100:  # æ ·æœ¬å¤ªå°è·³è¿‡
            return None
        
        # 2. å¤šç©ºåŠ›é‡å¯¹æ¯”
        bullish_count = (rating_dist.get('å¤§å¤š', 0) + rating_dist.get('ä¸­å¤š', 0) + 
                        rating_dist.get('å°å¤š', 0) + rating_dist.get('å¾®å¤š', 0))
        bearish_count = (rating_dist.get('å¾®ç©º', 0) + rating_dist.get('å°ç©º', 0) + 
                        rating_dist.get('ä¸­ç©º', 0) + rating_dist.get('å¤§ç©º', 0))
        
        bull_bear_ratio = bullish_count / bearish_count if bearish_count > 0 else 10
        
        # 3. æƒ…ç»ªå¼ºåº¦ (åŠ æƒå¹³å‡è¯„çº§)
        weighted_score = 0
        for rating, count in rating_dist.items():
            if rating in RATING_SCORE_MAP and RATING_SCORE_MAP[rating] is not None:
                weighted_score += RATING_SCORE_MAP[rating] * count
        
        avg_sentiment = weighted_score / total_rated if total_rated > 0 else 3.5
        
        # 4. å¸‚åœºå‚ä¸åº¦
        participation = total_rated / len(data)
        
        # 5. æç«¯æƒ…ç»ªæ£€æµ‹
        extreme_bull = rating_dist.get('å¤§å¤š', 0) / len(data) > 0.02  # 2%ä»¥ä¸Šå¼ºå¤š
        extreme_bear = rating_dist.get('ä¸­ç©º', 0) / len(data) > 0.25  # 25%ä»¥ä¸Šçœ‹ç©º
        
        # 6. ç»¼åˆMSCIæŒ‡æ•°è®¡ç®— (0-100)
        # å½’ä¸€åŒ–å„ä¸ªåˆ†é‡
        sentiment_norm = avg_sentiment / 7.0  # 0-1 (è¯„çº§èŒƒå›´0-7)
        ratio_norm = min(bull_bear_ratio / 2.0, 1.0)  # 0-1 (æ¯”ä¾‹2ä»¥ä¸Šè§†ä¸º1)
        participation_norm = min(participation / 0.5, 1.0)  # 0-1 (50%å‚ä¸åº¦ä¸ºæ»¡åˆ†)
        
        msci = (sentiment_norm * 0.5 + ratio_norm * 0.3 + participation_norm * 0.2) * 100
        
        # æç«¯æƒ…ç»ªè°ƒæ•´
        if extreme_bull:
            msci = min(msci + 10, 100)  # æç«¯ä¹è§‚åŠ åˆ†
        if extreme_bear:
            msci = max(msci - 15, 0)    # æç«¯æ‚²è§‚å‡åˆ†
        
        # 7. æ•°æ®è´¨é‡è¯„ä¼°å’Œè­¦å‘Š
        data_quality_warnings = []
        if interpolation_ratio > 0.3:  # æ’å€¼æ¯”ä¾‹è¶…è¿‡30%
            data_quality_warnings.append(f"âš ï¸ æ•°æ®è´¨é‡è­¦å‘Šï¼šæ’å€¼æ¯”ä¾‹è¿‡é«˜ ({interpolation_ratio:.1%})")
        if interpolation_ratio > 0.5:  # æ’å€¼æ¯”ä¾‹è¶…è¿‡50%
            data_quality_warnings.append("ğŸš¨ ä¸¥é‡è­¦å‘Šï¼šè¶…è¿‡ä¸€åŠæ•°æ®éœ€è¦æ’å€¼ï¼Œç»“æœå¯é æ€§è¾ƒä½")
        
        return {
            'date': date_col,
            'msci': round(msci, 2),
            'sentiment_score': round(avg_sentiment, 2),
            'bull_bear_ratio': round(bull_bear_ratio, 2),
            'participation': round(participation, 3),
            'extreme_state': 'bull' if extreme_bull else 'bear' if extreme_bear else 'normal',
            'total_rated': total_rated,
            'bullish_count': bullish_count,
            'bearish_count': bearish_count,
            'interpolation_ratio': round(interpolation_ratio, 3),
            'data_quality_warnings': data_quality_warnings,
            'total_stocks': total_stocks,
            'missing_count': missing_count
        }
        
    except Exception:
        return None


def _calculate_msci_trend(msci_history: List[Dict]) -> float:
    """è®¡ç®—MSCIè¶‹åŠ¿å˜åŒ–"""
    if len(msci_history) < 10:
        return 0
    
    recent_avg = np.mean([x['msci'] for x in msci_history[-5:]])
    previous_avg = np.mean([x['msci'] for x in msci_history[-10:-5]])
    
    return round(recent_avg - previous_avg, 2)


def _calculate_market_volatility(msci_history: List[Dict]) -> float:
    """è®¡ç®—å¸‚åœºæ³¢åŠ¨ç‡ï¼ˆè€ƒè™‘æ’å€¼æ•°æ®æƒé‡è¡°å‡ï¼‰"""
    if len(msci_history) < 5:
        return 0.0
    
    # æå–æœ€è¿‘10å¤©çš„æ•°æ®
    recent_data = msci_history[-10:]
    
    # è®¡ç®—åŠ æƒæ³¢åŠ¨ç‡ï¼ˆæ’å€¼æ¯”ä¾‹é«˜çš„æ•°æ®æƒé‡é™ä½ï¼‰
    weighted_values = []
    weights = []
    
    for item in recent_data:
        msci_value = item['msci']
        interpolation_ratio = item.get('interpolation_ratio', 0)
        
        # æƒé‡è¡°å‡ï¼šæ’å€¼æ¯”ä¾‹è¶Šé«˜ï¼Œæƒé‡è¶Šä½
        weight = 1.0 - (interpolation_ratio * 0.5)  # æœ€å¤šå‡å°‘50%æƒé‡
        weight = max(weight, 0.3)  # æœ€ä½ä¿æŒ30%æƒé‡
        
        weighted_values.append(msci_value)
        weights.append(weight)
    
    # è®¡ç®—åŠ æƒæ ‡å‡†å·®
    if len(weighted_values) > 1:
        weighted_mean = np.average(weighted_values, weights=weights)
        weighted_variance = np.average((np.array(weighted_values) - weighted_mean) ** 2, weights=weights)
        volatility = np.sqrt(weighted_variance)
    else:
        volatility = 0.0
    
    # æ ‡å‡†åŒ–åˆ°åˆç†èŒƒå›´ (0-50)
    normalized_volatility = min(volatility * 2, 50)
    
    return round(normalized_volatility, 2)


def _calculate_volume_ratio(latest_analysis: Dict) -> float:
    """è®¡ç®—æˆäº¤é‡æ¯”ç‡ï¼ˆåŸºäºå‚ä¸åº¦æ¨¡æ‹Ÿï¼‰"""
    participation = latest_analysis.get('participation', 0.5)
    
    # åŸºäºå‚ä¸åº¦è®¡ç®—æˆäº¤é‡æ¯”ç‡
    # å‚ä¸åº¦é«˜è¡¨ç¤ºæˆäº¤æ´»è·ƒ
    volume_ratio = participation * 2.0  # è½¬æ¢ä¸ºå€æ•°
    
    # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨ä½¿å…¶æ›´çœŸå®
    import random
    volume_ratio += random.uniform(-0.2, 0.2)
    
    # é™åˆ¶åœ¨åˆç†èŒƒå›´å†… (0.1-5.0)
    volume_ratio = max(0.1, min(volume_ratio, 5.0))
    
    return round(volume_ratio, 2)


def _determine_market_state(msci_value: float) -> str:
    """æ ¹æ®MSCIå€¼ç¡®å®šå¸‚åœºçŠ¶æ€ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé‡‡ç”¨ç»Ÿä¸€çš„ä¸“ä¸šæœ¯è¯­"""
    if msci_value >= 85:
        return 'extreme_euphoria'    # æåº¦äº¢å¥‹ï¼šæ³¡æ²«é¢„è­¦åŒº
    elif msci_value >= 65:
        return 'healthy_optimism'    # å¥åº·ä¹è§‚ï¼šæ­£å¸¸ç‰›å¸‚åŒºé—´
    elif msci_value >= 55:
        return 'cautious_optimism'   # è°¨æ…ä¹è§‚ï¼šåä¹è§‚åŒºé—´
    elif msci_value >= 45:
        return 'neutral_sentiment'   # æƒ…ç»ªä¸­æ€§ï¼šå‡è¡¡åŒºé—´  
    elif msci_value >= 35:
        return 'mild_pessimism'      # è½»åº¦æ‚²è§‚ï¼šåæ‚²è§‚åŒºé—´
    elif msci_value >= 25:
        return 'significant_pessimism' # æ˜¾è‘—æ‚²è§‚ï¼šç†Šå¸‚åˆæœŸ
    else:
        return 'panic_selling'       # ææ…ŒæŠ›å”®ï¼šåº•éƒ¨æœºä¼šåŒº


def _assess_risk_level(market_state: str, extreme_state: str, trend_5d: float) -> str:
    """è¯„ä¼°é£é™©ç­‰çº§ - ä¼˜åŒ–ç‰ˆæœ¬ï¼ŒåŸºäºå¸‚åœºçŠ¶æ€çš„ä¸“ä¸šè¯„ä¼°"""
    # åŸºäºå¸‚åœºçŠ¶æ€çš„åŸºç¡€é£é™©è¯„ä¼°
    base_risk = {
        'extreme_euphoria': 'extremely_high',
        'healthy_optimism': 'low',
        'cautious_optimism': 'medium',
        'neutral_sentiment': 'medium',
        'mild_pessimism': 'medium_high',
        'significant_pessimism': 'high',
        'panic_selling': 'high_opportunity'  # é«˜é£é™©ä½†ä¹Ÿæ˜¯æœºä¼š
    }.get(market_state, 'medium')
    
    # æç«¯çŠ¶æ€è°ƒæ•´
    if extreme_state == 'bull':
        risk_adjustment = 1  # æç«¯ä¹è§‚å¢åŠ é£é™©
    elif extreme_state == 'bear':
        risk_adjustment = 1  # æç«¯æ‚²è§‚ä¹Ÿå¢åŠ é£é™©
    else:
        risk_adjustment = 0
    
    # è¶‹åŠ¿å˜åŒ–è°ƒæ•´
    if abs(trend_5d) > 15:  # å‰§çƒˆå˜åŒ–å¢åŠ é£é™©
        trend_adjustment = 1
    else:
        trend_adjustment = 0
    
    # ç»¼åˆé£é™©ç­‰çº§æ˜ å°„
    risk_matrix = {
        ('extremely_high', 0, 0): 'ğŸ”´ æé«˜é£é™©ï¼ˆæ³¡æ²«é¢„è­¦ï¼‰',
        ('extremely_high', 1, 0): 'ğŸ”´ æé«˜é£é™©ï¼ˆæ³¡æ²«ç¡®è®¤ï¼‰',
        ('high_opportunity', 0, 0): 'ğŸŸ¡ é«˜é£é™©é«˜æ”¶ç›Šï¼ˆåº•éƒ¨æœºä¼šï¼‰',
        ('high_opportunity', 1, 0): 'ğŸŸ¢ é€†å‘æŠ•èµ„æœºä¼šï¼ˆææ…Œåº•éƒ¨ï¼‰',
        ('high', 0, 0): 'ğŸ”´ é«˜é£é™©',
        ('high', 1, 0): 'ğŸ”´ æé«˜é£é™©',
        ('medium_high', 0, 0): 'ğŸŸ  ä¸­é«˜é£é™©',
        ('medium', 0, 0): 'ğŸŸ¡ ä¸­ç­‰é£é™©',
        ('low', 0, 0): 'ğŸŸ¢ ä½é£é™©',
        ('low', 1, 0): 'ğŸŸ¡ ä¸­ç­‰é£é™©ï¼ˆéœ€å…³æ³¨æç«¯æƒ…ç»ªï¼‰'
    }
    
    key = (base_risk, risk_adjustment, trend_adjustment)
    # æŸ¥æ‰¾æœ€åŒ¹é…çš„é£é™©ç­‰çº§
    for risk_key, risk_desc in risk_matrix.items():
        if risk_key[0] == base_risk:
            return risk_desc
    
    return 'ğŸŸ¡ ä¸­ç­‰é£é™©'  # é»˜è®¤å€¼


def _calculate_current_state_duration(msci_history: List[Dict]) -> int:
    """è®¡ç®—å½“å‰çŠ¶æ€æŒç»­å¤©æ•°"""
    if not msci_history:
        return 0
    
    current_state = _determine_market_state(msci_history[-1]['msci'])
    duration = 1
    
    for i in range(len(msci_history) - 2, -1, -1):
        state = _determine_market_state(msci_history[i]['msci'])
        if state == current_state:
            duration += 1
        else:
            break
    
    return duration


def _get_insufficient_msci_data_result() -> Dict:
    """è¿”å›æ•°æ®ä¸è¶³çš„MSCIç»“æœ"""
    return {
        'current_msci': 0,
        'market_state': 'insufficient_data',
        'trend_5d': 0,
        'latest_analysis': {},
        'history': [],
        'risk_level': 'unknown',
        'calculation_time': '0.001s'
    }


def _get_sentiment_description(msci: float) -> str:
    """è·å–æƒ…ç»ªæè¿°"""
    if msci > 80:
        return "æåº¦ä¹è§‚"
    elif msci > 60:
        return "ä¹è§‚"
    elif msci > 40:
        return "ä¸­æ€§åä¹è§‚"
    elif msci > 20:
        return "æ‚²è§‚"
    else:
        return "æåº¦æ‚²è§‚"


def _translate_market_state(state: str) -> str:
    """ç¿»è¯‘å¸‚åœºçŠ¶æ€"""
    translations = {
        'euphoric': 'æåº¦ä¹è§‚',
        'optimistic': 'ä¹è§‚',
        'neutral': 'ä¸­æ€§',
        'pessimistic': 'æ‚²è§‚',
        'panic': 'ææ…Œ',
        'insufficient_data': 'æ•°æ®ä¸è¶³'
    }
    return translations.get(state, state)


def _translate_risk_level(level: str) -> str:
    """ç¿»è¯‘é£é™©ç­‰çº§"""
    translations = {
        'high': 'é«˜é£é™©',
        'medium': 'ä¸­ç­‰é£é™©',
        'low': 'ä½é£é™©',
        'unknown': 'æœªçŸ¥'
    }
    return translations.get(level, level)


def _get_investment_advice(market_state: str, trend_5d: float, risk_level: str) -> str:
    """è·å–æŠ•èµ„å»ºè®®"""
    if market_state == 'euphoric':
        return "å¸‚åœºè¿‡çƒ­ï¼Œå»ºè®®å‡ä»“è§‚æœ›"
    elif market_state == 'panic':
        return "å¸‚åœºææ…Œï¼Œå¯é€‚åº¦é€¢ä½å¸ƒå±€"
    elif market_state == 'optimistic' and trend_5d > 0:
        return "å¸‚åœºå‘å¥½ï¼Œå¯é€‚å½“å¢ä»“"
    elif market_state == 'pessimistic' and trend_5d < 0:
        return "å¸‚åœºç–²å¼±ï¼Œå»ºè®®æ§åˆ¶ä»“ä½"
    else:
        return "å¸‚åœºä¸­æ€§ï¼Œä¿æŒå‡è¡¡é…ç½®"


def get_msci_professional_terminology(market_state: str) -> dict:
    """
    è·å–MSCIä¸“ä¸šæœ¯è¯­æè¿° - æ–°å¢å‡½æ•°
    
    å‚æ•°:
        market_state (str): å¸‚åœºçŠ¶æ€åˆ†ç±»
        
    è¿”å›:
        dict: åŒ…å«ä¸“ä¸šæœ¯è¯­å’ŒæŠ•èµ„ç­–ç•¥çš„æè¿°
    """
    terminology = {
        'extreme_euphoria': {
            'state': 'æåº¦äº¢å¥‹',
            'description': 'å¸‚åœºæƒ…ç»ªè¿‡åº¦ä¹è§‚ï¼Œå­˜åœ¨æ˜æ˜¾æ³¡æ²«é£é™©ï¼ŒæŠ€æœ¯æŒ‡æ ‡ä¸¥é‡è¶…ä¹°',
            'strategy': 'ğŸ”´ é£é™©è§„é¿ç­–ç•¥ï¼šå»ºè®®å¤§å¹…å‡ä»“è§‚æœ›ï¼Œé˜²èŒƒç³»ç»Ÿæ€§è°ƒæ•´é£é™©',
            'risk_level': 'æé«˜é£é™©',
            'opportunity': 'ç­‰å¾…è°ƒæ•´æœºä¼š',
            'time_horizon': 'çŸ­æœŸå†…è°¨æ…ï¼Œä¸­æœŸç­‰å¾…å›è°ƒ'
        },
        'healthy_optimism': {
            'state': 'å¥åº·ä¹è§‚',
            'description': 'å¸‚åœºæƒ…ç»ªç§¯æå‘ä¸Šï¼Œç‰›å¸‚æ ¼å±€ç¡®ç«‹ï¼ŒåŸºæœ¬é¢ä¸æŠ€æœ¯é¢å…±æŒ¯',
            'strategy': 'ğŸŸ¢ ç§¯æé…ç½®ç­–ç•¥ï¼šé€‚åˆä¸­é•¿æœŸæŠ•èµ„å¸ƒå±€ï¼Œäº«å—ç‰›å¸‚æ”¶ç›Š',
            'risk_level': 'ä½é£é™©',
            'opportunity': 'ä¼˜è´¨èµ„äº§é…ç½®æœŸ',
            'time_horizon': 'ä¸­é•¿æœŸæŒæœ‰ä¸ºä¸»'
        },
        'cautious_optimism': {
            'state': 'è°¨æ…ä¹è§‚',
            'description': 'å¸‚åœºæƒ…ç»ªåå‘ä¹è§‚ï¼Œä½†éœ€ä¿æŒç†æ€§ï¼ŒæŠ€æœ¯é¢åå¼º',
            'strategy': 'ğŸŸ¡ å‡è¡¡é…ç½®ç­–ç•¥ï¼šé€‚åº¦å‚ä¸ï¼Œæ³¨é‡é£é™©æ§åˆ¶',
            'risk_level': 'ä¸­ç­‰é£é™©',
            'opportunity': 'ç»“æ„æ€§æœºä¼šæ˜¾ç°',
            'time_horizon': 'ä¸­æœŸé…ç½®ï¼Œçµæ´»è°ƒæ•´'
        },
        'neutral_sentiment': {
            'state': 'æƒ…ç»ªä¸­æ€§',
            'description': 'å¸‚åœºæƒ…ç»ªå‡è¡¡ï¼Œå¤šç©ºåŠ›é‡åŸºæœ¬ç›¸å½“ï¼Œæ–¹å‘é€‰æ‹©å¾…æ˜ç¡®',
            'strategy': 'âš–ï¸ ä¸­æ€§ç­–ç•¥ï¼šä¿æŒè§‚æœ›ï¼Œç­‰å¾…æ–¹å‘æ˜ç¡®åå†åšå†³ç­–',
            'risk_level': 'ä¸­ç­‰é£é™©',
            'opportunity': 'ç­‰å¾…çªç ´æ–¹å‘',
            'time_horizon': 'çŸ­æœŸè§‚æœ›ï¼Œä¸­æœŸå¾…å®š'
        },
        'mild_pessimism': {
            'state': 'è½»åº¦æ‚²è§‚',
            'description': 'å¸‚åœºæƒ…ç»ªåå‘æ‚²è§‚ï¼Œä½†æœªè¾¾ææ…Œï¼ŒæŠ€æœ¯é¢åå¼±',
            'strategy': 'ğŸŸ¡ è°¨æ…è§‚æœ›ç­–ç•¥ï¼šä¸¥æ§ä»“ä½ï¼Œå¯»æ‰¾é˜²å¾¡æ€§æœºä¼š',
            'risk_level': 'ä¸­é«˜é£é™©',
            'opportunity': 'é˜²å¾¡æ€§èµ„äº§é…ç½®',
            'time_horizon': 'çŸ­æœŸé˜²å¾¡ï¼Œç­‰å¾…è½¬æœº'
        },
        'significant_pessimism': {
            'state': 'æ˜¾è‘—æ‚²è§‚',
            'description': 'å¸‚åœºæƒ…ç»ªæ˜æ˜¾ä½è¿·ï¼Œç†Šå¸‚ç‰¹å¾æ˜¾ç°ï¼ŒæŠ€æœ¯é¢ç–²å¼±',
            'strategy': 'ğŸ”¶ é˜²å¾¡ç­–ç•¥ï¼šä»¥èµ„æœ¬ä¿å…¨ä¸ºå…ˆï¼Œç­‰å¾…å¸‚åœºè½¬æœºä¿¡å·',
            'risk_level': 'é«˜é£é™©',
            'opportunity': 'ç°é‡‘ä¸ºç‹ï¼Œç­‰å¾…åº•éƒ¨',
            'time_horizon': 'ä¸­æœŸé˜²å¾¡ï¼Œç­‰å¾…åè½¬'
        },
        'panic_selling': {
            'state': 'ææ…ŒæŠ›å”®',
            'description': 'å¸‚åœºæåº¦ææ…Œï¼Œå¯èƒ½æ¥è¿‘å‘¨æœŸåº•éƒ¨ï¼ŒæŠ€æœ¯é¢è¶…å–ä¸¥é‡',
            'strategy': 'ğŸŸ¢ é€†å‘æŠ•èµ„ç­–ç•¥ï¼šææ…Œä¸­è•´å«é•¿æœŸæœºä¼šï¼Œåˆ†æ‰¹å»ºä»“ä¼˜è´¨èµ„äº§',
            'risk_level': 'é«˜é£é™©é«˜æ”¶ç›Š',
            'opportunity': 'å†å²æ€§æŠ•èµ„æœºä¼š',
            'time_horizon': 'é•¿æœŸå¸ƒå±€ï¼Œè€å¿ƒç­‰å¾…'
        }
    }
    
    return terminology.get(market_state, {
        'state': 'æœªçŸ¥çŠ¶æ€',
        'description': 'å¸‚åœºæƒ…ç»ªçŠ¶æ€ä¸æ˜ç¡®',
        'strategy': 'â“ è§‚æœ›ç­–ç•¥ï¼šç­‰å¾…æ˜ç¡®ä¿¡å·',
        'risk_level': 'ä¸ç¡®å®š',
        'opportunity': 'æš‚æ— æ˜ç¡®æœºä¼š',
        'time_horizon': 'çŸ­æœŸè§‚æœ›'
    })


def generate_market_investment_advice(msci_value: float, market_state: str, trend_5d: float) -> dict:
    """
    ç”Ÿæˆå¸‚åœºæŠ•èµ„å»ºè®® - æ–°å¢å‡½æ•°
    åŸºäºMSCIå€¼ã€å¸‚åœºçŠ¶æ€å’Œè¶‹åŠ¿å˜åŒ–æä¾›å…·ä½“å»ºè®®
    
    å‚æ•°:
        msci_value (float): MSCIæŒ‡æ•°å€¼
        market_state (str): å¸‚åœºçŠ¶æ€
        trend_5d (float): 5æ—¥è¶‹åŠ¿å˜åŒ–
        
    è¿”å›:
        dict: è¯¦ç»†çš„æŠ•èµ„å»ºè®®
    """
    # è·å–ä¸“ä¸šæœ¯è¯­
    terminology = get_msci_professional_terminology(market_state)
    
    # åŸºäºMSCIå€¼çš„ä»“ä½å»ºè®®
    if msci_value >= 85:
        position_advice = 'å»ºè®®ä»“ä½ï¼š10-30%ï¼ˆæåº¦è°¨æ…ï¼‰'
        action = 'å¤§å¹…å‡ä»“'
    elif msci_value >= 65:
        position_advice = 'å»ºè®®ä»“ä½ï¼š70-90%ï¼ˆç§¯æé…ç½®ï¼‰'
        action = 'æ­£å¸¸é…ç½®'
    elif msci_value >= 55:
        position_advice = 'å»ºè®®ä»“ä½ï¼š50-70%ï¼ˆå‡è¡¡é…ç½®ï¼‰'
        action = 'é€‚åº¦é…ç½®'
    elif msci_value >= 45:
        position_advice = 'å»ºè®®ä»“ä½ï¼š30-50%ï¼ˆä¸­æ€§è§‚æœ›ï¼‰'
        action = 'è§‚æœ›ä¸ºä¸»'
    elif msci_value >= 35:
        position_advice = 'å»ºè®®ä»“ä½ï¼š20-40%ï¼ˆè°¨æ…é˜²å¾¡ï¼‰'
        action = 'é˜²å¾¡æ€§é…ç½®'
    elif msci_value >= 25:
        position_advice = 'å»ºè®®ä»“ä½ï¼š10-30%ï¼ˆä¸¥æ ¼é˜²å¾¡ï¼‰'
        action = 'ä¸¥æ§ä»“ä½'
    else:
        position_advice = 'å»ºè®®ä»“ä½ï¼š30-60%ï¼ˆé€†å‘å¸ƒå±€ï¼‰'
        action = 'åˆ†æ‰¹å»ºä»“'
    
    # åŸºäºè¶‹åŠ¿çš„æ“ä½œå»ºè®®
    if trend_5d > 10:
        trend_advice = 'å¸‚åœºæƒ…ç»ªå¿«é€Ÿå‡æ¸©ï¼Œæ³¨æ„è¿½é«˜é£é™©'
    elif trend_5d > 5:
        trend_advice = 'å¸‚åœºæƒ…ç»ªç¨³æ­¥å›å‡ï¼Œå¯é€‚åº¦å‚ä¸'
    elif trend_5d < -10:
        trend_advice = 'å¸‚åœºæƒ…ç»ªå¿«é€Ÿæ¶åŒ–ï¼Œæ³¨æ„æ­¢æŸ'
    elif trend_5d < -5:
        trend_advice = 'å¸‚åœºæƒ…ç»ªé€æ­¥è½¬å¼±ï¼Œä¿æŒè°¨æ…'
    else:
        trend_advice = 'å¸‚åœºæƒ…ç»ªç›¸å¯¹ç¨³å®šï¼Œç»´æŒç­–ç•¥'
    
    return {
        'primary_strategy': terminology['strategy'],
        'position_advice': position_advice,
        'action_recommendation': action,
        'trend_guidance': trend_advice,
        'risk_assessment': terminology['risk_level'],
        'opportunity_description': terminology['opportunity'],
        'time_horizon': terminology['time_horizon'],
        'market_description': terminology['description']
    }


# æ¨¡å—æµ‹è¯•å‡½æ•°
def test_msci_calculator():
    """æµ‹è¯•MSCIè®¡ç®—å™¨åŠŸèƒ½"""
    print("æµ‹è¯• æµ‹è¯•MSCIè®¡ç®—å™¨...")
    
    # æ„é€ æµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'è‚¡ç¥¨ä»£ç ': [f"00000{i}" for i in range(1, 101)],
        'è‚¡ç¥¨åç§°': [f"æµ‹è¯•è‚¡ç¥¨{i}" for i in range(1, 101)],
        'è¡Œä¸š': ['é“¶è¡Œ'] * 20 + ['ç§‘æŠ€'] * 30 + ['åœ°äº§'] * 25 + ['åˆ¶é€ '] * 25,
        '20250601': ['ä¸­ç©º'] * 60 + ['å¾®å¤š'] * 25 + ['å°å¤š'] * 10 + ['ä¸­å¤š'] * 5,
        '20250602': ['ä¸­ç©º'] * 50 + ['å¾®å¤š'] * 30 + ['å°å¤š'] * 15 + ['ä¸­å¤š'] * 5,
        '20250603': ['å°ç©º'] * 40 + ['å¾®å¤š'] * 35 + ['å°å¤š'] * 20 + ['ä¸­å¤š'] * 5,
        '20250604': ['å¾®ç©º'] * 30 + ['å¾®å¤š'] * 40 + ['å°å¤š'] * 25 + ['ä¸­å¤š'] * 5,
        '20250605': ['å¾®å¤š'] * 45 + ['å°å¤š'] * 30 + ['ä¸­å¤š'] * 20 + ['å¤§å¤š'] * 5
    })
    
    # æµ‹è¯•MSCIè®¡ç®—
    result = calculate_market_sentiment_composite_index(test_data)
    print(f"   MSCIæµ‹è¯•: æŒ‡æ•°={result['current_msci']}, çŠ¶æ€={result['market_state']}")
    
    # æµ‹è¯•æç«¯çŠ¶æ€åˆ†æ
    if result['history']:
        extremes = analyze_market_extremes(result['history'])
        print(f"   æç«¯åˆ†æ: æ³¢åŠ¨æ€§={extremes.get('volatility', 0)}")
    
    # æµ‹è¯•é£é™©é¢„è­¦
    warnings = generate_risk_warnings(
        result['market_state'], 
        result['latest_analysis'], 
        result['trend_5d']
    )
    print(f"   é£é™©é¢„è­¦: {len(warnings)} æ¡é¢„è­¦")
    
    # æµ‹è¯•å¸‚åœºæ€»ç»“
    summary = get_msci_market_summary(result)
    print(f"   å¸‚åœºæ€»ç»“: {summary.get('sentiment_description', 'æœªçŸ¥')}")
    
    print("æˆåŠŸ MSCIè®¡ç®—å™¨æµ‹è¯•å®Œæˆ")
    return True


class MSCICalculator:
    """
    MSCIç®—æ³•è®¡ç®—å™¨ç±»
    
    æä¾›é¢å‘å¯¹è±¡çš„MSCIè®¡ç®—æ¥å£ï¼Œä¾¿äºå®ä¾‹åŒ–å’Œé…ç½®ç®¡ç†
    """
    
    def __init__(self, rating_map: Dict = None, min_data_days: int = 5, enable_cache: bool = True):
        """
        åˆå§‹åŒ–MSCIè®¡ç®—å™¨
        
        å‚æ•°:
            rating_map (dict): è¯„çº§æ˜ å°„è¡¨ï¼Œé»˜è®¤ä½¿ç”¨RATING_SCORE_MAP
            min_data_days (int): æœ€å°‘æ•°æ®å¤©æ•°è¦æ±‚ï¼Œé»˜è®¤5å¤©
            enable_cache (bool): æ˜¯å¦å¯ç”¨ç»“æœç¼“å­˜ï¼Œé»˜è®¤å¯ç”¨
        """
        self.rating_map = rating_map or RATING_SCORE_MAP
        self.min_data_days = min_data_days
        self.calculation_count = 0
        self.enable_cache = enable_cache
        self._cache = {} if enable_cache else None
        
        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_calculations': 0,
            'cache_hits': 0,
            'total_time': 0.0,
            'avg_time_per_calc': 0.0
        }
    
    def calculate(self, all_data: pd.DataFrame, cache_key: str = None) -> Dict[str, Union[float, str, int, List, Dict]]:
        """
        è®¡ç®—å¸‚åœºæƒ…ç»ªç»¼åˆæŒ‡æ•°
        
        å‚æ•°:
            all_data (pd.DataFrame): å…¨å¸‚åœºè‚¡ç¥¨æ•°æ®
            cache_key (str): ç¼“å­˜é”®ï¼Œç”¨äºæ ‡è¯†æ•°æ®ç‰ˆæœ¬
            
        è¿”å›:
            dict: MSCIè®¡ç®—ç»“æœ
        """
        self.calculation_count += 1
        start_time = datetime.now()
        
        # ç¼“å­˜æ£€æŸ¥
        if self.enable_cache and cache_key:
            if cache_key in self._cache:
                self.stats['cache_hits'] += 1
                return self._cache[cache_key]
        
        # æ‰§è¡Œè®¡ç®—
        result = calculate_market_sentiment_composite_index(all_data)
        
        # æ›´æ–°ç»Ÿè®¡
        calc_time = (datetime.now() - start_time).total_seconds()
        self.stats['total_calculations'] += 1
        self.stats['total_time'] += calc_time
        self.stats['avg_time_per_calc'] = self.stats['total_time'] / self.stats['total_calculations']
        
        # å­˜å‚¨ç¼“å­˜
        if self.enable_cache and cache_key:
            self._cache[cache_key] = result
        
        return result
    
    def analyze_extremes(self, msci_history: List[Dict]) -> Dict[str, Union[int, float, List]]:
        """
        åˆ†æå¸‚åœºæç«¯çŠ¶æ€
        
        å‚æ•°:
            msci_history (List[Dict]): MSCIå†å²æ•°æ®
            
        è¿”å›:
            dict: æç«¯çŠ¶æ€åˆ†æç»“æœ
        """
        return analyze_market_extremes(msci_history)
    
    def generate_warnings(self, market_state: str, latest_analysis: Dict, trend_5d: float) -> List[str]:
        """
        ç”Ÿæˆé£é™©é¢„è­¦
        
        å‚æ•°:
            market_state (str): å¸‚åœºçŠ¶æ€
            latest_analysis (dict): æœ€æ–°åˆ†ææ•°æ®
            trend_5d (float): 5æ—¥è¶‹åŠ¿
            
        è¿”å›:
            list: é£é™©é¢„è­¦åˆ—è¡¨
        """
        return generate_risk_warnings(market_state, latest_analysis, trend_5d)
    
    def get_market_summary(self, msci_result: Dict) -> Dict[str, Union[str, float, int]]:
        """
        è·å–å¸‚åœºæ‘˜è¦ä¿¡æ¯
        
        å‚æ•°:
            msci_result (dict): MSCIè®¡ç®—ç»“æœ
            
        è¿”å›:
            dict: å¸‚åœºæ‘˜è¦
        """
        return get_msci_market_summary(msci_result)
    
    def get_professional_terminology(self, market_state: str) -> dict:
        """
        è·å–ä¸“ä¸šæœ¯è¯­è§£é‡Š
        
        å‚æ•°:
            market_state (str): å¸‚åœºçŠ¶æ€
            
        è¿”å›:
            dict: ä¸“ä¸šæœ¯è¯­è§£é‡Š
        """
        return get_msci_professional_terminology(market_state)
    
    def generate_investment_advice(self, msci_value: float, market_state: str, trend_5d: float) -> dict:
        """
        ç”ŸæˆæŠ•èµ„å»ºè®®
        
        å‚æ•°:
            msci_value (float): MSCIæŒ‡æ•°å€¼
            market_state (str): å¸‚åœºçŠ¶æ€
            trend_5d (float): 5æ—¥è¶‹åŠ¿
            
        è¿”å›:
            dict: æŠ•èµ„å»ºè®®
        """
        return generate_market_investment_advice(msci_value, market_state, trend_5d)
    
    def get_performance_stats(self) -> Dict[str, Union[int, float, str]]:
        """è·å–æ€§èƒ½ç»Ÿè®¡ä¿¡æ¯"""
        cache_hit_rate = (self.stats['cache_hits'] / max(1, self.stats['total_calculations'])) * 100
        
        return {
            'total_calculations': self.stats['total_calculations'],
            'cache_hits': self.stats['cache_hits'],
            'cache_hit_rate': f"{cache_hit_rate:.1f}%",
            'total_time': f"{self.stats['total_time']:.3f}s",
            'avg_time_per_calc': f"{self.stats['avg_time_per_calc']*1000:.2f}ms",
            'cache_enabled': self.enable_cache,
            'cache_size': len(self._cache) if self._cache else 0
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        if self._cache:
            self._cache.clear()
            print("æˆåŠŸ MSCIè®¡ç®—å™¨ç¼“å­˜å·²æ¸…ç©º")
    
    def reset_counter(self):
        """é‡ç½®è®¡ç®—è®¡æ•°å™¨"""
        self.calculation_count = 0
        self.stats = {
            'total_calculations': 0,
            'cache_hits': 0,
            'total_time': 0.0,
            'avg_time_per_calc': 0.0
        }
    
    def __str__(self):
        cache_info = f", cache={len(self._cache) if self._cache else 0}" if self.enable_cache else ""
        return f"MSCICalculator(calculations={self.calculation_count}, min_days={self.min_data_days}{cache_info})"


if __name__ == "__main__":
    test_msci_calculator()