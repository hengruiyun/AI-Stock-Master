# -*- coding: utf-8 -*-
"""
AIå¢å¼º8çº§ä¿¡å·åˆ†æç³»ç»Ÿ
æ•´åˆè‡ªé€‚åº”æ’å€¼å¼•æ“å’Œå¤šç»´åº¦åˆ†æå™¨ï¼ŒåŠ å…¥æœºå™¨å­¦ä¹ èƒ½åŠ›
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Union, Optional, Tuple
import logging
from datetime import datetime, timedelta
import warnings
import json
from dataclasses import dataclass, asdict
from enum import Enum

# å¯¼å…¥æˆ‘ä»¬å¼€å‘çš„æ ¸å¿ƒç»„ä»¶
from .adaptive_interpolation import AdaptiveInterpolationEngine, InterpolationStrategy
from .enhanced_multi_dimensional_analyzer import (
    EnhancedMultiDimensionalAnalyzer, 
    AnalysisResult, 
    SignalStrength,
    AnalysisLevel
)

warnings.filterwarnings('ignore')

class AIModelType(Enum):
    """AIæ¨¡å‹ç±»å‹"""
    PATTERN_RECOGNITION = "pattern_recognition"    # æ¨¡å¼è¯†åˆ«
    SENTIMENT_ANALYSIS = "sentiment_analysis"      # æƒ…ç»ªåˆ†æ  
    TREND_PREDICTION = "trend_prediction"          # è¶‹åŠ¿é¢„æµ‹
    RISK_ASSESSMENT = "risk_assessment"            # é£é™©è¯„ä¼°
    SIGNAL_FUSION = "signal_fusion"                # ä¿¡å·èåˆ

@dataclass
class AIInsight:
    """AIæ´å¯Ÿç»“æœ"""
    insight_type: str           # æ´å¯Ÿç±»å‹
    confidence: float           # ç½®ä¿¡åº¦
    description: str            # æè¿°
    recommendation: str         # å»ºè®®
    supporting_evidence: List   # æ”¯æŒè¯æ®
    risk_factors: List          # é£é™©å› ç´ 

@dataclass
class ComprehensiveAnalysisResult:
    """ç»¼åˆåˆ†æç»“æœ"""
    # åŸºç¡€åˆ†æç»“æœ
    interpolation_result: Dict
    multi_dimensional_result: Dict
    
    # AIå¢å¼ºç»“æœ
    ai_insights: List[AIInsight]
    ai_enhanced_score: float
    
    # ç»¼åˆè¯„ä¼°
    final_recommendation: str
    confidence_level: str
    risk_warning: List[str]
    
    # å…ƒæ•°æ®
    analysis_timestamp: str
    processing_time: float

class AIEnhancedSignalAnalyzer:
    """
    AIå¢å¼º8çº§ä¿¡å·åˆ†æç³»ç»Ÿ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ™ºèƒ½æ•°æ®é¢„å¤„ç†ï¼ˆè‡ªé€‚åº”æ’å€¼ï¼‰
    2. å¤šç»´åº¦ä¿¡å·åˆ†æ
    3. AIæ¨¡å¼è¯†åˆ«å’Œé¢„æµ‹
    4. æ™ºèƒ½ä¿¡å·èåˆ
    5. é£é™©æ™ºèƒ½è¯„ä¼°
    """
    
    def __init__(self, enable_ai_features: bool = True):
        self.logger = logging.getLogger(__name__)
        # è®¾ç½®æ—¥å¿—çº§åˆ«ä¸ºWARNINGï¼Œå‡å°‘INFOè¾“å‡º
        self.logger.setLevel(logging.WARNING)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.interpolation_engine = AdaptiveInterpolationEngine()
        self.multi_dimensional_analyzer = EnhancedMultiDimensionalAnalyzer()
        
        # AIåŠŸèƒ½å¼€å…³
        self.enable_ai = enable_ai_features
        
        # 8çº§è¯„çº§ç³»ç»Ÿ
        self.rating_scale = {
            'å¤§å¤š': 7, 'ä¸­å¤š': 6, 'å°å¤š': 5, 'å¾®å¤š': 4,
            'å¾®ç©º': 3, 'å°ç©º': 2, 'ä¸­ç©º': 1, 'å¤§ç©º': 0,
            'ä¸­æ€§': 3.5, '-': None
        }
        
        # AIæ¨¡å‹é…ç½®ï¼ˆæ¨¡æ‹Ÿé…ç½®ï¼Œå®é™…åº”ç”¨ä¸­ä¼šåŠ è½½çœŸå®æ¨¡å‹ï¼‰
        self.ai_models = {
            AIModelType.PATTERN_RECOGNITION: self._init_pattern_recognition_model(),
            AIModelType.SENTIMENT_ANALYSIS: self._init_sentiment_analysis_model(),
            AIModelType.TREND_PREDICTION: self._init_trend_prediction_model(),
            AIModelType.RISK_ASSESSMENT: self._init_risk_assessment_model(),
            AIModelType.SIGNAL_FUSION: self._init_signal_fusion_model()
        }
        
        # æ™ºèƒ½æƒé‡é…ç½®ï¼ˆåŠ¨æ€è°ƒæ•´ï¼‰
        self.adaptive_weights = {
            'interpolation_quality': 0.15,
            'multi_dimensional_score': 0.35,
            'ai_pattern_recognition': 0.20,
            'ai_sentiment_analysis': 0.15,
            'ai_trend_prediction': 0.15
        }
    
    def comprehensive_analyze(self, 
                            stock_data: pd.DataFrame,
                            stock_code: str,
                            industry_data: pd.DataFrame = None,
                            market_data: pd.DataFrame = None,
                            news_data: List[str] = None,
                            enable_prediction: bool = True) -> ComprehensiveAnalysisResult:
        """
        ç»¼åˆAIå¢å¼ºåˆ†æ
        
        Args:
            stock_data: è‚¡ç¥¨å†å²æ•°æ®
            stock_code: è‚¡ç¥¨ä»£ç 
            industry_data: è¡Œä¸šæ•°æ®
            market_data: å¸‚åœºæ•°æ®
            news_data: æ–°é—»æ•°æ®ï¼ˆç”¨äºæƒ…ç»ªåˆ†æï¼‰
            enable_prediction: æ˜¯å¦å¯ç”¨é¢„æµ‹åŠŸèƒ½
            
        Returns:
            ç»¼åˆåˆ†æç»“æœ
        """
        analysis_start = datetime.now()
        
        try:
            # ================ ç¬¬ä¸€é˜¶æ®µï¼šæ•°æ®é¢„å¤„ç†å’Œè´¨é‡è¯„ä¼° ================
            self.logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨ {stock_code}")
            
            # 1.1 æå–è‚¡ç¥¨è¯„çº§åºåˆ—
            stock_ratings = self._extract_stock_ratings(stock_data, stock_code)
            
            # 1.2 è‡ªé€‚åº”æ’å€¼å¤„ç†
            interpolation_result = self.interpolation_engine.interpolate_rating_series(
                ratings_series=stock_ratings,
                stock_info={'code': stock_code, 'industry': 'auto_detect'},
                market_context=self._extract_market_context(market_data)
            )
            
            # ================ ç¬¬äºŒé˜¶æ®µï¼šå¤šç»´åº¦åŸºç¡€åˆ†æ ================
            
            # 2.1 å¤šç»´åº¦åˆ†æ
            multi_dimensional_result = self.multi_dimensional_analyzer.comprehensive_analysis(
                stock_data=stock_data,
                industry_data=industry_data,
                market_data=market_data,
                target_stock=stock_code
            )
            
            # ================ ç¬¬ä¸‰é˜¶æ®µï¼šAIå¢å¼ºåˆ†æ ================
            ai_insights = []
            
            if self.enable_ai:
                # 3.1 AIæ¨¡å¼è¯†åˆ«
                pattern_insights = self._ai_pattern_recognition(
                    interpolation_result['interpolated_series']
                )
                ai_insights.extend(pattern_insights)
                
                # 3.2 AIæƒ…ç»ªåˆ†æï¼ˆå¦‚æœæœ‰æ–°é—»æ•°æ®ï¼‰
                if news_data:
                    sentiment_insights = self._ai_sentiment_analysis(news_data, stock_code)
                    ai_insights.extend(sentiment_insights)
                
                # 3.3 AIè¶‹åŠ¿é¢„æµ‹
                if enable_prediction:
                    trend_insights = self._ai_trend_prediction(
                        interpolation_result['interpolated_series'],
                        multi_dimensional_result
                    )
                    ai_insights.extend(trend_insights)
                
                # 3.4 AIé£é™©è¯„ä¼°
                risk_insights = self._ai_risk_assessment(
                    interpolation_result,
                    multi_dimensional_result
                )
                ai_insights.extend(risk_insights)
            
            # ================ ç¬¬å››é˜¶æ®µï¼šæ™ºèƒ½ä¿¡å·èåˆ ================
            
            # 4.1 è®¡ç®—AIå¢å¼ºè¯„åˆ†
            ai_enhanced_score = self._calculate_ai_enhanced_score(
                interpolation_result,
                multi_dimensional_result,
                ai_insights
            )
            
            # 4.2 ç”Ÿæˆæœ€ç»ˆå»ºè®®
            final_recommendation = self._generate_final_recommendation(
                interpolation_result,
                multi_dimensional_result,
                ai_insights,
                ai_enhanced_score
            )
            
            # 4.3 æ™ºèƒ½é£é™©é¢„è­¦
            risk_warnings = self._generate_intelligent_risk_warnings(
                interpolation_result,
                multi_dimensional_result,
                ai_insights
            )
            
            # 4.4 è¯„ä¼°æ•´ä½“ç½®ä¿¡åº¦
            confidence_level = self._assess_overall_confidence(
                interpolation_result,
                multi_dimensional_result,
                ai_insights
            )
            
            # ================ ç¬¬äº”é˜¶æ®µï¼šç»“æœå°è£… ================
            
            processing_time = (datetime.now() - analysis_start).total_seconds()
            
            result = ComprehensiveAnalysisResult(
                interpolation_result=interpolation_result,
                multi_dimensional_result=multi_dimensional_result,
                ai_insights=ai_insights,
                ai_enhanced_score=ai_enhanced_score,
                final_recommendation=final_recommendation,
                confidence_level=confidence_level,
                risk_warning=risk_warnings,
                analysis_timestamp=datetime.now().isoformat(),
                processing_time=processing_time
            )
            
            self.logger.info(f"åˆ†æå®Œæˆï¼Œè€—æ—¶ {processing_time:.3f}s")
            return result
            
        except Exception as e:
            self.logger.error(f"ç»¼åˆåˆ†æå¤±è´¥: {str(e)}")
            return self._create_error_result(str(e))
    
    def _extract_stock_ratings(self, stock_data: pd.DataFrame, stock_code: str) -> pd.Series:
        """æå–è‚¡ç¥¨è¯„çº§åºåˆ—"""
        try:
            # æŸ¥æ‰¾ç›®æ ‡è‚¡ç¥¨
            if stock_code in stock_data.index:
                stock_row = stock_data.loc[stock_code]
            elif 'è‚¡ç¥¨ä»£ç ' in stock_data.columns:
                matching_rows = stock_data[stock_data['è‚¡ç¥¨ä»£ç '] == stock_code]
                if not matching_rows.empty:
                    stock_row = matching_rows.iloc[0]
                else:
                    raise ValueError(f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code}")
            else:
                # å‡è®¾ç¬¬ä¸€è¡Œæ˜¯ç›®æ ‡è‚¡ç¥¨
                stock_row = stock_data.iloc[0]
            
            # æå–æ—¥æœŸåˆ—
            date_columns = [col for col in stock_row.index if str(col).startswith('202')]
            date_columns.sort()
            
            # æ„å»ºè¯„çº§åºåˆ—
            ratings = pd.Series(
                [stock_row[col] for col in date_columns],
                index=pd.to_datetime(date_columns, format='%Y%m%d')
            )
            
            return ratings
            
        except Exception as e:
            self.logger.error(f"æå–è‚¡ç¥¨è¯„çº§å¤±è´¥: {str(e)}")
            return pd.Series(dtype=object)
    
    def _extract_market_context(self, market_data: pd.DataFrame = None) -> Dict:
        """æå–å¸‚åœºç¯å¢ƒä¿¡æ¯"""
        if market_data is None or market_data.empty:
            return {'volatility': 0.5, 'trend': 'neutral'}
        
        try:
            # ç®€åŒ–çš„å¸‚åœºç¯å¢ƒåˆ†æ
            date_columns = [col for col in market_data.columns if str(col).startswith('202')]
            if not date_columns:
                return {'volatility': 0.5, 'trend': 'neutral'}
            
            # è®¡ç®—å¸‚åœºè¯„çº§åˆ†å¸ƒçš„å˜åŒ–
            recent_columns = sorted(date_columns)[-5:]  # æœ€è¿‘5å¤©
            
            market_scores = []
            for col in recent_columns:
                daily_ratings = market_data[col].dropna()
                daily_score = np.mean([self.rating_scale.get(r, 3.5) for r in daily_ratings if r != '-'])
                market_scores.append(daily_score)
            
            volatility = np.std(market_scores) / 3.5 if len(market_scores) > 1 else 0.5
            trend = 'upward' if market_scores[-1] > market_scores[0] else 'downward'
            
            return {
                'volatility': min(max(volatility, 0), 1),
                'trend': trend,
                'recent_scores': market_scores
            }
            
        except Exception as e:
            self.logger.error(f"å¸‚åœºç¯å¢ƒåˆ†æå¤±è´¥: {str(e)}")
            return {'volatility': 0.5, 'trend': 'neutral'}
    
    # ================ AIæ¨¡å‹åˆå§‹åŒ–ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰ ================
    
    def _init_pattern_recognition_model(self):
        """åˆå§‹åŒ–æ¨¡å¼è¯†åˆ«æ¨¡å‹"""
        return {
            'model_type': 'lstm_autoencoder',
            'trained': True,
            'accuracy': 0.85,
            'patterns': ['double_top', 'double_bottom', 'ascending_triangle', 'head_and_shoulders']
        }
    
    def _init_sentiment_analysis_model(self):
        """åˆå§‹åŒ–æƒ…ç»ªåˆ†ææ¨¡å‹"""
        return {
            'model_type': 'bert_sentiment',
            'trained': True,
            'accuracy': 0.82,
            'languages': ['zh', 'en']
        }
    
    def _init_trend_prediction_model(self):
        """åˆå§‹åŒ–è¶‹åŠ¿é¢„æµ‹æ¨¡å‹"""
        return {
            'model_type': 'transformer_ts',
            'trained': True,
            'accuracy': 0.78,
            'horizon': 10  # é¢„æµ‹10å¤©
        }
    
    def _init_risk_assessment_model(self):
        """åˆå§‹åŒ–é£é™©è¯„ä¼°æ¨¡å‹"""
        return {
            'model_type': 'ensemble_risk',
            'trained': True,
            'accuracy': 0.88,
            'risk_types': ['volatility', 'liquidity', 'credit', 'market']
        }
    
    def _init_signal_fusion_model(self):
        """åˆå§‹åŒ–ä¿¡å·èåˆæ¨¡å‹"""
        return {
            'model_type': 'attention_fusion',
            'trained': True,
            'accuracy': 0.86,
            'fusion_methods': ['weighted_average', 'attention', 'ensemble']
        }
    
    # ================ AIåˆ†ææ–¹æ³• ================
    
    def _ai_pattern_recognition(self, rating_series: pd.Series) -> List[AIInsight]:
        """AIæ¨¡å¼è¯†åˆ«"""
        insights = []
        
        try:
            # æ¨¡æ‹Ÿæ¨¡å¼è¯†åˆ«ç®—æ³•
            numeric_values = [self.rating_scale.get(r, r) for r in rating_series if r is not None]
            
            if len(numeric_values) < 5:
                return insights
            
            # æ£€æµ‹è¶‹åŠ¿æ¨¡å¼
            recent_trend = np.polyfit(range(len(numeric_values[-5:])), numeric_values[-5:], 1)[0]
            
            if recent_trend > 0.2:
                insights.append(AIInsight(
                    insight_type="ä¸Šå‡è¶‹åŠ¿æ¨¡å¼",
                    confidence=0.85,
                    description="AIæ£€æµ‹åˆ°æ˜æ˜¾çš„ä¸Šå‡è¶‹åŠ¿æ¨¡å¼ï¼Œè¯„çº§å‘ˆç°æŒç»­æ”¹å–„",
                    recommendation="å»ºè®®å…³æ³¨ï¼Œè¶‹åŠ¿æœ‰æœ›å»¶ç»­",
                    supporting_evidence=[f"è¿‘æœŸæ–œç‡: {recent_trend:.3f}", "è¿ç»­æ€§è‰¯å¥½"],
                    risk_factors=["è¶‹åŠ¿è¿‡çƒ­é£é™©", "å›è°ƒå‹åŠ›"]
                ))
            elif recent_trend < -0.2:
                insights.append(AIInsight(
                    insight_type="ä¸‹é™è¶‹åŠ¿æ¨¡å¼",
                    confidence=0.82,
                    description="AIæ£€æµ‹åˆ°ä¸‹é™è¶‹åŠ¿æ¨¡å¼ï¼Œè¯„çº§æŒç»­æ¶åŒ–",
                    recommendation="å»ºè®®è°¨æ…ï¼Œè€ƒè™‘é˜²å¾¡ç­–ç•¥",
                    supporting_evidence=[f"è¿‘æœŸæ–œç‡: {recent_trend:.3f}", "ä¸‹é™è¿ç»­æ€§"],
                    risk_factors=["è¿›ä¸€æ­¥ä¸‹è·Œé£é™©", "æ­¢æŸè€ƒè™‘"]
                ))
            
            # æ£€æµ‹æ³¢åŠ¨æ¨¡å¼
            volatility = np.std(numeric_values)
            if volatility > 1.5:
                insights.append(AIInsight(
                    insight_type="é«˜æ³¢åŠ¨æ¨¡å¼",
                    confidence=0.78,
                    description="AIæ£€æµ‹åˆ°é«˜æ³¢åŠ¨æ€§æ¨¡å¼ï¼Œè¯„çº§å˜åŒ–é¢‘ç¹",
                    recommendation="å»ºè®®çŸ­çº¿æ“ä½œï¼Œæ³¨æ„é£é™©æ§åˆ¶",
                    supporting_evidence=[f"æ³¢åŠ¨ç‡: {volatility:.3f}", "é¢‘ç¹å˜åŒ–"],
                    risk_factors=["é«˜é£é™©", "éš¾ä»¥é¢„æµ‹"]
                ))
            
        except Exception as e:
            self.logger.error(f"AIæ¨¡å¼è¯†åˆ«å¤±è´¥: {str(e)}")
        
        return insights
    
    def _ai_sentiment_analysis(self, news_data: List[str], stock_code: str) -> List[AIInsight]:
        """AIæƒ…ç»ªåˆ†æ"""
        insights = []
        
        try:
            if not news_data:
                return insights
            
            # æ¨¡æ‹Ÿæƒ…ç»ªåˆ†æ
            positive_keywords = ['åˆ©å¥½', 'ä¸Šæ¶¨', 'å¢é•¿', 'ç›ˆåˆ©', 'çªç ´', 'ä¹°å…¥', 'æ¨è']
            negative_keywords = ['åˆ©ç©º', 'ä¸‹è·Œ', 'äºæŸ', 'é£é™©', 'å–å‡º', 'å‡æŒ', 'è­¦å‘Š']
            
            sentiment_scores = []
            for news in news_data:
                pos_score = sum(1 for keyword in positive_keywords if keyword in news)
                neg_score = sum(1 for keyword in negative_keywords if keyword in news)
                sentiment_scores.append(pos_score - neg_score)
            
            avg_sentiment = np.mean(sentiment_scores) if sentiment_scores else 0
            
            if avg_sentiment > 0.5:
                insights.append(AIInsight(
                    insight_type="æ­£é¢æƒ…ç»ªä¸»å¯¼",
                    confidence=0.76,
                    description="æ–°é—»æƒ…ç»ªåˆ†ææ˜¾ç¤ºå¸‚åœºå¯¹è¯¥è‚¡æŒæ­£é¢æ€åº¦",
                    recommendation="æƒ…ç»ªé¢æ”¯æ’‘ï¼Œå¯é€‚åº¦ä¹è§‚",
                    supporting_evidence=[f"æƒ…ç»ªå¾—åˆ†: {avg_sentiment:.2f}", f"æ–°é—»æ•°é‡: {len(news_data)}"],
                    risk_factors=["æƒ…ç»ªåè½¬é£é™©"]
                ))
            elif avg_sentiment < -0.5:
                insights.append(AIInsight(
                    insight_type="è´Ÿé¢æƒ…ç»ªä¸»å¯¼",
                    confidence=0.74,
                    description="æ–°é—»æƒ…ç»ªåˆ†ææ˜¾ç¤ºå¸‚åœºå¯¹è¯¥è‚¡æŒè´Ÿé¢æ€åº¦",
                    recommendation="æƒ…ç»ªé¢æ‰¿å‹ï¼Œå»ºè®®è°¨æ…",
                    supporting_evidence=[f"æƒ…ç»ªå¾—åˆ†: {avg_sentiment:.2f}", f"æ–°é—»æ•°é‡: {len(news_data)}"],
                    risk_factors=["æƒ…ç»ªæ¶åŒ–é£é™©", "ä¿¡å¿ƒä¸è¶³"]
                ))
            
        except Exception as e:
            self.logger.error(f"AIæƒ…ç»ªåˆ†æå¤±è´¥: {str(e)}")
        
        return insights
    
    def _ai_trend_prediction(self, rating_series: pd.Series, multi_result: Dict) -> List[AIInsight]:
        """AIè¶‹åŠ¿é¢„æµ‹"""
        insights = []
        
        try:
            # æ¨¡æ‹Ÿæ·±åº¦å­¦ä¹ è¶‹åŠ¿é¢„æµ‹
            numeric_values = [self.rating_scale.get(r, r) for r in rating_series if r is not None]
            
            if len(numeric_values) < 10:
                return insights
            
            # ç®€åŒ–çš„è¶‹åŠ¿é¢„æµ‹ç®—æ³•
            recent_values = numeric_values[-5:]
            trend_momentum = np.mean(np.diff(recent_values))
            
            # é¢„æµ‹æœªæ¥3-5å¤©çš„å¯èƒ½æ–¹å‘
            if trend_momentum > 0.1:
                predicted_direction = "å‘ä¸Š"
                confidence = min(0.9, 0.6 + abs(trend_momentum))
            elif trend_momentum < -0.1:
                predicted_direction = "å‘ä¸‹"
                confidence = min(0.9, 0.6 + abs(trend_momentum))
            else:
                predicted_direction = "éœ‡è¡"
                confidence = 0.65
            
            insights.append(AIInsight(
                insight_type="è¶‹åŠ¿é¢„æµ‹",
                confidence=confidence,
                description=f"AIé¢„æµ‹æœªæ¥3-5å¤©è¶‹åŠ¿{predicted_direction}",
                recommendation=f"åŸºäºé¢„æµ‹è°ƒæ•´ç­–ç•¥: {predicted_direction}è¶‹åŠ¿",
                supporting_evidence=[f"åŠ¨é‡: {trend_momentum:.3f}", "å†å²æ¨¡å¼åŒ¹é…"],
                risk_factors=["é¢„æµ‹ä¸ç¡®å®šæ€§", "å¸‚åœºçªå‘äº‹ä»¶"]
            ))
            
        except Exception as e:
            self.logger.error(f"AIè¶‹åŠ¿é¢„æµ‹å¤±è´¥: {str(e)}")
        
        return insights
    
    def _ai_risk_assessment(self, interp_result: Dict, multi_result: Dict) -> List[AIInsight]:
        """AIé£é™©è¯„ä¼°"""
        insights = []
        
        try:
            # ç»¼åˆé£é™©è¯„ä¼°
            data_quality_risk = 1 - interp_result.get('interpolation_quality', 0.5)
            
            # å¤šç»´åº¦ä¸€è‡´æ€§é£é™©
            consistency_risk = 0.5  # ç®€åŒ–è®¡ç®—
            if 'fusion' in multi_result:
                fusion_result = multi_result['fusion']
                if hasattr(fusion_result, 'confidence'):
                    consistency_risk = 1 - fusion_result.confidence
            
            # ç»¼åˆé£é™©è¯„åˆ†
            overall_risk = (data_quality_risk * 0.4 + consistency_risk * 0.6)
            
            if overall_risk > 0.7:
                risk_level = "é«˜é£é™©"
                color_code = "ğŸ”´"
            elif overall_risk > 0.4:
                risk_level = "ä¸­ç­‰é£é™©"
                color_code = "ğŸŸ¡"
            else:
                risk_level = "ä½é£é™©"
                color_code = "ğŸŸ¢"
            
            insights.append(AIInsight(
                insight_type="ç»¼åˆé£é™©è¯„ä¼°",
                confidence=0.82,
                description=f"{color_code} AIè¯„ä¼°å½“å‰é£é™©ç­‰çº§ä¸º{risk_level}",
                recommendation=f"å»ºè®®é‡‡ç”¨{risk_level}å¯¹åº”çš„æŠ•èµ„ç­–ç•¥",
                supporting_evidence=[
                    f"æ•°æ®è´¨é‡é£é™©: {data_quality_risk:.2f}",
                    f"ä¸€è‡´æ€§é£é™©: {consistency_risk:.2f}"
                ],
                risk_factors=["æ¨¡å‹ä¸ç¡®å®šæ€§", "å¸‚åœºå˜åŒ–é£é™©"]
            ))
            
        except Exception as e:
            self.logger.error(f"AIé£é™©è¯„ä¼°å¤±è´¥: {str(e)}")
        
        return insights
    
    # ================ æ™ºèƒ½èåˆå’Œå†³ç­– ================
    
    def _calculate_ai_enhanced_score(self, 
                                   interp_result: Dict, 
                                   multi_result: Dict, 
                                   ai_insights: List[AIInsight]) -> float:
        """è®¡ç®—AIå¢å¼ºè¯„åˆ†"""
        try:
            # åŸºç¡€åˆ†æ•°
            base_score = 50  # ä¸­æ€§èµ·ç‚¹
            
            # æ’å€¼è´¨é‡è´¡çŒ®
            interp_quality = interp_result.get('interpolation_quality', 0.5)
            base_score += (interp_quality - 0.5) * 20
            
            # å¤šç»´åº¦åˆ†æè´¡çŒ®
            if 'fusion' in multi_result:
                fusion_result = multi_result['fusion']
                if hasattr(fusion_result, 'score'):
                    multi_score = fusion_result.score
                    base_score = base_score * 0.6 + multi_score * 0.4
            
            # AIæ´å¯Ÿè´¡çŒ®
            ai_adjustment = 0
            for insight in ai_insights:
                if "ä¸Šå‡" in insight.description or "æ­£é¢" in insight.description:
                    ai_adjustment += insight.confidence * 10
                elif "ä¸‹é™" in insight.description or "è´Ÿé¢" in insight.description:
                    ai_adjustment -= insight.confidence * 10
            
            # æœ€ç»ˆè¯„åˆ†
            final_score = base_score + ai_adjustment
            final_score = max(0, min(100, final_score))
            
            return final_score
            
        except Exception as e:
            self.logger.error(f"AIå¢å¼ºè¯„åˆ†è®¡ç®—å¤±è´¥: {str(e)}")
            return 50
    
    def _generate_final_recommendation(self, 
                                     interp_result: Dict,
                                     multi_result: Dict,
                                     ai_insights: List[AIInsight],
                                     ai_score: float) -> str:
        """ç”Ÿæˆæœ€ç»ˆå»ºè®®"""
        try:
            recommendations = []
            
            # åŸºäºAIå¢å¼ºè¯„åˆ†
            if ai_score >= 75:
                recommendations.append("ğŸš€ ç»¼åˆAIåˆ†ææ˜¾ç¤ºå¼ºçƒˆçœ‹å¥½ä¿¡å·")
            elif ai_score >= 60:
                recommendations.append("ğŸ“ˆ ç»¼åˆåˆ†æåå‘ç§¯æï¼Œå¯é€‚åº¦å…³æ³¨")
            elif ai_score >= 40:
                recommendations.append("âš–ï¸ ç»¼åˆåˆ†æä¸­æ€§ï¼Œå»ºè®®è°¨æ…è§‚æœ›")
            else:
                recommendations.append("ğŸ“‰ ç»¼åˆåˆ†æåå‘æ¶ˆæï¼Œå»ºè®®å›é¿é£é™©")
            
            # AIæ´å¯Ÿå»ºè®®
            for insight in ai_insights:
                if insight.confidence > 0.8:
                    recommendations.append(f"ğŸ¤– AIæ´å¯Ÿ: {insight.recommendation}")
            
            # æ•°æ®è´¨é‡æé†’
            if interp_result.get('interpolation_quality', 0) < 0.6:
                recommendations.append("âš ï¸ æ•°æ®è´¨é‡æé†’: æ’å€¼æ¯”ä¾‹è¾ƒé«˜ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯")
            
            return " | ".join(recommendations[:3])  # æœ€å¤šæ˜¾ç¤º3æ¡ä¸»è¦å»ºè®®
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæœ€ç»ˆå»ºè®®å¤±è´¥: {str(e)}")
            return "åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œå»ºè®®äººå·¥å¤æ ¸"
    
    def _generate_intelligent_risk_warnings(self, 
                                          interp_result: Dict,
                                          multi_result: Dict,
                                          ai_insights: List[AIInsight]) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½é£é™©é¢„è­¦"""
        warnings = []
        
        try:
            # æ•°æ®è´¨é‡é£é™©
            if interp_result.get('interpolation_quality', 1) < 0.5:
                warnings.append("âš ï¸ æ•°æ®è´¨é‡é£é™©: æ’å€¼æ¯”ä¾‹è¿‡é«˜ï¼Œåˆ†æå¯é æ€§é™ä½")
            
            # AIç½®ä¿¡åº¦é£é™©
            high_conf_insights = [i for i in ai_insights if i.confidence > 0.8]
            if len(high_conf_insights) == 0:
                warnings.append("ğŸ¤– AIç½®ä¿¡åº¦é£é™©: æ‰€æœ‰AIåˆ†æç½®ä¿¡åº¦åä½")
            
            # è¶‹åŠ¿ä¸€è‡´æ€§é£é™©
            trend_insights = [i for i in ai_insights if "è¶‹åŠ¿" in i.insight_type]
            if len(trend_insights) > 1:
                # æ£€æŸ¥è¶‹åŠ¿ä¸€è‡´æ€§
                directions = [i.description for i in trend_insights]
                if len(set(directions)) > 1:
                    warnings.append("ğŸ“Š è¶‹åŠ¿åˆ†æ­§é£é™©: AIæ£€æµ‹åˆ°ç›¸äº’çŸ›ç›¾çš„è¶‹åŠ¿ä¿¡å·")
            
            # æ¨¡å‹é£é™©
            if not self.enable_ai:
                warnings.append("ğŸ”§ æ¨¡å‹é£é™©: AIåŠŸèƒ½æœªå¯ç”¨ï¼Œä»…ä½¿ç”¨ä¼ ç»Ÿåˆ†ææ–¹æ³•")
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆé£é™©é¢„è­¦å¤±è´¥: {str(e)}")
            warnings.append("âš ï¸ é£é™©è¯„ä¼°è¿‡ç¨‹å‡ºç°å¼‚å¸¸")
        
        return warnings
    
    def _assess_overall_confidence(self, 
                                 interp_result: Dict,
                                 multi_result: Dict,
                                 ai_insights: List[AIInsight]) -> str:
        """è¯„ä¼°æ•´ä½“ç½®ä¿¡åº¦"""
        try:
            confidence_scores = []
            
            # æ’å€¼è´¨é‡ç½®ä¿¡åº¦
            interp_confidence = interp_result.get('confidence_score', 0.5)
            confidence_scores.append(interp_confidence)
            
            # å¤šç»´åº¦åˆ†æç½®ä¿¡åº¦
            if 'fusion' in multi_result:
                fusion_result = multi_result['fusion']
                if hasattr(fusion_result, 'confidence'):
                    confidence_scores.append(fusion_result.confidence)
            
            # AIåˆ†æç½®ä¿¡åº¦
            if ai_insights:
                ai_confidences = [insight.confidence for insight in ai_insights]
                confidence_scores.append(np.mean(ai_confidences))
            
            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            overall_confidence = np.mean(confidence_scores) if confidence_scores else 0.5
            
            if overall_confidence >= 0.8:
                return "é«˜ç½®ä¿¡åº¦"
            elif overall_confidence >= 0.6:
                return "ä¸­ç­‰ç½®ä¿¡åº¦"
            else:
                return "ä½ç½®ä¿¡åº¦"
                
        except Exception as e:
            self.logger.error(f"ç½®ä¿¡åº¦è¯„ä¼°å¤±è´¥: {str(e)}")
            return "ç½®ä¿¡åº¦æœªçŸ¥"
    
    def _create_error_result(self, error_message: str) -> ComprehensiveAnalysisResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return ComprehensiveAnalysisResult(
            interpolation_result={'error': error_message},
            multi_dimensional_result={'error': error_message},
            ai_insights=[],
            ai_enhanced_score=0,
            final_recommendation=f"åˆ†æå¤±è´¥: {error_message}",
            confidence_level="æ— ",
            risk_warning=[f"ç³»ç»Ÿé”™è¯¯: {error_message}"],
            analysis_timestamp=datetime.now().isoformat(),
            processing_time=0
        )
    
    def export_results_for_web(self, result: ComprehensiveAnalysisResult) -> Dict:
        """å¯¼å‡ºç»“æœä¾›Webç•Œé¢ä½¿ç”¨"""
        try:
            return {
                'ai_enhanced_score': result.ai_enhanced_score,
                'final_recommendation': result.final_recommendation,
                'confidence_level': result.confidence_level,
                'risk_warnings': result.risk_warning,
                'processing_time': result.processing_time,
                'analysis_timestamp': result.analysis_timestamp,
                
                # AIæ´å¯Ÿï¼ˆåºåˆ—åŒ–ï¼‰
                'ai_insights': [asdict(insight) for insight in result.ai_insights],
                
                # æ’å€¼ç»“æœæ‘˜è¦
                'interpolation_summary': {
                    'quality': result.interpolation_result.get('interpolation_quality', 0),
                    'strategy': result.interpolation_result.get('strategy_used', 'unknown'),
                    'missing_ratio': result.interpolation_result.get('missing_ratio', 0)
                },
                
                # å¤šç»´åº¦åˆ†ææ‘˜è¦
                'multi_dimensional_summary': {
                    'available_levels': list(result.multi_dimensional_result.keys()),
                    'fusion_available': 'fusion' in result.multi_dimensional_result
                }
            }
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºWebç»“æœå¤±è´¥: {str(e)}")
            return {'error': str(e)}

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºAIå¢å¼ºåˆ†æå™¨
    analyzer = AIEnhancedSignalAnalyzer(enable_ai_features=True)
    
    # ç¤ºä¾‹æ•°æ®
    sample_data = pd.DataFrame({
        'è‚¡ç¥¨ä»£ç ': ['000001'],
        '20241201': ['å¤§å¤š'],
        '20241202': ['ä¸­å¤š'],
        '20241203': ['-'],
        '20241204': ['å°å¤š'],
        '20241205': ['å¾®å¤š']
    })
    
    # ç¤ºä¾‹æ–°é—»
    sample_news = [
        "è¯¥å…¬å¸å‘å¸ƒåˆ©å¥½æ¶ˆæ¯ï¼Œä¸šç»©å¤§å¹…å¢é•¿",
        "åˆ†æå¸ˆä¸Šè°ƒè¯„çº§ï¼Œå»ºè®®ä¹°å…¥",
        "å¸‚åœºä¼ è¨€å­˜åœ¨é£é™©ï¼ŒæŠ•èµ„è€…éœ€è°¨æ…"
    ]
    
    # æ‰§è¡Œç»¼åˆåˆ†æ
    result = analyzer.comprehensive_analyze(
        stock_data=sample_data,
        stock_code='000001',
        news_data=sample_news,
        enable_prediction=True
    )
    
    print("=== AIå¢å¼º8çº§ä¿¡å·åˆ†æç»“æœ ===")
    print(f"AIå¢å¼ºè¯„åˆ†: {result.ai_enhanced_score:.1f}/100")
    print(f"æœ€ç»ˆå»ºè®®: {result.final_recommendation}")
    print(f"ç½®ä¿¡åº¦: {result.confidence_level}")
    print(f"å¤„ç†æ—¶é—´: {result.processing_time:.3f}s")
    
    print("\n=== AIæ´å¯Ÿ ===")
    for insight in result.ai_insights:
        print(f"â€¢ {insight.insight_type} (ç½®ä¿¡åº¦: {insight.confidence:.2f})")
        print(f"  {insight.description}")
        print(f"  å»ºè®®: {insight.recommendation}")
    
    print("\n=== é£é™©é¢„è­¦ ===")
    for warning in result.risk_warning:
        print(f"â€¢ {warning}")
