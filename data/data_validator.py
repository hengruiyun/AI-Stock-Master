"""
æ•°æ®éªŒè¯å™¨ - æ•°æ®è´¨é‡æ£€æµ‹å’ŒæŠ¥å‘Š

åŠŸèƒ½ç‰¹æ€§ï¼š
1. è¯„çº§æ•°æ®éªŒè¯ - 8çº§è¯„çº§ç³»ç»Ÿå®Œæ•´æ€§æ£€æŸ¥
2. è¡Œä¸šæ•°æ®éªŒè¯ - è¡Œä¸šåˆ†ç±»æ­£ç¡®æ€§æ£€æŸ¥
3. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ - ç¼ºå¤±å€¼å’Œå¼‚å¸¸å€¼æ£€æµ‹
4. è´¨é‡æŠ¥å‘Šç”Ÿæˆ - è¯¦ç»†çš„æ•°æ®è´¨é‡åˆ†ææŠ¥å‘Š

ä½œè€…: 267278466@qq.com
åˆ›å»ºæ—¶é—´ï¼š2025-06-07
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Set
from datetime import datetime
import warnings

# å¯¼å…¥é…ç½®
try:
    from config import RATING_SCORE_MAP, MARKET_CONFIG
    from industry_lookup import get_industry_stocks, get_stock_industry
except ImportError:
    # é»˜è®¤é…ç½®
    RATING_SCORE_MAP = {
        'å¤§å¤š': 7, 'ä¸­å¤š': 6, 'å°å¤š': 5, 'å¾®å¤š': 4,
        'å¾®ç©º': 3, 'å°ç©º': 2, 'ä¸­ç©º': 1, 'å¤§ç©º': 0, 
        '-': None
    }
    MARKET_CONFIG = {'CN': {'name': 'ä¸­å›½Aè‚¡'}}

def get_industry_stocks(industry): return []
def get_stock_industry(code): return "æœªåˆ†ç±»"


class DataValidator:
    """æ•°æ®éªŒè¯å™¨ - æä¾›å…¨é¢çš„æ•°æ®è´¨é‡æ£€æµ‹"""
    
    def __init__(self, enable_industry_check: bool = True):
        """
        åˆå§‹åŒ–éªŒè¯å™¨
        
        å‚æ•°:
            enable_industry_check (bool): æ˜¯å¦å¯ç”¨è¡Œä¸šæ•°æ®éªŒè¯
        """
        self.enable_industry_check = enable_industry_check
        self.validation_results = {}
        self.quality_score = 0.0
    
    def validate_complete_dataset(self, dataset) -> Dict:
        """
        å®Œæ•´æ•°æ®é›†éªŒè¯
        
        å‚æ•°:
            dataset: StockDataSetå¯¹è±¡æˆ–DataFrame
            
        è¿”å›:
            dict: å®Œæ•´éªŒè¯ç»“æœ
        """
        if hasattr(dataset, 'data'):
            df = dataset.data
            file_path = dataset.file_path
        else:
            df = dataset
            file_path = "unknown"
        
        validation_start = datetime.now()
        
        # 1. åŸºç¡€ç»“æ„éªŒè¯
        structure_result = self.validate_data_structure(df)
        
        # 2. è¯„çº§æ•°æ®éªŒè¯
        rating_result = self.validate_rating_data(df)
        
        # 3. è¡Œä¸šæ•°æ®éªŒè¯
        industry_result = self.validate_industry_data(df) if self.enable_industry_check else {}
        
        # 4. æ•°æ®å®Œæ•´æ€§éªŒè¯
        completeness_result = self.check_data_completeness(df)
        
        # 5. æ•°æ®ä¸€è‡´æ€§éªŒè¯
        consistency_result = self.check_data_consistency(df)
        
        # 6. è®¡ç®—è´¨é‡åˆ†æ•°
        quality_score = self.calculate_quality_score(
            structure_result, rating_result, industry_result, 
            completeness_result, consistency_result
        )
        
        validation_time = (datetime.now() - validation_start).total_seconds()
        
        # æ•´åˆç»“æœ
        complete_result = {
            'is_valid': all([
                structure_result.get('is_valid', False),
                rating_result.get('is_valid', False),
                completeness_result.get('is_valid', False)
            ]),
            'quality_score': round(quality_score, 2),
            'validation_time': f"{validation_time:.2f}s",
            'file_path': file_path,
            'validation_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'structure': structure_result,
            'rating_data': rating_result,
            'industry_data': industry_result,
            'completeness': completeness_result,
            'consistency': consistency_result,
            'recommendations': self._generate_recommendations(
                structure_result, rating_result, industry_result, completeness_result
            )
        }
        
        self.validation_results = complete_result
        self.quality_score = quality_score
        
        return complete_result
    
    def validate_data_structure(self, df: pd.DataFrame) -> Dict:
        """éªŒè¯æ•°æ®åŸºç¡€ç»“æ„"""
        result = {
            'is_valid': True,
            'missing_columns': [],
            'warnings': [],
            'data_quality': {}
        }
        
        # æ£€æŸ¥å¿…éœ€åˆ—
        required_columns = ['è¡Œä¸š', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°']
        for col in required_columns:
            if col not in df.columns:
                result['missing_columns'].append(col)
                result['is_valid'] = False
        
        # æ£€æŸ¥æ—¥æœŸåˆ—
        date_columns = [col for col in df.columns if str(col).startswith('202')]
        
        if len(date_columns) == 0:
            result['warnings'].append('æœªæ‰¾åˆ°æ—¥æœŸåˆ—')
            result['is_valid'] = False
        elif len(date_columns) < 5:
            result['warnings'].append('æ—¥æœŸåˆ—è¿‡å°‘ï¼Œå¯èƒ½å½±å“è¶‹åŠ¿åˆ†æå‡†ç¡®æ€§')
        
        # æ•°æ®è´¨é‡æ£€æŸ¥
        if result['is_valid']:
            result['data_quality'] = {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'date_columns_count': len(date_columns),
                'date_range': f"{min(date_columns)} ~ {max(date_columns)}" if date_columns else "æ— ",
                'industry_coverage': df['è¡Œä¸š'].notna().sum() / len(df) * 100 if 'è¡Œä¸š' in df.columns else 0,
                'duplicate_codes': df['è‚¡ç¥¨ä»£ç '].duplicated().sum() if 'è‚¡ç¥¨ä»£ç ' in df.columns else 0,
                'duplicate_names': df['è‚¡ç¥¨åç§°'].duplicated().sum() if 'è‚¡ç¥¨åç§°' in df.columns else 0
            }
        
        return result
    
    def validate_rating_data(self, df: pd.DataFrame) -> Dict:
        """éªŒè¯è¯„çº§æ•°æ®"""
        date_columns = [col for col in df.columns if str(col).startswith('202')]
        
        if not date_columns:
            return {
                'is_valid': False,
                'error': 'æœªæ‰¾åˆ°è¯„çº§æ—¥æœŸåˆ—',
                'details': {}
            }
        
        valid_ratings = set(RATING_SCORE_MAP.keys())
        result = {
            'is_valid': True,
            'total_date_columns': len(date_columns),
            'date_range': f"{min(date_columns)} ~ {max(date_columns)}",
            'rating_distribution': {},
            'invalid_ratings': {},
            'missing_data_stats': {},
            'quality_metrics': {}
        }
        
        total_cells = 0
        valid_cells = 0
        missing_cells = 0
        
        # éªŒè¯æ¯ä¸ªæ—¥æœŸåˆ—
        for col in date_columns:
            col_data = df[col]
            total_cells += len(col_data)
            
            # è¯„çº§åˆ†å¸ƒ
            rating_dist = col_data.value_counts()
            result['rating_distribution'][col] = rating_dist.to_dict()
            
            # æ— æ•ˆè¯„çº§æ£€æµ‹
            unique_ratings = set(col_data.dropna().unique())
            invalid = unique_ratings - valid_ratings
            if invalid:
                result['invalid_ratings'][col] = list(invalid)
                result['is_valid'] = False
            
            # ç¼ºå¤±æ•°æ®ç»Ÿè®¡
            missing_count = col_data.isna().sum() + (col_data == '-').sum()
            missing_rate = missing_count / len(col_data) * 100
            missing_cells += missing_count
            
            result['missing_data_stats'][col] = {
                'missing_count': missing_count,
                'missing_rate': round(missing_rate, 2),
                'valid_count': len(col_data) - missing_count
            }
            
            # æœ‰æ•ˆæ•°æ®ç»Ÿè®¡
            valid_ratings_count = col_data.isin([r for r in valid_ratings if r != '-']).sum()
            valid_cells += valid_ratings_count
        
        # æ•´ä½“è´¨é‡æŒ‡æ ‡
        overall_validity_rate = valid_cells / total_cells * 100 if total_cells > 0 else 0
        overall_missing_rate = missing_cells / total_cells * 100 if total_cells > 0 else 0
        
        result['quality_metrics'] = {
            'total_cells': total_cells,
            'valid_cells': valid_cells,
            'missing_cells': missing_cells,
            'validity_rate': round(overall_validity_rate, 2),
            'missing_rate': round(overall_missing_rate, 2),
            'data_coverage': round(100 - overall_missing_rate, 2)
        }
        
        return result
    
    def validate_industry_data(self, df: pd.DataFrame) -> Dict:
        """éªŒè¯è¡Œä¸šæ•°æ®"""
        if 'è¡Œä¸š' not in df.columns:
            return {
                'is_valid': False,
                'error': 'æœªæ‰¾åˆ°è¡Œä¸šåˆ—',
                'details': {}
            }
        
        industry_col = df['è¡Œä¸š']
        result = {
            'is_valid': True,
            'industry_coverage': 0,
            'industry_distribution': {},
            'missing_industry_stats': {},
            'quality_metrics': {}
        }
        
        # è¡Œä¸šè¦†ç›–ç‡
        non_missing = industry_col.notna() & (industry_col != '') & (industry_col != 'æœªåˆ†ç±»')
        coverage_rate = non_missing.sum() / len(industry_col) * 100
        result['industry_coverage'] = round(coverage_rate, 2)
        
        # è¡Œä¸šåˆ†å¸ƒ
        industry_dist = industry_col.value_counts()
        result['industry_distribution'] = industry_dist.head(20).to_dict()
        
        # ç¼ºå¤±ç»Ÿè®¡
        missing_count = industry_col.isna().sum() + (industry_col == '').sum()
        unclassified_count = (industry_col == 'æœªåˆ†ç±»').sum()
        
        result['missing_industry_stats'] = {
            'missing_count': missing_count,
            'unclassified_count': unclassified_count,
            'total_missing': missing_count + unclassified_count,
            'missing_rate': round((missing_count + unclassified_count) / len(industry_col) * 100, 2)
        }
        
        # è´¨é‡æŒ‡æ ‡
        result['quality_metrics'] = {
            'total_stocks': len(df),
            'classified_stocks': non_missing.sum(),
            'unique_industries': len(industry_dist),
            'largest_industry': industry_dist.index[0] if len(industry_dist) > 0 else None,
            'largest_industry_count': industry_dist.iloc[0] if len(industry_dist) > 0 else 0
        }
        
        return result
    
    def check_data_completeness(self, df: pd.DataFrame) -> Dict:
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        result = {
            'is_valid': True,
            'overall_completeness': 0,
            'column_completeness': {},
            'row_completeness': {},
            'critical_missing': [],
            'quality_metrics': {}
        }
        
        # åˆ—å®Œæ•´æ€§
        for col in df.columns:
            missing_count = df[col].isna().sum()
            completeness = (len(df) - missing_count) / len(df) * 100
            
            result['column_completeness'][col] = {
                'missing_count': missing_count,
                'completeness_rate': round(completeness, 2),
                'is_critical': col in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°']
            }
            
            # å…³é”®åˆ—ç¼ºå¤±æ£€æŸ¥
            if col in ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°'] and missing_count > 0:
                result['critical_missing'].append(col)
                result['is_valid'] = False
        
        # è¡Œå®Œæ•´æ€§ï¼ˆè¯„çº§æ•°æ®è¡Œï¼‰
        date_columns = [col for col in df.columns if str(col).startswith('202')]
        if date_columns:
            row_stats = []
            for idx, row in df.iterrows():
                rating_data = row[date_columns]
                non_missing = rating_data.notna().sum()
                completeness = non_missing / len(date_columns) * 100
                row_stats.append(completeness)
            
            result['row_completeness'] = {
                'avg_completeness': round(np.mean(row_stats), 2),
                'min_completeness': round(np.min(row_stats), 2),
                'max_completeness': round(np.max(row_stats), 2),
                'stocks_with_full_data': sum(1 for x in row_stats if x == 100),
                'stocks_with_no_data': sum(1 for x in row_stats if x == 0)
            }
        
        # æ•´ä½“å®Œæ•´æ€§
        total_cells = df.size
        missing_cells = df.isna().sum().sum()
        overall_completeness = (total_cells - missing_cells) / total_cells * 100
        result['overall_completeness'] = round(overall_completeness, 2)
        
        # è´¨é‡æŒ‡æ ‡
        result['quality_metrics'] = {
            'total_cells': total_cells,
            'missing_cells': missing_cells,
            'data_density': round(overall_completeness, 2),
            'critical_columns_ok': len(result['critical_missing']) == 0
        }
        
        return result
    
    def check_data_consistency(self, df: pd.DataFrame) -> Dict:
        """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
        result = {
            'is_valid': True,
            'duplicate_checks': {},
            'format_consistency': {},
            'value_consistency': {}
        }
        
        # é‡å¤æ•°æ®æ£€æŸ¥
        if 'è‚¡ç¥¨ä»£ç ' in df.columns:
            duplicate_codes = df['è‚¡ç¥¨ä»£ç '].duplicated().sum()
            result['duplicate_checks']['duplicate_stock_codes'] = duplicate_codes
            if duplicate_codes > 0:
                result['is_valid'] = False
        
        if 'è‚¡ç¥¨åç§°' in df.columns:
            duplicate_names = df['è‚¡ç¥¨åç§°'].duplicated().sum()
            result['duplicate_checks']['duplicate_stock_names'] = duplicate_names
        
        return result
    
    def calculate_quality_score(self, structure: Dict, rating: Dict, 
                              industry: Dict, completeness: Dict, 
                              consistency: Dict) -> float:
        """è®¡ç®—æ•°æ®è´¨é‡åˆ†æ•° (0-100)"""
        score = 0.0
        
        # ç»“æ„åˆ†æ•° (20%)
        if structure.get('is_valid', False):
            score += 20
        
        # è¯„çº§æ•°æ®åˆ†æ•° (40%)
        if rating.get('is_valid', False):
            validity_rate = rating.get('quality_metrics', {}).get('validity_rate', 0)
            score += 40 * (validity_rate / 100)
        
        # å®Œæ•´æ€§åˆ†æ•° (25%)
        if completeness.get('is_valid', False):
            completeness_rate = completeness.get('overall_completeness', 0)
            score += 25 * (completeness_rate / 100)
        
        # ä¸€è‡´æ€§åˆ†æ•° (10%)
        if consistency.get('is_valid', False):
            score += 10
        
        # è¡Œä¸šæ•°æ®åˆ†æ•° (5%)
        if industry.get('is_valid', True):
            coverage = industry.get('industry_coverage', 0)
            score += 5 * (coverage / 100)
        
        return min(100.0, score)
    
    def generate_quality_report(self) -> str:
        """ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š"""
        if not self.validation_results:
            return "é”™è¯¯ æœªè¿›è¡Œæ•°æ®éªŒè¯ï¼Œè¯·å…ˆè°ƒç”¨validate_complete_datasetæ–¹æ³•"
        
        results = self.validation_results
        
        report = []
        report.append("=" * 80)
        report.append("æ•°æ® æ•°æ®è´¨é‡éªŒè¯æŠ¥å‘Š")
        report.append("=" * 80)
        
        # åŸºç¡€ä¿¡æ¯
        report.append(f"ğŸ“‚ æ–‡ä»¶è·¯å¾„: {results.get('file_path', 'unknown')}")
        report.append(f"ğŸ•’ éªŒè¯æ—¶é—´: {results.get('validation_timestamp', 'unknown')}")
        report.append(f"â±ï¸ éªŒè¯è€—æ—¶: {results.get('validation_time', 'unknown')}")
        report.append(f"æ ¸å¿ƒ è´¨é‡åˆ†æ•°: {results.get('quality_score', 0)}/100")
        report.append("")
        
        # éªŒè¯çŠ¶æ€
        status_emoji = "æˆåŠŸ" if results.get('is_valid', False) else "é”™è¯¯"
        report.append(f"{status_emoji} æ•´ä½“éªŒè¯çŠ¶æ€: {'é€šè¿‡' if results.get('is_valid', False) else 'å¤±è´¥'}")
        report.append("")
        
        # ç»“æ„éªŒè¯
        structure = results.get('structure', {})
        if structure:
            report.append("åˆ—è¡¨ æ•°æ®ç»“æ„éªŒè¯:")
            dq = structure.get('data_quality', {})
            report.append(f"   ğŸ“ æ•°æ®è§„æ¨¡: {dq.get('total_rows', 0)} è¡Œ Ã— {dq.get('total_columns', 0)} åˆ—")
            report.append(f"   æ—¶é—´ æ—¥æœŸèŒƒå›´: {dq.get('date_range', 'æ— ')}")
            report.append(f"   è¡Œä¸š è¡Œä¸šè¦†ç›–: {dq.get('industry_coverage', 0):.1f}%")
            report.append("")
        
        # æ¨èå»ºè®®
        recommendations = results.get('recommendations', [])
        if recommendations:
            report.append("æç¤º æ”¹è¿›å»ºè®®:")
            for i, rec in enumerate(recommendations, 1):
                report.append(f"   {i}. {rec}")
            report.append("")
        
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def _generate_recommendations(self, structure: Dict, rating: Dict, 
                                industry: Dict, completeness: Dict) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # ç»“æ„é—®é¢˜
        if not structure.get('is_valid', False):
            recommendations.append("ä¿®å¤æ•°æ®ç»“æ„é—®é¢˜ï¼Œç¡®ä¿åŒ…å«å¿…éœ€çš„åˆ—")
        
        # è¯„çº§é—®é¢˜
        if rating.get('quality_metrics', {}).get('validity_rate', 0) < 90:
            recommendations.append("æ¸…ç†æ— æ•ˆè¯„çº§æ•°æ®ï¼Œç¡®ä¿ç¬¦åˆ8çº§è¯„çº§ç³»ç»Ÿ")
        
        # è¡Œä¸šé—®é¢˜
        if industry.get('industry_coverage', 0) < 80:
            recommendations.append("å®Œå–„è¡Œä¸šåˆ†ç±»ä¿¡æ¯ï¼Œæé«˜è¡Œä¸šè¦†ç›–ç‡")
        
        # å®Œæ•´æ€§é—®é¢˜
        if completeness.get('overall_completeness', 0) < 70:
            recommendations.append("è¡¥å……ç¼ºå¤±æ•°æ®ï¼Œæé«˜æ•°æ®å®Œæ•´æ€§")
        
        return recommendations


# ä¾¿æ·å‡½æ•°
def validate_stock_data(data: pd.DataFrame, enable_industry_check: bool = True) -> Dict:
    """ä¾¿æ·å‡½æ•°ï¼šéªŒè¯è‚¡ç¥¨æ•°æ®"""
    validator = DataValidator(enable_industry_check)
    return validator.validate_complete_dataset(data)


def generate_quick_report(data: pd.DataFrame) -> str:
    """ä¾¿æ·å‡½æ•°ï¼šç”Ÿæˆå¿«é€Ÿæ•°æ®è´¨é‡æŠ¥å‘Š"""
    validator = DataValidator()
    validator.validate_complete_dataset(data)
    return validator.generate_quality_report()


# æµ‹è¯•å‡½æ•°
def test_data_validator():
    """æµ‹è¯•æ•°æ®éªŒè¯å™¨"""
    print("æµ‹è¯• æµ‹è¯•æ•°æ®éªŒè¯å™¨...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = pd.DataFrame({
        'è¡Œä¸š': ['è½¯ä»¶å¼€å‘', 'åŠå¯¼ä½“', 'é“¶è¡Œ', None, 'æœªåˆ†ç±»'],
        'è‚¡ç¥¨ä»£ç ': ['000001', '000002', '000003', '000004', '000005'],
        'è‚¡ç¥¨åç§°': ['æµ‹è¯•è‚¡ç¥¨1', 'æµ‹è¯•è‚¡ç¥¨2', 'æµ‹è¯•è‚¡ç¥¨3', 'æµ‹è¯•è‚¡ç¥¨4', 'æµ‹è¯•è‚¡ç¥¨5'],
        '20250601': ['å¤§å¤š', 'ä¸­å¤š', 'å°å¤š', '-', 'å¾®ç©º'],
        '20250602': ['ä¸­å¤š', 'å°å¤š', 'å¾®å¤š', '-', 'å°ç©º'],
        '20250603': ['å°å¤š', 'å¾®å¤š', 'å¾®å¤š', 'å¾®å¤š', '-']
    })
    
    # æµ‹è¯•éªŒè¯
    validator = DataValidator(enable_industry_check=False)
    result = validator.validate_complete_dataset(test_data)
    
    print(f"   æˆåŠŸ éªŒè¯å®Œæˆï¼Œè´¨é‡åˆ†æ•°: {result['quality_score']}")
    print(f"   æ•°æ® éªŒè¯çŠ¶æ€: {'é€šè¿‡' if result['is_valid'] else 'å¤±è´¥'}")
    
    # ç”ŸæˆæŠ¥å‘Š
    report = validator.generate_quality_report()
    print("   åˆ—è¡¨ è´¨é‡æŠ¥å‘Šå·²ç”Ÿæˆ")
    
    print("æˆåŠŸ æ•°æ®éªŒè¯å™¨æµ‹è¯•å®Œæˆ")
    return True


if __name__ == "__main__":
    test_data_validator() 